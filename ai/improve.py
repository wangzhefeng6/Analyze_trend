import os
import json
import sys
import dotenv
import argparse
import time
import requests
import urllib3
import winreg  # Windowsæ³¨å†Œè¡¨è®¿é—®

import langchain_core.exceptions
from langchain_openai import ChatOpenAI
from langchain.prompts import (
  ChatPromptTemplate,
  SystemMessagePromptTemplate,
  HumanMessagePromptTemplate,
)
from structure import Structure

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è·å–é¡¹ç›®æ ¹ç›®å½•çš„.envæ–‡ä»¶
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
env_path = os.path.join(root_dir, '.env')

if os.path.exists(env_path):
    dotenv.load_dotenv(env_path)
    print(f"Loaded environment from {env_path}", file=sys.stderr)
else:
    print(f"Warning: .env file not found at {env_path}", file=sys.stderr)

# è®¾ç½®é»˜è®¤çš„APIé…ç½®
os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'sk-ngUapJAt1q3Dm5d2094aDe236d60422589B9Ab4bAaF933Ab')
os.environ['OPENAI_BASE_URL'] = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')

# å®šä¹‰æ”¯æŒçš„æ¨¡å‹
PROXY_MODELS = {
    'deepseek-chat': 'é€‚ç”¨äºä»£ç†æœåŠ¡',
    'gpt-3.5-turbo': 'éœ€è¦OpenAI APIæˆ–ä»£ç†æœåŠ¡æ”¯æŒ',
    'gpt-4': 'éœ€è¦OpenAI APIæˆ–ä»£ç†æœåŠ¡æ”¯æŒ',
}

template = open(os.path.join(current_dir, "template.txt"), "r", encoding='utf-8').read()
system = open(os.path.join(current_dir, "system.txt"), "r", encoding='utf-8').read()

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=str, required=True, help="jsonline data file")
    parser.add_argument("--no-proxy", action="store_true", help="ç¦ç”¨æ‰€æœ‰ä»£ç†")
    parser.add_argument("--proxy", type=str, help="æŒ‡å®šä»£ç†åœ°å€ (ä¾‹å¦‚: http://127.0.0.1:7890)")
    parser.add_argument("--test-network", action="store_true", help="æµ‹è¯•ç½‘ç»œè¿æ¥")
    return parser.parse_args()

def test_network_connection():
    """æµ‹è¯•ç½‘ç»œè¿æ¥å’Œä»£ç†çŠ¶æ€"""
    print("=" * 50, file=sys.stderr)
    print("ç½‘ç»œè¿æ¥è¯Šæ–­", file=sys.stderr)
    print("=" * 50, file=sys.stderr)
    
    # æ£€æŸ¥Windowsç³»ç»Ÿä»£ç†
    windows_proxy = check_windows_proxy()
    
    # æµ‹è¯•åŸºæœ¬ç½‘ç»œè¿æ¥
    test_urls = [
        "https://httpbin.org/ip",  # è·å–å½“å‰IP
        "https://api.openai.com/v1/models",  # OpenAI API
        "https://www.google.com",  # åŸºæœ¬è¿æ¥æµ‹è¯•
    ]
    
    connection_results = {}
    
    for url in test_urls:
        try:
            print(f"æµ‹è¯•è¿æ¥: {url}", file=sys.stderr)
            response = requests.get(url, timeout=10, verify=False)
            print(f"  âœ… çŠ¶æ€ç : {response.status_code}", file=sys.stderr)
            connection_results[url] = "success"
            
            if "httpbin.org/ip" in url:
                try:
                    ip_info = response.json()
                    print(f"  ğŸ“ å½“å‰IP: {ip_info.get('origin', 'Unknown')}", file=sys.stderr)
                except:
                    pass
        except Exception as e:
            error_msg = str(e)
            connection_results[url] = "failed"
            print(f"  âŒ å¤±è´¥: {error_msg}", file=sys.stderr)
            
            # åˆ†æé”™è¯¯ç±»å‹
            if "10054" in error_msg:
                print("    ğŸ’¡ è¿™æ˜¯Windowsè¿æ¥é‡ç½®é”™è¯¯ï¼Œé€šå¸¸ç”±ä»£ç†ä¸ç¨³å®šå¼•èµ·", file=sys.stderr)
            elif "ProxyError" in error_msg:
                print("    ğŸ’¡ è¿™æ˜¯ä»£ç†è¿æ¥é”™è¯¯", file=sys.stderr)
            elif "timeout" in error_msg.lower():
                print("    ğŸ’¡ è¿™æ˜¯ç½‘ç»œè¶…æ—¶ï¼Œå¯èƒ½æ˜¯ä»£ç†å»¶è¿Ÿè¿‡é«˜", file=sys.stderr)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†è®¾ç½®
    proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY']
    print("\nä»£ç†ç¯å¢ƒå˜é‡:", file=sys.stderr)
    for var in proxy_vars:
        value = os.environ.get(var)
        if value:
            print(f"  {var}: {value}", file=sys.stderr)
        else:
            print(f"  {var}: æœªè®¾ç½®", file=sys.stderr)
    
    # åˆ†æè¿æ¥æ¨¡å¼
    success_count = sum(1 for result in connection_results.values() if result == "success")
    total_count = len(connection_results)
    
    print(f"\nğŸ“Š è¿æ¥ç»Ÿè®¡: {success_count}/{total_count} æˆåŠŸ", file=sys.stderr)
    
    if success_count == 0:
        print("ğŸš¨ æ‰€æœ‰è¿æ¥éƒ½å¤±è´¥ï¼Œå»ºè®®:", file=sys.stderr)
        print("   1. æ£€æŸ¥ç§‘å­¦ä¸Šç½‘å·¥å…·æ˜¯å¦æ­£å¸¸è¿è¡Œ", file=sys.stderr)
        print("   2. å°è¯•åˆ‡æ¢ä»£ç†èŠ‚ç‚¹", file=sys.stderr)
        print("   3. ä½¿ç”¨ --no-proxy å®Œå…¨ç¦ç”¨ä»£ç†", file=sys.stderr)
    elif success_count < total_count:
        print("âš ï¸  éƒ¨åˆ†è¿æ¥å¤±è´¥ï¼Œç½‘ç»œä¸ç¨³å®šï¼Œå»ºè®®:", file=sys.stderr)
        print("   1. æ£€æŸ¥ä»£ç†æœåŠ¡å™¨è´Ÿè½½", file=sys.stderr)
        print("   2. å°è¯•ä½¿ç”¨æ›´ç¨³å®šçš„ä»£ç†èŠ‚ç‚¹", file=sys.stderr)
        print("   3. å¢åŠ é‡è¯•æ¬¡æ•°å’Œç­‰å¾…æ—¶é—´", file=sys.stderr)
    
    print("=" * 50, file=sys.stderr)

def configure_proxy_settings(args):
    """é…ç½®ä»£ç†è®¾ç½®"""
    if args.no_proxy:
        print("ğŸš« ç¦ç”¨æ‰€æœ‰ä»£ç†", file=sys.stderr)
        # æ¸…é™¤æ‰€æœ‰ä»£ç†ç¯å¢ƒå˜é‡
        proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY']
        for var in proxy_vars:
            if var in os.environ:
                del os.environ[var]
        
        # è®¾ç½®requestsçš„é»˜è®¤è¡Œä¸º
        os.environ['NO_PROXY'] = '*'
        
    elif args.proxy:
        print(f"ğŸ”„ ä½¿ç”¨æŒ‡å®šä»£ç†: {args.proxy}", file=sys.stderr)
        os.environ['HTTP_PROXY'] = args.proxy
        os.environ['HTTPS_PROXY'] = args.proxy
    else:
        print("ğŸ” ä½¿ç”¨å½“å‰ä»£ç†è®¾ç½®", file=sys.stderr)

def create_llm_with_proxy_handling(model_name):
    """åˆ›å»ºLLMå®ä¾‹ï¼Œå¤„ç†ä»£ç†ç›¸å…³é—®é¢˜"""
    try:
        # æ–¹å¼1ï¼šå°è¯•æ­£å¸¸è¿æ¥
        print(f"ğŸ”— å°è¯•æ­£å¸¸è¿æ¥æ¨¡å‹: {model_name}", file=sys.stderr)
        
        # é¦–å…ˆå°è¯•æ”¯æŒfunction callingçš„æ¨¡å‹
        try:
            llm = ChatOpenAI(
                model=model_name,
                temperature=0.7,
                request_timeout=30,  # å¢åŠ è¶…æ—¶æ—¶é—´
                max_retries=2,       # å‡å°‘é‡è¯•æ¬¡æ•°
            ).with_structured_output(Structure, method="function_calling")
            
            # å®é™…æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§
            print(f"ğŸ§ª æµ‹è¯•æ¨¡å‹ {model_name} function calling å¯ç”¨æ€§...", file=sys.stderr)
            test_prompt = ChatPromptTemplate.from_messages([
                ("system", "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œè¯·ç®€æ´å›å¤ã€‚"),
                ("human", "è¯·ç”¨ä¸­æ–‡å›å¤'æµ‹è¯•æˆåŠŸ'")
            ])
            test_chain = test_prompt | llm
            test_response = test_chain.invoke({})
            print(f"âœ… æ¨¡å‹ {model_name} (function calling) æµ‹è¯•æˆåŠŸ", file=sys.stderr)
            return llm, "function_calling"
            
        except Exception as fc_error:
            # å¦‚æœfunction callingå¤±è´¥ï¼Œå°è¯•JSONæ¨¡å¼
            if "tool use" in str(fc_error) or "function" in str(fc_error).lower():
                print(f"ğŸ’¡ æ¨¡å‹ {model_name} ä¸æ”¯æŒfunction callingï¼Œå°è¯•JSONæ¨¡å¼", file=sys.stderr)
                
                # åˆ›å»ºä¸å¸¦function callingçš„LLM
                llm = ChatOpenAI(
                    model=model_name,
                    temperature=0.7,
                    request_timeout=30,
                    max_retries=2,
                )
                
                # æµ‹è¯•åŸºæœ¬å¯ç”¨æ€§
                print(f"ğŸ§ª æµ‹è¯•æ¨¡å‹ {model_name} JSONæ¨¡å¼å¯ç”¨æ€§...", file=sys.stderr)
                test_prompt = ChatPromptTemplate.from_messages([
                    ("system", "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œè¯·ç®€æ´å›å¤ã€‚"),
                    ("human", "è¯·ç”¨ä¸­æ–‡å›å¤'æµ‹è¯•æˆåŠŸ'")
                ])
                test_chain = test_prompt | llm
                test_response = test_chain.invoke({})
                print(f"âœ… æ¨¡å‹ {model_name} (JSONæ¨¡å¼) æµ‹è¯•æˆåŠŸ", file=sys.stderr)
                return llm, "json_mode"
            else:
                raise fc_error
        
    except Exception as e:
        error_msg = str(e).lower()
        print(f"âŒ æ¨¡å‹ {model_name} è¿æ¥å¤±è´¥: {e}", file=sys.stderr)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯one-apiçš„æ¨¡å‹ä¸å¯ç”¨é”™è¯¯
        if "æ— å¯ç”¨æ¸ é“" in str(e) or "one_api_error" in str(e):
            print(f"ğŸ’¡ æ¨¡å‹ {model_name} åœ¨one-apiä¸­æœªé…ç½®ï¼Œå°†å°è¯•å…¶ä»–æ¨¡å‹", file=sys.stderr)
            raise e  # ç›´æ¥æŠ›å‡ºï¼Œä¸å°è¯•ä»£ç†å¤„ç†
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä»£ç†ç›¸å…³é”™è¯¯
        proxy_related_errors = [
            'proxy', 'timeout', 'connection', 'ssl', 'certificate', 
            '503', 'service unavailable', 'network', 'tunnel'
        ]
        
        if any(keyword in error_msg for keyword in proxy_related_errors):
            print("ğŸ” æ£€æµ‹åˆ°å¯èƒ½çš„ä»£ç†ç›¸å…³é—®é¢˜ï¼Œå°è¯•ä»£ç†è§£å†³æ–¹æ¡ˆ...", file=sys.stderr)
            
            # æ–¹å¼2ï¼šä¸´æ—¶ç¦ç”¨ä»£ç†é‡è¯•
            print("ğŸš« ä¸´æ—¶ç¦ç”¨ä»£ç†é‡è¯•", file=sys.stderr)
            original_proxies = {}
            proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']
            
            try:
                # ä¿å­˜åŸå§‹ä»£ç†è®¾ç½®
                for var in proxy_vars:
                    if var in os.environ:
                        original_proxies[var] = os.environ[var]
                        del os.environ[var]
                
                # è®¾ç½®NO_PROXY
                os.environ['NO_PROXY'] = '*'
                
                # å°è¯•function callingæ¨¡å¼
                try:
                    llm = ChatOpenAI(
                        model=model_name,
                        temperature=0.7,
                        request_timeout=60,
                    ).with_structured_output(Structure, method="function_calling")
                    
                    # å†æ¬¡æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§
                    print(f"ğŸ§ª ç¦ç”¨ä»£ç†åæµ‹è¯•æ¨¡å‹ {model_name} function calling å¯ç”¨æ€§...", file=sys.stderr)
                    test_prompt = ChatPromptTemplate.from_messages([
                        ("system", "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œè¯·ç®€æ´å›å¤ã€‚"),
                        ("human", "è¯·ç”¨ä¸­æ–‡å›å¤'æµ‹è¯•æˆåŠŸ'")
                    ])
                    test_chain = test_prompt | llm
                    test_response = test_chain.invoke({})
                    
                    print(f"âœ… ç¦ç”¨ä»£ç†åæ¨¡å‹ {model_name} (function calling) è¿æ¥æˆåŠŸ", file=sys.stderr)
                    return llm, "function_calling"
                    
                except Exception as fc_error2:
                    if "tool use" in str(fc_error2) or "function" in str(fc_error2).lower():
                        print(f"ğŸ’¡ ç¦ç”¨ä»£ç†åæ¨¡å‹ {model_name} ä»ä¸æ”¯æŒfunction callingï¼Œä½¿ç”¨JSONæ¨¡å¼", file=sys.stderr)
                        
                        llm = ChatOpenAI(
                            model=model_name,
                            temperature=0.7,
                            request_timeout=60,
                        )
                        
                        print(f"âœ… ç¦ç”¨ä»£ç†åæ¨¡å‹ {model_name} (JSONæ¨¡å¼) è¿æ¥æˆåŠŸ", file=sys.stderr)
                        return llm, "json_mode"
                    else:
                        raise fc_error2
                
            except Exception as e2:
                print(f"âŒ ç¦ç”¨ä»£ç†åä»ç„¶å¤±è´¥: {e2}", file=sys.stderr)
                
                # æ¢å¤åŸå§‹ä»£ç†è®¾ç½®
                for var, value in original_proxies.items():
                    os.environ[var] = value
                if 'NO_PROXY' in os.environ:
                    del os.environ['NO_PROXY']
                
                raise e  # æŠ›å‡ºåŸå§‹é”™è¯¯
        else:
            raise e

def check_windows_proxy():
    """æ£€æŸ¥Windowsç³»ç»Ÿä»£ç†è®¾ç½®"""
    try:
        # è®¿é—®æ³¨å†Œè¡¨è·å–ä»£ç†è®¾ç½®
        reg_key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, 
                                r"Software\Microsoft\Windows\CurrentVersion\Internet Settings")
        
        proxy_enable = winreg.QueryValueEx(reg_key, "ProxyEnable")[0]
        if proxy_enable:
            proxy_server = winreg.QueryValueEx(reg_key, "ProxyServer")[0]
            print(f"ğŸ” æ£€æµ‹åˆ°Windowsç³»ç»Ÿä»£ç†: {proxy_server}", file=sys.stderr)
            return proxy_server
        else:
            print("ğŸ” Windowsç³»ç»Ÿä»£ç†: æœªå¯ç”¨", file=sys.stderr)
            return None
            
    except Exception as e:
        print(f"ğŸ” æ— æ³•æ£€æŸ¥Windowsä»£ç†è®¾ç½®: {e}", file=sys.stderr)
        return None
    finally:
        try:
            winreg.CloseKey(reg_key)
        except:
            pass

def disable_system_proxy():
    """ä¸´æ—¶ç¦ç”¨ç³»ç»Ÿä»£ç†"""
    try:
        # ä¿å­˜åŸå§‹è®¾ç½®
        reg_key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, 
                                r"Software\Microsoft\Windows\CurrentVersion\Internet Settings",
                                0, winreg.KEY_ALL_ACCESS)
        
        original_enable = winreg.QueryValueEx(reg_key, "ProxyEnable")[0]
        
        # ç¦ç”¨ä»£ç†
        winreg.SetValueEx(reg_key, "ProxyEnable", 0, winreg.REG_DWORD, 0)
        winreg.CloseKey(reg_key)
        
        print("ğŸš« å·²ä¸´æ—¶ç¦ç”¨Windowsç³»ç»Ÿä»£ç†", file=sys.stderr)
        return original_enable
        
    except Exception as e:
        print(f"âŒ æ— æ³•ç¦ç”¨ç³»ç»Ÿä»£ç†: {e}", file=sys.stderr)
        return None

def restore_system_proxy(original_enable):
    """æ¢å¤åŸå§‹ä»£ç†è®¾ç½®"""
    try:
        if original_enable is not None:
            reg_key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, 
                                    r"Software\Microsoft\Windows\CurrentVersion\Internet Settings",
                                    0, winreg.KEY_ALL_ACCESS)
            
            winreg.SetValueEx(reg_key, "ProxyEnable", 0, winreg.REG_DWORD, original_enable)
            winreg.CloseKey(reg_key)
            
            print("ğŸ”„ å·²æ¢å¤Windowsç³»ç»Ÿä»£ç†è®¾ç½®", file=sys.stderr)
            
    except Exception as e:
        print(f"âŒ æ— æ³•æ¢å¤ç³»ç»Ÿä»£ç†: {e}", file=sys.stderr)

def main():
    args = parse_args()
    
    # å¦‚æœç”¨æˆ·è¯·æ±‚ç½‘ç»œæµ‹è¯•
    if args.test_network:
        test_network_connection()
        return
    
    # é…ç½®ä»£ç†è®¾ç½®
    configure_proxy_settings(args)
    
    # ä¼˜å…ˆä½¿ç”¨ä»£ç†æœåŠ¡æ”¯æŒçš„æ¨¡å‹
    model_name = os.environ.get("MODEL_NAME", 'deepseek/deepseek-r1:free')  # é»˜è®¤ä½¿ç”¨å…è´¹æ¨¡å‹
    language = os.environ.get("LANGUAGE", 'Chinese')

    # å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼Œå…è´¹å’Œä»£ç†æœåŠ¡å‹å¥½çš„æ¨¡å‹åœ¨å‰ï¼‰
    available_models = [
        'deepseek/deepseek-r1:free', 
        'qwq-32b:free',
        'deepseek-chat', 
        'gpt-3.5-turbo', 
        'gpt-4', 
        'gemini-2.0-flash-001'
    ]
    
    print(f"ğŸ¯ ç›®æ ‡æ¨¡å‹: {model_name}", file=sys.stderr)
    print(f"ğŸ”„ å¤‡ç”¨æ¨¡å‹: {available_models}", file=sys.stderr)

    # ä¿®å¤è·¯å¾„å¤„ç†
    if args.data.startswith('..'):
        # å¦‚æœæ˜¯ç›¸å¯¹äºå½“å‰ç›®å½•çš„ä¸Šçº§ç›®å½•çš„è·¯å¾„
        args.data = os.path.abspath(os.path.join(current_dir, args.data))
    elif not os.path.isabs(args.data):
        # å¦‚æœæ˜¯ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
        args.data = os.path.join(root_dir, args.data)

    if not os.path.exists(args.data):
        raise ValueError(f"Data file not found: {args.data}")

    print(f"ğŸ“– è¯»å–æ•°æ®: {args.data}", file=sys.stderr)
    
    data = []
    with open(args.data, "r") as f:
        for line in f:
            data.append(json.loads(line))

    seen_ids = set()
    unique_data = []
    for item in data:
        if item['id'] not in seen_ids:
            seen_ids.add(item['id'])
            unique_data.append(item)

    data = unique_data

    print(f'ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ: {len(data)} ç¯‡è®ºæ–‡', file=sys.stderr)

    # å°è¯•è¿æ¥æ¨¡å‹ï¼Œä½¿ç”¨ä»£ç†å¤„ç†åŠŸèƒ½
    llm = None
    model_mode = None
    for model in [model_name] + [m for m in available_models if m != model_name]:
        try:
            llm, mode = create_llm_with_proxy_handling(model)
            model_name = model  # æ›´æ–°å®é™…ä½¿ç”¨çš„æ¨¡å‹å
            model_mode = mode
            print(f"ğŸš€ å°†ä½¿ç”¨æ¨¡å‹: {model_name} ({mode})", file=sys.stderr)
            break
        except Exception as e:
            error_msg = str(e)
            if "æ— å¯ç”¨æ¸ é“" in error_msg or "one_api_error" in error_msg:
                print(f'ğŸ”„ æ¨¡å‹ {model} åœ¨one-apiä¸­æœªé…ç½®ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹', file=sys.stderr)
            else:
                print(f'âŒ æ¨¡å‹ {model} æœ€ç»ˆè¿æ¥å¤±è´¥: {e}', file=sys.stderr)
            continue
    
    if llm is None:
        print("âŒ æ‰€æœ‰æ¨¡å‹éƒ½æ— æ³•è¿æ¥ï¼", file=sys.stderr)
        print("ğŸ’¡ é—®é¢˜è¯Šæ–­:", file=sys.stderr)
        print("   1. one-apiæœåŠ¡ä¸­å¯èƒ½æ²¡æœ‰é…ç½®ä»»ä½•å¯ç”¨çš„æ¨¡å‹æ¸ é“", file=sys.stderr)
        print("   2. è¯·æ£€æŸ¥one-apiç®¡ç†é¢æ¿ä¸­çš„æ¸ é“é…ç½®", file=sys.stderr)
        print("   3. ç¡®ä¿è‡³å°‘é…ç½®äº†å…è´¹æ¨¡å‹æˆ–å¸¸ç”¨æ¨¡å‹", file=sys.stderr)
        print("   4. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®", file=sys.stderr)
        raise RuntimeError("æ‰€æœ‰æ¨¡å‹éƒ½æ— æ³•è¿æ¥ï¼Œè¯·æ£€æŸ¥one-apié…ç½®")
    
    # æ ¹æ®æ¨¡å‹æ¨¡å¼åˆ›å»ºä¸åŒçš„å¤„ç†é“¾
    if model_mode == "function_calling":
        # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
        prompt_template = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system),
            HumanMessagePromptTemplate.from_template(template=template)
        ])
        chain = prompt_template | llm
        
    else:  # JSONæ¨¡å¼
        # åˆ›å»ºJSONæ ¼å¼çš„prompt
        json_system = system + """

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼Œç¡®ä¿è¾“å‡ºæ˜¯æœ‰æ•ˆçš„JSONï¼š
{{
    "tldr": "ç®€æ´çš„ä¸€å¥è¯æ€»ç»“",
    "motivation": "ç ”ç©¶åŠ¨æœºå’ŒèƒŒæ™¯",
    "method": "ä¸»è¦æ–¹æ³•å’ŒæŠ€æœ¯",
    "result": "å…³é”®ç»“æœå’Œå‘ç°",
    "conclusion": "ç»“è®ºå’Œæ„ä¹‰"
}}

åªè¾“å‡ºJSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"""
        
        prompt_template = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(json_system),
            HumanMessagePromptTemplate.from_template(template=template)
        ])
        chain = prompt_template | llm

    output_file = args.data.replace('.jsonl', f'_AI_enhanced_{language}.jsonl')
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}", file=sys.stderr)
    
    for idx, d in enumerate(data):
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                if model_mode == "function_calling":
                    # ç»“æ„åŒ–è¾“å‡ºæ¨¡å¼
                    response: Structure = chain.invoke({
                        "language": language,
                        "content": d['summary']
                    })
                    d['AI'] = response.model_dump()
                else:
                    # JSONæ¨¡å¼ - éœ€è¦è§£æJSON
                    response = chain.invoke({
                        "language": language,
                        "content": d['summary']
                    })
                    
                    # è§£æJSONå“åº”
                    try:
                        response_text = response.content if hasattr(response, 'content') else str(response)
                        # æå–JSONéƒ¨åˆ†
                        json_start = response_text.find('{')
                        json_end = response_text.rfind('}') + 1
                        if json_start != -1 and json_end != -1:
                            json_str = response_text[json_start:json_end]
                            parsed_response = json.loads(json_str)
                            
                            # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨
                            required_fields = ["tldr", "motivation", "method", "result", "conclusion"]
                            for field in required_fields:
                                if field not in parsed_response:
                                    parsed_response[field] = "ä¿¡æ¯ä¸å®Œæ•´"
                                    
                            d['AI'] = parsed_response
                        else:
                            raise ValueError("No valid JSON found in response")
                            
                    except (json.JSONDecodeError, ValueError) as json_error:
                        print(f"âš ï¸ JSONè§£æå¤±è´¥: {json_error}", file=sys.stderr)
                        d['AI'] = {
                            "tldr": f"AIå›å¤è§£æå¤±è´¥: {str(response)[:100]}...",
                            "motivation": "è§£æé”™è¯¯",
                            "method": "è§£æé”™è¯¯",
                            "result": "è§£æé”™è¯¯", 
                            "conclusion": "è¯·æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ ¼å¼"
                        }
                
                break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                
            except Exception as e:
                retry_count += 1
                error_msg = str(e)
                print(f"ğŸ“„ {d['id']} ç¬¬{retry_count}æ¬¡å°è¯•å¤±è´¥: {error_msg}", file=sys.stderr)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯one-apiæ¨¡å‹é…ç½®é”™è¯¯
                if "æ— å¯ç”¨æ¸ é“" in error_msg:
                    print(f"ğŸ’¡ æ£€æµ‹åˆ°æ¨¡å‹é…ç½®é—®é¢˜ï¼Œè·³è¿‡é‡è¯•", file=sys.stderr)
                    retry_count = max_retries  # ç›´æ¥è·³åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä»£ç†æˆ–ç½‘ç»œç›¸å…³é”™è¯¯
                network_errors = ["503", "timeout", "connection", "proxy", "ssl", "certificate", "network"]
                if any(keyword in error_msg.lower() for keyword in network_errors):
                    if retry_count < max_retries:
                        wait_time = retry_count * 3  # å¢åŠ ç­‰å¾…æ—¶é—´
                        print(f"ğŸ”„ ç½‘ç»œé—®é¢˜ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...", file=sys.stderr)
                        time.sleep(wait_time)
                        continue
                
                # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                if retry_count >= max_retries:
                    print(f"âŒ {d['id']} é‡è¯• {max_retries} æ¬¡åä»ç„¶å¤±è´¥", file=sys.stderr)
                    d['AI'] = {
                        "tldr": f"å¤„ç†é”™è¯¯: {str(e)}",
                        "motivation": "æ¨¡å‹å¤„ç†é”™è¯¯",
                        "method": "æ¨¡å‹å¤„ç†é”™è¯¯", 
                        "result": "æ¨¡å‹å¤„ç†é”™è¯¯",
                        "conclusion": "å»ºè®®æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–ç½‘ç»œè®¾ç½®"
                    }
        
        # ä½¿ç”¨è¿½åŠ æ¨¡å¼å†™å…¥æ–‡ä»¶ï¼Œè¿™æ ·å³ä½¿ä¸­é€”å‡ºé”™ä¹Ÿèƒ½ä¿å­˜å·²å¤„ç†çš„ç»“æœ
        with open(output_file, "a", encoding='utf-8') as f:
            f.write(json.dumps(d, ensure_ascii=False) + "\n")

        print(f"âœ… å®Œæˆ {idx+1}/{len(data)} (æ¨¡å‹: {model_name})", file=sys.stderr)

if __name__ == "__main__":
    main()