{
  "2505.23301": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 人体姿态估计",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "人体姿态估计",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于虚拟人类动画的质量评估，涉及三维人体动画的生成与主观/客观评价。该任务属于三维重建领域，具体聚焦于人体姿态与动作的建模与评估。虽然论文强调质量评估，但其核心数据和方法均围绕三维人体动画，因此选择'计算机视觉 → 三维重建 → 人体姿态估计'作为最合适的分类路径。",
      "keywords": [
        "虚拟人类动画",
        "质量评估",
        "主观评价",
        "客观评价",
        "三维重建",
        "人体姿态",
        "数据驱动方法"
      ],
      "methods": [
        "数据集构建",
        "用户主观评分收集",
        "线性回归预测",
        "深度学习基线对比"
      ],
      "problems": [
        "如何对非参数化三维虚拟人动画进行有效的质量评估",
        "如何利用主观评价数据训练客观自动评估模型",
        "现有方法在非参数化动画上的适用性不足"
      ]
    },
    "keywords": [
      "虚拟人类动画",
      "质量评估",
      "主观评价",
      "客观评价",
      "三维重建",
      "人体姿态",
      "数据驱动方法"
    ],
    "methods": [
      "数据集构建",
      "用户主观评分收集",
      "线性回归预测",
      "深度学习基线对比"
    ],
    "problems": [
      "如何对非参数化三维虚拟人动画进行有效的质量评估",
      "如何利用主观评价数据训练客观自动评估模型",
      "现有方法在非参数化动画上的适用性不足"
    ]
  },
  "2505.23447": {
    "classification_path": "计算机科学 → 数据可视化",
    "raw_result": {
      "root": "计算机科学",
      "level1": "数据可视化",
      "level2": null,
      "level3": null,
      "depth": 2,
      "confidence": 0.95,
      "reasoning": "论文主要关注于高维数据中缺失结构的可视化分析与质量度量方法，属于数据可视化领域。虽然涉及数据质量与缺失值处理，但核心贡献在于通过可视化和质量指标辅助理解和分析缺失结构，而非机器学习或人机交互等其他领域。标准领域词表中‘数据可视化’最为贴切，且无更细分的三级任务可选，因此分类深度为2。",
      "keywords": [
        "缺失数据",
        "数据可视化",
        "高维数据",
        "质量度量",
        "结构性缺失",
        "数据分析"
      ],
      "methods": [
        "缺失结构质量度量指标",
        "可视化分析方法",
        "案例研究"
      ],
      "problems": [
        "如何在高维数据中识别和分析结构性缺失模式？",
        "如何通过可视化和质量度量辅助理解数据缺失结构？",
        "如何支持大规模高维数据中缺失结构的高效可视化分析？"
      ]
    },
    "keywords": [
      "缺失数据",
      "数据可视化",
      "高维数据",
      "质量度量",
      "结构性缺失",
      "数据分析"
    ],
    "methods": [
      "缺失结构质量度量指标",
      "可视化分析方法",
      "案例研究"
    ],
    "problems": [
      "如何在高维数据中识别和分析结构性缺失模式？",
      "如何通过可视化和质量度量辅助理解数据缺失结构？",
      "如何支持大规模高维数据中缺失结构的高效可视化分析？"
    ]
  },
  "2505.23617": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文主要关注视频内容的高效表征与理解，提出了一种基于全景子目标轨迹的分词方法（TrajViT），用于提升长视频的Transformer模型效率和性能。论文的核心任务是视频内容的理解与表征优化，属于计算机视觉下的视频理解领域。虽然涉及tokenization和模型结构创新，但其主要贡献和实验均围绕视频理解任务展开，因此选择'计算机视觉 → 视频理解'作为最合适的分类路径。",
      "keywords": [
        "视频分词",
        "全景子目标轨迹",
        "视频理解",
        "Transformer",
        "TrajViT",
        "token reduction",
        "对比学习"
      ],
      "methods": [
        "基于全景子目标轨迹的视频分词",
        "TrajViT视频编码器",
        "对比学习训练",
        "token冗余减少",
        "语义一致性token生成"
      ],
      "problems": [
        "如何高效地对长视频进行分词以适配Transformer模型",
        "如何减少视频分词过程中的token冗余和计算开销",
        "如何在保持时序一致性的同时提升视频理解任务的性能"
      ]
    },
    "keywords": [
      "视频分词",
      "全景子目标轨迹",
      "视频理解",
      "Transformer",
      "TrajViT",
      "token reduction",
      "对比学习"
    ],
    "methods": [
      "基于全景子目标轨迹的视频分词",
      "TrajViT视频编码器",
      "对比学习训练",
      "token冗余减少",
      "语义一致性token生成"
    ],
    "problems": [
      "如何高效地对长视频进行分词以适配Transformer模型",
      "如何减少视频分词过程中的token冗余和计算开销",
      "如何在保持时序一致性的同时提升视频理解任务的性能"
    ]
  },
  "2505.23685": {
    "classification_path": "计算机科学 → 人机交互",
    "raw_result": {
      "root": "计算机科学",
      "level1": "人机交互",
      "level2": null,
      "level3": null,
      "depth": 2,
      "confidence": 0.95,
      "reasoning": "论文主要研究立体头戴显示器（HMD）中立体几何误差对用户距离感知的影响，并提出几何框架和实验平台来分析和校正这种误差。该研究聚焦于用户与虚拟环境的交互体验、感知误差及其校正，属于人机交互领域。虽然涉及三维视觉和感知，但核心问题是用户与系统的交互与感知，因此选择'人机交互'作为二级领域，未涉及标准三级任务。",
      "keywords": [
        "立体头戴显示器",
        "距离感知",
        "几何误差",
        "人机交互",
        "视觉反馈",
        "视差"
      ],
      "methods": [
        "几何建模",
        "实验平台搭建",
        "眼动追踪",
        "实时视觉反馈校准",
        "用户实验"
      ],
      "problems": [
        "立体显示系统中的几何误差如何影响用户的距离感知？",
        "如何通过几何框架预测和解释这些感知误差？",
        "能否通过实时视觉反馈动态校准用户的动作以补偿感知误差？"
      ]
    },
    "keywords": [
      "立体头戴显示器",
      "距离感知",
      "几何误差",
      "人机交互",
      "视觉反馈",
      "视差"
    ],
    "methods": [
      "几何建模",
      "实验平台搭建",
      "眼动追踪",
      "实时视觉反馈校准",
      "用户实验"
    ],
    "problems": [
      "立体显示系统中的几何误差如何影响用户的距离感知？",
      "如何通过几何框架预测和解释这些感知误差？",
      "能否通过实时视觉反馈动态校准用户的动作以补偿感知误差？"
    ]
  },
  "2505.22677": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 小目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "小目标检测",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "论文聚焦于提升小尺寸头部（tiny head）的检测与跟踪性能，提出了跨域检测损失、多尺度模块和小感受野检测机制，主要解决小目标检测中的精度与效率平衡问题。根据标准领域词表，'目标检测'是最合适的三级领域，'小目标检测'作为具体任务符合论文核心内容。",
      "keywords": [
        "小目标检测",
        "头部检测",
        "目标跟踪",
        "多尺度信息",
        "跨域检测损失",
        "小感受野",
        "CrowdHuman",
        "CroHD"
      ],
      "methods": [
        "跨域检测损失（cross-domain detection loss）",
        "多尺度模块（multi-scale module）",
        "小感受野检测机制（small receptive field detection mechanism）"
      ],
      "problems": [
        "如何在保证检测与跟踪性能的同时降低小目标检测的计算资源消耗",
        "如何提升在拥挤场景下对小尺寸头部的检测与跟踪准确率"
      ]
    },
    "keywords": [
      "小目标检测",
      "头部检测",
      "目标跟踪",
      "多尺度信息",
      "跨域检测损失",
      "小感受野",
      "CrowdHuman",
      "CroHD"
    ],
    "methods": [
      "跨域检测损失（cross-domain detection loss）",
      "多尺度模块（multi-scale module）",
      "小感受野检测机制（small receptive field detection mechanism）"
    ],
    "problems": [
      "如何在保证检测与跟踪性能的同时降低小目标检测的计算资源消耗",
      "如何提升在拥挤场景下对小尺寸头部的检测与跟踪准确率"
    ]
  },
  "2505.22704": {
    "classification_path": "计算机科学 → 大语言模型 → 代码生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "代码生成",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于利用大语言模型（LLMs）进行代码生成，并通过强化学习和程序分析反馈提升代码质量。虽然涉及强化学习，但核心任务是提升大语言模型在代码生成场景下的实际应用能力，因此选择“大语言模型”作为二级领域，'代码生成'为三级领域。四级领域暂无更细分标准任务，故为null。",
      "keywords": [
        "大语言模型",
        "代码生成",
        "程序分析",
        "强化学习",
        "代码质量",
        "安全性",
        "可维护性"
      ],
      "methods": [
        "强化学习框架（REAL）",
        "程序分析反馈",
        "自动化单元测试",
        "无监督/无参考监督"
      ],
      "problems": [
        "如何提升大语言模型生成代码的质量，特别是在安全性和可维护性方面",
        "如何实现无需人工注释和规则的可扩展代码质量监督",
        "如何同时保证代码的功能正确性与高质量"
      ]
    },
    "keywords": [
      "大语言模型",
      "代码生成",
      "程序分析",
      "强化学习",
      "代码质量",
      "安全性",
      "可维护性"
    ],
    "methods": [
      "强化学习框架（REAL）",
      "程序分析反馈",
      "自动化单元测试",
      "无监督/无参考监督"
    ],
    "problems": [
      "如何提升大语言模型生成代码的质量，特别是在安全性和可维护性方面",
      "如何实现无需人工注释和规则的可扩展代码质量监督",
      "如何同时保证代码的功能正确性与高质量"
    ]
  },
  "2505.23708": {
    "classification_path": "计算机科学 → 强化学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "强化学习",
      "level2": "多目标强化学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "论文提出了一种多目标强化学习框架，针对物理和机器人角色的自适应控制，核心创新在于通过多目标权重条件化策略高效实现行为调优和任务适应。虽然涉及机器人角色控制，但主要贡献和方法属于强化学习领域下的多目标强化学习，因此选择'强化学习 → 多目标强化学习'作为最合适的分类路径。",
      "keywords": [
        "多目标强化学习",
        "权重条件化策略",
        "机器人控制",
        "Pareto前沿",
        "自适应行为",
        "层次策略"
      ],
      "methods": [
        "多目标强化学习框架",
        "权重条件化策略训练",
        "Pareto前沿权重采样",
        "层次策略结构（高层动态权重选择）"
      ],
      "problems": [
        "如何减少多目标奖励权重调优的迭代成本和时间",
        "如何训练能适应不同奖励权重的单一策略以实现多样化行为",
        "如何提升机器人角色在现实世界中的适应性和任务泛化能力"
      ]
    },
    "keywords": [
      "多目标强化学习",
      "权重条件化策略",
      "机器人控制",
      "Pareto前沿",
      "自适应行为",
      "层次策略"
    ],
    "methods": [
      "多目标强化学习框架",
      "权重条件化策略训练",
      "Pareto前沿权重采样",
      "层次策略结构（高层动态权重选择）"
    ],
    "problems": [
      "如何减少多目标奖励权重调优的迭代成本和时间",
      "如何训练能适应不同奖励权重的单一策略以实现多样化行为",
      "如何提升机器人角色在现实世界中的适应性和任务泛化能力"
    ]
  },
  "2505.22701": {
    "classification_path": "计算机科学 → 计算机视觉 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文主要关注于稀缺数据（小样本）条件下的野生动物图像分类问题，提出了一种结合自适应DCT频域处理、ViT和ResNet的混合深度学习架构。其核心创新点在于针对小样本场景下的视觉表征与分类，因此最合适的分类路径为‘计算机科学 → 计算机视觉 → 小样本学习’。论文未聚焦于目标检测、分割或三维重建等具体任务，故level3设为null。",
      "keywords": [
        "小样本学习",
        "频域特征",
        "自适应DCT",
        "ViT",
        "ResNet",
        "稀缺数据",
        "野生动物分类",
        "特征融合",
        "贝叶斯线性分类器"
      ],
      "methods": [
        "自适应离散余弦变换（DCT）预处理模块",
        "ViT-B16主干网络",
        "ResNet50主干网络",
        "频域与空间域特征融合",
        "贝叶斯线性分类头"
      ],
      "problems": [
        "在稀缺标注样本条件下提升野生动物图像分类的准确率",
        "如何自适应地选择最优频域特征以增强深度模型的判别能力",
        "如何有效融合频域和空间域特征以提升小样本视觉任务表现"
      ]
    },
    "keywords": [
      "小样本学习",
      "频域特征",
      "自适应DCT",
      "ViT",
      "ResNet",
      "稀缺数据",
      "野生动物分类",
      "特征融合",
      "贝叶斯线性分类器"
    ],
    "methods": [
      "自适应离散余弦变换（DCT）预处理模块",
      "ViT-B16主干网络",
      "ResNet50主干网络",
      "频域与空间域特征融合",
      "贝叶斯线性分类头"
    ],
    "problems": [
      "在稀缺标注样本条件下提升野生动物图像分类的准确率",
      "如何自适应地选择最优频域特征以增强深度模型的判别能力",
      "如何有效融合频域和空间域特征以提升小样本视觉任务表现"
    ]
  },
  "2505.22752": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于基于大型语言模型对企业气候信息披露文本进行问答，核心任务是构建和评测一个开放的问答基准数据集，并比较RAG（检索增强生成）方法在该任务上的表现。其主要内容属于自然语言处理领域中的问答系统方向，未涉及更细致的具体任务（如多轮对话、代码生成等），因此分类到'自然语言处理 → 问答系统'最为合适。",
      "keywords": [
        "气候金融",
        "问答系统",
        "企业气候披露",
        "大型语言模型",
        "RAG",
        "检索增强生成",
        "可持续发展报告",
        "碳排放报告",
        "权重量化"
      ],
      "methods": [
        "开放问答基准构建",
        "RAG（检索增强生成）方法比较",
        "专家标注问答对",
        "权重量化（Weight Quantization）"
      ],
      "problems": [
        "如何利用大型语言模型对企业气候披露文本进行高质量问答？",
        "检索增强生成方法在气候金融问答中的性能瓶颈是什么？",
        "如何推动AI在气候领域应用中的透明碳排放报告？"
      ]
    },
    "keywords": [
      "气候金融",
      "问答系统",
      "企业气候披露",
      "大型语言模型",
      "RAG",
      "检索增强生成",
      "可持续发展报告",
      "碳排放报告",
      "权重量化"
    ],
    "methods": [
      "开放问答基准构建",
      "RAG（检索增强生成）方法比较",
      "专家标注问答对",
      "权重量化（Weight Quantization）"
    ],
    "problems": [
      "如何利用大型语言模型对企业气候披露文本进行高质量问答？",
      "检索增强生成方法在气候金融问答中的性能瓶颈是什么？",
      "如何推动AI在气候领域应用中的透明碳排放报告？"
    ]
  },
  "2505.23738": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究如何基于关键帧和扩散模型生成与音乐同步的动物舞蹈视频。其核心技术路线为视频生成，涉及关键帧插值、扩散模型合成中间帧、舞蹈动作的时序结构优化等。虽然涉及多模态（音乐、图像），但主要贡献和创新点集中在视觉内容生成，特别是利用扩散模型进行视频帧生成，因此归入'计算机视觉 → 生成模型 → 扩散模型'最为贴切。",
      "keywords": [
        "动物舞蹈生成",
        "关键帧",
        "扩散模型",
        "音乐同步",
        "舞蹈编排",
        "视频生成",
        "姿态对称"
      ],
      "methods": [
        "关键帧驱动的视频生成框架",
        "图优化求解关键帧结构",
        "自动节拍检测与舞蹈模式匹配",
        "姿态镜像生成",
        "视频扩散模型合成中间帧"
      ],
      "problems": [
        "如何基于少量关键帧生成与音乐同步且具备编舞意识的动物舞蹈视频？",
        "如何自动优化关键帧结构以匹配指定的舞蹈节奏和动作模式？",
        "如何生成对称且自然的动物舞蹈姿态？"
      ]
    },
    "keywords": [
      "动物舞蹈生成",
      "关键帧",
      "扩散模型",
      "音乐同步",
      "舞蹈编排",
      "视频生成",
      "姿态对称"
    ],
    "methods": [
      "关键帧驱动的视频生成框架",
      "图优化求解关键帧结构",
      "自动节拍检测与舞蹈模式匹配",
      "姿态镜像生成",
      "视频扩散模型合成中间帧"
    ],
    "problems": [
      "如何基于少量关键帧生成与音乐同步且具备编舞意识的动物舞蹈视频？",
      "如何自动优化关键帧结构以匹配指定的舞蹈节奏和动作模式？",
      "如何生成对称且自然的动物舞蹈姿态？"
    ]
  },
  "2505.22705": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文提出了HiDream-I1，一个高效的图像生成基础模型，核心创新为稀疏扩散Transformer结构，并以扩散模型为主要生成机制。论文聚焦于提升图像生成质量与效率，属于计算机视觉领域下的生成模型，具体任务为扩散模型。虽然涉及多模态（图文）和图像编辑，但主线为高效图像生成，因此选择'计算机视觉→生成模型→扩散模型'作为最合适的分类路径。",
      "keywords": [
        "图像生成",
        "扩散模型",
        "Transformer",
        "稀疏结构",
        "Mixture-of-Experts",
        "多模态",
        "指令编辑",
        "基础模型"
      ],
      "methods": [
        "稀疏Diffusion Transformer（DiT）结构",
        "动态Mixture-of-Experts架构",
        "双流解耦编码器",
        "单流多模态交互",
        "指令驱动图像编辑"
      ],
      "problems": [
        "如何在保证高质量图像生成的同时降低计算复杂度和推理延迟",
        "如何实现高效的多模态（图文）交互以提升生成能力",
        "如何支持灵活的图像生成与基于指令的图像编辑"
      ]
    },
    "keywords": [
      "图像生成",
      "扩散模型",
      "Transformer",
      "稀疏结构",
      "Mixture-of-Experts",
      "多模态",
      "指令编辑",
      "基础模型"
    ],
    "methods": [
      "稀疏Diffusion Transformer（DiT）结构",
      "动态Mixture-of-Experts架构",
      "双流解耦编码器",
      "单流多模态交互",
      "指令驱动图像编辑"
    ],
    "problems": [
      "如何在保证高质量图像生成的同时降低计算复杂度和推理延迟",
      "如何实现高效的多模态（图文）交互以提升生成能力",
      "如何支持灵活的图像生成与基于指令的图像编辑"
    ]
  },
  "2505.22757": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于语言模型的预训练目标（multi-token prediction），属于自然语言处理领域。其核心内容是改进生成式语言模型的训练方式（curriculum learning for multi-token prediction），并分析对下游生成任务和推理效率的影响。虽然论文涉及大语言模型，但其主要创新点和实验均围绕生成模型的预训练目标设计，因此选择'自然语言处理 → 生成模型'作为最合适的分类路径。",
      "keywords": [
        "多token预测",
        "语言模型",
        "课程学习",
        "预训练",
        "小型语言模型",
        "生成质量",
        "自推理解码"
      ],
      "methods": [
        "多token预测（MTP）",
        "课程学习策略",
        "前向课程",
        "反向课程",
        "多预测头"
      ],
      "problems": [
        "小型语言模型在多token预测预训练目标下表现不佳的问题",
        "如何通过课程学习策略提升小型语言模型对多token预测目标的适应能力",
        "不同课程学习策略对下游生成任务性能和推理效率的影响"
      ]
    },
    "keywords": [
      "多token预测",
      "语言模型",
      "课程学习",
      "预训练",
      "小型语言模型",
      "生成质量",
      "自推理解码"
    ],
    "methods": [
      "多token预测（MTP）",
      "课程学习策略",
      "前向课程",
      "反向课程",
      "多预测头"
    ],
    "problems": [
      "小型语言模型在多token预测预训练目标下表现不佳的问题",
      "如何通过课程学习策略提升小型语言模型对多token预测目标的适应能力",
      "不同课程学习策略对下游生成任务性能和推理效率的影响"
    ]
  },
  "2505.23740": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究图像矢量化任务，提出了一种基于逐层剥离（peeling）的自回归方法，利用视觉-语言模型和扩散模型实现高质量的图像分层与矢量化。论文核心方法为基于描述的编辑扩散模型，属于生成模型范畴，且明确采用了扩散模型进行图像内容的分层去除与重建。因此，最合适的分类路径为‘计算机科学 → 计算机视觉 → 生成模型 → 扩散模型’。",
      "keywords": [
        "图像矢量化",
        "分层矢量化",
        "扩散模型",
        "视觉-语言模型",
        "自回归剥离",
        "图层结构",
        "路径语义",
        "几何规则性",
        "视觉保真度"
      ],
      "methods": [
        "自回归剥离策略",
        "视觉-语言模型构建图层关系",
        "基于描述的扩散模型编辑",
        "局部注意力控制",
        "大规模分层剥离数据集"
      ],
      "problems": [
        "现有图像矢量化方法在遮挡区域处理不完整，导致形状碎片化、可编辑性差",
        "如何提升分层矢量化的质量与灵活性",
        "如何实现对遮挡关系的精确建模与分层内容的完整恢复"
      ]
    },
    "keywords": [
      "图像矢量化",
      "分层矢量化",
      "扩散模型",
      "视觉-语言模型",
      "自回归剥离",
      "图层结构",
      "路径语义",
      "几何规则性",
      "视觉保真度"
    ],
    "methods": [
      "自回归剥离策略",
      "视觉-语言模型构建图层关系",
      "基于描述的扩散模型编辑",
      "局部注意力控制",
      "大规模分层剥离数据集"
    ],
    "problems": [
      "现有图像矢量化方法在遮挡区域处理不完整，导致形状碎片化、可编辑性差",
      "如何提升分层矢量化的质量与灵活性",
      "如何实现对遮挡关系的精确建模与分层内容的完整恢复"
    ]
  },
  "2505.22762": {
    "classification_path": "计算机科学 → 医学图像 → 医学图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "医学图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于医学图像中的异常区域分割任务，提出了一种无需阈值的分割方法（MIAS-SAM），并在脑MRI、肝脏CT和视网膜OCT等多种医学影像数据集上进行了实验。其主要创新点和应用场景均属于医学图像分割，因此选择'医学图像'作为二级领域，'医学图像分割'作为三级领域。四级领域暂无更细致标准任务，设为null。",
      "keywords": [
        "医学图像分割",
        "异常检测",
        "无阈值分割",
        "SAM",
        "记忆库",
        "特征嵌入",
        "脑MRI",
        "肝脏CT",
        "视网膜OCT"
      ],
      "methods": [
        "基于补丁的记忆库",
        "SAM编码器特征提取",
        "特征嵌入比对",
        "重心引导分割",
        "无阈值异常分割"
      ],
      "problems": [
        "如何在医学图像中实现无需阈值的异常区域分割",
        "如何利用正常样本特征实现高效的异常检测与分割",
        "提升多模态医学影像中异常分割的准确性"
      ]
    },
    "keywords": [
      "医学图像分割",
      "异常检测",
      "无阈值分割",
      "SAM",
      "记忆库",
      "特征嵌入",
      "脑MRI",
      "肝脏CT",
      "视网膜OCT"
    ],
    "methods": [
      "基于补丁的记忆库",
      "SAM编码器特征提取",
      "特征嵌入比对",
      "重心引导分割",
      "无阈值异常分割"
    ],
    "problems": [
      "如何在医学图像中实现无需阈值的异常区域分割",
      "如何利用正常样本特征实现高效的异常检测与分割",
      "提升多模态医学影像中异常分割的准确性"
    ]
  },
  "2505.22759": {
    "classification_path": "计算机科学 → 语音与音频处理 → 语音识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "语音与音频处理",
      "level2": "语音识别",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要聚焦于构建和开源大规模语音基础模型（Speech Foundation Model），并在英文和意大利语上进行训练和评测。其核心任务是语音识别（Speech Recognition），且强调开放科学和可复现性。虽然涉及模型训练和数据集构建，但最贴切的标准领域为'语音与音频处理'下的'语音识别'，没有更细的具体任务，因此level3为null。",
      "keywords": [
        "开源语音基础模型",
        "FAMA",
        "语音识别",
        "英文",
        "意大利语",
        "开放科学",
        "大规模数据集",
        "可复现性"
      ],
      "methods": [
        "大规模开源语音数据训练",
        "模型开源",
        "数据集清洗与伪标签",
        "性能对比评测"
      ],
      "problems": [
        "现有语音基础模型闭源导致的可复现性和公平评测难题",
        "缺乏大规模开源语音基础模型和数据集",
        "如何在开放科学框架下实现高效、性能优良的语音识别模型"
      ]
    },
    "keywords": [
      "开源语音基础模型",
      "FAMA",
      "语音识别",
      "英文",
      "意大利语",
      "开放科学",
      "大规模数据集",
      "可复现性"
    ],
    "methods": [
      "大规模开源语音数据训练",
      "模型开源",
      "数据集清洗与伪标签",
      "性能对比评测"
    ],
    "problems": [
      "现有语音基础模型闭源导致的可复现性和公平评测难题",
      "缺乏大规模开源语音基础模型和数据集",
      "如何在开放科学框架下实现高效、性能优良的语音识别模型"
    ]
  },
  "2505.22792": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究如何通过扩散模型优化修辞性文本到图像的生成过程，提出了两层马尔可夫决策过程（MDP）扩散策略优化框架Rhet2Pix。论文聚焦于文本到图像生成任务，尤其是处理修辞性语言的语义映射，属于计算机视觉领域中的生成模型方向。由于其核心方法为扩散模型的创新应用，因此归类为‘计算机视觉 → 生成模型 → 扩散模型’最为贴切。",
      "keywords": [
        "修辞性文本到图像生成",
        "扩散模型",
        "多层马尔可夫决策过程",
        "策略优化",
        "语义对齐"
      ],
      "methods": [
        "两层MDP扩散模块",
        "多步策略优化",
        "子句分解与逐步生成",
        "奖励稀疏性缓解",
        "扩散去噪轨迹优化"
      ],
      "problems": [
        "现有文本到图像模型难以理解和生成修辞性语言的隐含语义图像",
        "模型过度依赖字面词嵌入，忽略修辞表达的真实语义",
        "如何通过生成模型有效捕捉和表达修辞性文本的深层语义"
      ]
    },
    "keywords": [
      "修辞性文本到图像生成",
      "扩散模型",
      "多层马尔可夫决策过程",
      "策略优化",
      "语义对齐"
    ],
    "methods": [
      "两层MDP扩散模块",
      "多步策略优化",
      "子句分解与逐步生成",
      "奖励稀疏性缓解",
      "扩散去噪轨迹优化"
    ],
    "problems": [
      "现有文本到图像模型难以理解和生成修辞性语言的隐含语义图像",
      "模型过度依赖字面词嵌入，忽略修辞表达的真实语义",
      "如何通过生成模型有效捕捉和表达修辞性文本的深层语义"
    ]
  },
  "2505.22765": {
    "classification_path": "计算机科学 → 语音与音频处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "语音与音频处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "本论文聚焦于语音语言模型（SLM）对句子重音（sentence stress）理解能力的评估与提升，核心任务是通过StressTest基准测试和Stress17k合成数据集，提升模型对语音中重音变化导致语义变化的推理能力。论文强调直接处理音频信号并进行语音推理（如spoken question answering），属于语音与音频处理领域。由于主要任务是基于语音的问答与推理，最贴切的三级领域为问答系统。四级领域暂无更细分标准任务，设为null。",
      "keywords": [
        "语音语言模型",
        "句子重音",
        "StressTest",
        "Stress17k",
        "语音推理",
        "spoken question answering",
        "音频理解"
      ],
      "methods": [
        "基准测试设计（StressTest）",
        "合成数据生成（Stress17k）",
        "模型微调（finetuning）",
        "实证评估"
      ],
      "problems": [
        "现有语音语言模型对句子重音导致的语义变化理解能力不足",
        "缺乏针对句子重音推理能力的评测基准",
        "如何通过合成数据提升模型对重音变化的推理与检测能力"
      ]
    },
    "keywords": [
      "语音语言模型",
      "句子重音",
      "StressTest",
      "Stress17k",
      "语音推理",
      "spoken question answering",
      "音频理解"
    ],
    "methods": [
      "基准测试设计（StressTest）",
      "合成数据生成（Stress17k）",
      "模型微调（finetuning）",
      "实证评估"
    ],
    "problems": [
      "现有语音语言模型对句子重音导致的语义变化理解能力不足",
      "缺乏针对句子重音推理能力的评测基准",
      "如何通过合成数据提升模型对重音变化的推理与检测能力"
    ]
  },
  "2505.22793": {
    "classification_path": "计算机科学 → 多模态学习 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于视觉-语言模型（VLMs）的文化能力评估，属于多模态学习领域。虽然论文涉及计算机视觉和自然语言处理，但其核心在于多模态模型的文化理解与评测框架。论文未聚焦于具体的视觉任务（如目标检测、图像分割等），而是探讨VLMs的文化分析方法，因此选择'多模态学习'作为二级领域。由于VLMs通常属于生成模型范畴，且论文讨论的是模型能力与评测框架，最贴近的三级领域为'生成模型'，四级领域暂无更细分具体任务，设为null。",
      "keywords": [
        "视觉-语言模型",
        "文化能力",
        "文化理论",
        "多模态学习",
        "评测框架",
        "视觉文化研究"
      ],
      "methods": [
        "文化理论方法引入",
        "视觉文化研究框架",
        "多维度文化评测框架提出"
      ],
      "problems": [
        "如何系统性地评估视觉-语言模型的文化能力？",
        "现有VLMs在文化细节理解上存在哪些不足？",
        "如何借鉴文化理论为VLMs的文化评测建立全面框架？"
      ]
    },
    "keywords": [
      "视觉-语言模型",
      "文化能力",
      "文化理论",
      "多模态学习",
      "评测框架",
      "视觉文化研究"
    ],
    "methods": [
      "文化理论方法引入",
      "视觉文化研究框架",
      "多维度文化评测框架提出"
    ],
    "problems": [
      "如何系统性地评估视觉-语言模型的文化能力？",
      "现有VLMs在文化细节理解上存在哪些不足？",
      "如何借鉴文化理论为VLMs的文化评测建立全面框架？"
    ]
  },
  "2505.22771": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究自动作文评分（Automated Essay Scoring, AES），属于自然语言处理领域。论文方法核心在于利用大语言模型（LLM）生成反馈注释，并将这些注释融入评分流程，提升评分准确性。虽然涉及分类任务，但整体流程以生成和利用文本注释为主，且未涉及问答、对话等具体任务，因此选择'生成模型'作为三级领域。四级领域暂无更具体标准任务可选，故为null。",
      "keywords": [
        "自动作文评分",
        "反馈注释",
        "大语言模型",
        "生成模型",
        "论证结构",
        "拼写纠错",
        "语法错误检测"
      ],
      "methods": [
        "集成反馈驱动注释",
        "利用生成式语言模型进行拼写纠错",
        "基于编码器的token分类器识别论证成分",
        "大语言模型微调为分类器"
      ],
      "problems": [
        "如何通过集成自动反馈注释提升自动作文评分系统的准确性？",
        "如何有效利用大语言模型生成的注释信息改进评分流程？"
      ]
    },
    "keywords": [
      "自动作文评分",
      "反馈注释",
      "大语言模型",
      "生成模型",
      "论证结构",
      "拼写纠错",
      "语法错误检测"
    ],
    "methods": [
      "集成反馈驱动注释",
      "利用生成式语言模型进行拼写纠错",
      "基于编码器的token分类器识别论证成分",
      "大语言模型微调为分类器"
    ],
    "problems": [
      "如何通过集成自动反馈注释提升自动作文评分系统的准确性？",
      "如何有效利用大语言模型生成的注释信息改进评分流程？"
    ]
  },
  "2505.22797": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于磁性粒子成像（MPI）数据的重建算法，属于医学成像领域。论文核心贡献是提出了一种新的基于模型的、与扫描轨迹无关的重建方法，并在真实2D医学成像数据上进行了验证。虽然涉及去噪和Plug-and-Play算法，但主要任务是医学成像数据的重建，最贴近标准领域词表中的‘医学图像’→‘三维重建’。",
      "keywords": [
        "磁性粒子成像",
        "模型重建",
        "Plug-and-Play",
        "去噪",
        "轨迹无关",
        "医学成像",
        "Chebyshev多项式"
      ],
      "methods": [
        "基于模型的重建算法",
        "零样本Plug-and-Play算法",
        "自动噪声水平估计",
        "利用自然图像训练的去噪器"
      ],
      "problems": [
        "如何实现无需特定扫描轨迹的通用磁性粒子成像重建",
        "如何在无需MPI专用数据训练的情况下提升重建质量",
        "如何高效解决医学成像中的去卷积问题"
      ]
    },
    "keywords": [
      "磁性粒子成像",
      "模型重建",
      "Plug-and-Play",
      "去噪",
      "轨迹无关",
      "医学成像",
      "Chebyshev多项式"
    ],
    "methods": [
      "基于模型的重建算法",
      "零样本Plug-and-Play算法",
      "自动噪声水平估计",
      "利用自然图像训练的去噪器"
    ],
    "problems": [
      "如何实现无需特定扫描轨迹的通用磁性粒子成像重建",
      "如何在无需MPI专用数据训练的情况下提升重建质量",
      "如何高效解决医学成像中的去卷积问题"
    ]
  },
  "2505.22774": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究语音与书面语在句法结构上的变异，采用依存句法树库对比分析不同语体的句法特征。虽然涉及语音和文本，但核心任务是基于树库的句法结构分析，属于自然语言处理范畴。论文关注口语与书面语的句法差异，尤其强调口语中与互动性、上下文相关的结构，这与对话系统中的语体建模和句法分析密切相关，因此选择'自然语言处理→对话系统'作为最合适的细分领域。由于标准三级领域未包含'句法分析'等更细任务，选择与口语/对话相关的'对话系统'，level3设为null。",
      "keywords": [
        "句法变异",
        "依存句法树库",
        "口语与书面语",
        "跨语言对比",
        "Universal Dependencies",
        "结构多样性",
        "语体分析"
      ],
      "methods": [
        "基于树库的句法结构提取",
        "去词化依存子树分析",
        "跨语体结构分布统计",
        "keyness分析"
      ],
      "problems": [
        "如何系统性比较不同语体（口语与书面语）中的句法结构变异？",
        "不同语言中口语与书面语的句法结构有何异同？",
        "哪些句法结构最能表征口语语体？",
        "如何构建可扩展、语言无关的句法变异分析框架？"
      ]
    },
    "keywords": [
      "句法变异",
      "依存句法树库",
      "口语与书面语",
      "跨语言对比",
      "Universal Dependencies",
      "结构多样性",
      "语体分析"
    ],
    "methods": [
      "基于树库的句法结构提取",
      "去词化依存子树分析",
      "跨语体结构分布统计",
      "keyness分析"
    ],
    "problems": [
      "如何系统性比较不同语体（口语与书面语）中的句法结构变异？",
      "不同语言中口语与书面语的句法结构有何异同？",
      "哪些句法结构最能表征口语语体？",
      "如何构建可扩展、语言无关的句法变异分析框架？"
    ]
  },
  "2505.22810": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了VidText基准，专注于视频中视觉文本的理解与评测，涵盖视频级、片段级和实例级任务，并涉及多模态推理。虽然涉及多模态内容，但核心任务是对视频中视觉文本的理解与评测，最符合'计算机视觉 → 视频理解'的分类。论文未聚焦于具体的下一级任务如动作识别或事件检测，因此level3设为null。",
      "keywords": [
        "视频文本理解",
        "多模态推理",
        "基准评测",
        "视觉文本",
        "视频理解",
        "OCR",
        "层次化评测",
        "跨模态推理"
      ],
      "methods": [
        "基准设计",
        "层次化评测框架",
        "多任务评测",
        "大规模多模态模型评测",
        "Chain-of-Thought推理分析"
      ],
      "problems": [
        "现有视频理解基准忽视视频中的文本信息",
        "OCR基准局限于静态图像，无法评估文本与动态视觉内容的交互",
        "缺乏针对视频文本理解的全面、多层次评测基准",
        "当前多模态模型在视频文本理解任务上表现有限"
      ]
    },
    "keywords": [
      "视频文本理解",
      "多模态推理",
      "基准评测",
      "视觉文本",
      "视频理解",
      "OCR",
      "层次化评测",
      "跨模态推理"
    ],
    "methods": [
      "基准设计",
      "层次化评测框架",
      "多任务评测",
      "大规模多模态模型评测",
      "Chain-of-Thought推理分析"
    ],
    "problems": [
      "现有视频理解基准忽视视频中的文本信息",
      "OCR基准局限于静态图像，无法评估文本与动态视觉内容的交互",
      "缺乏针对视频文本理解的全面、多层次评测基准",
      "当前多模态模型在视频文本理解任务上表现有限"
    ]
  },
  "2505.22777": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统 → 开放域对话评测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": "开放域对话评测",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于多语言开放域对话系统的评测与基准构建，核心内容为自动化生成和评估多语言对话数据，并分析大语言模型在对话评测中的表现。根据标准领域词表，'自然语言处理'下的'对话系统'最为贴切，具体任务为'开放域对话评测'，符合四级分类要求。",
      "keywords": [
        "多语言",
        "开放域对话",
        "大语言模型",
        "基准评测",
        "自动化评测",
        "对话生成",
        "对话质量评估"
      ],
      "methods": [
        "多智能体自动生成对话",
        "多维度性能分析",
        "大语言模型辅助评测",
        "人工标注质量判断",
        "跨语言性能对比"
      ],
      "problems": [
        "现有对话系统评测基准数据集静态、过时且缺乏多语言覆盖",
        "如何自动化生成和评测多语言开放域对话数据",
        "大语言模型在对话评测任务中的能力与局限性，尤其是对细粒度共情与推理问题的检测能力"
      ]
    },
    "keywords": [
      "多语言",
      "开放域对话",
      "大语言模型",
      "基准评测",
      "自动化评测",
      "对话生成",
      "对话质量评估"
    ],
    "methods": [
      "多智能体自动生成对话",
      "多维度性能分析",
      "大语言模型辅助评测",
      "人工标注质量判断",
      "跨语言性能对比"
    ],
    "problems": [
      "现有对话系统评测基准数据集静态、过时且缺乏多语言覆盖",
      "如何自动化生成和评测多语言开放域对话数据",
      "大语言模型在对话评测任务中的能力与局限性，尤其是对细粒度共情与推理问题的检测能力"
    ]
  },
  "2505.22815": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于不规则多变量时间序列（IMTS）的预测问题，提出了一种基于视觉Masked Autoencoder（MAE）的新方法，并强调了其在小样本场景下的优越性能。虽然方法借鉴了计算机视觉领域的技术，但核心任务是时间序列预测，属于机器学习范畴。论文还突出展示了模型在few-shot（小样本）场景下的能力，因此选择'机器学习 → 小样本学习'作为最合适的分类路径。",
      "keywords": [
        "不规则多变量时间序列",
        "时间序列预测",
        "视觉Masked Autoencoder",
        "小样本学习",
        "跨通道依赖",
        "自监督学习"
      ],
      "methods": [
        "视觉Masked Autoencoder（MAE）适配时间序列",
        "特征patch分割与重建",
        "跨通道补全",
        "粗到细预测策略",
        "自监督学习"
      ],
      "problems": [
        "如何在存在大量缺失值和不对齐的多通道信号下进行准确的时间序列预测",
        "如何将视觉领域的MAE模型有效迁移到不规则多变量时间序列任务",
        "如何提升模型在小样本场景下的泛化能力"
      ]
    },
    "keywords": [
      "不规则多变量时间序列",
      "时间序列预测",
      "视觉Masked Autoencoder",
      "小样本学习",
      "跨通道依赖",
      "自监督学习"
    ],
    "methods": [
      "视觉Masked Autoencoder（MAE）适配时间序列",
      "特征patch分割与重建",
      "跨通道补全",
      "粗到细预测策略",
      "自监督学习"
    ],
    "problems": [
      "如何在存在大量缺失值和不对齐的多通道信号下进行准确的时间序列预测",
      "如何将视觉领域的MAE模型有效迁移到不规则多变量时间序列任务",
      "如何提升模型在小样本场景下的泛化能力"
    ]
  },
  "2505.22787": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究大语言模型（LLMs）在医学系统综述自动化中的能力，核心任务是让模型根据给定文献回答与系统综述结论一致的问题，属于自然语言处理领域。具体任务是评估LLMs在复杂医学问答（即系统综述结论生成/匹配）中的表现，最贴近标准词表中的'问答系统'，而非'大语言模型'（因其为模型类型而非任务），也不属于'生成模型'或'对话系统'等其他三级领域。",
      "keywords": [
        "大语言模型",
        "系统综述",
        "医学问答",
        "自动化综述生成",
        "模型评测",
        "MedEvidence"
      ],
      "methods": [
        "基准数据集构建（MedEvidence）",
        "多模型系统性评测",
        "性能对比分析",
        "模型行为分析"
      ],
      "problems": [
        "大语言模型能否在医学系统综述任务中达到专家结论的一致性？",
        "不同类型和规模的LLM在系统综述自动化中的表现差异如何？",
        "现有LLM在处理长文档和低质量证据时存在哪些局限？"
      ]
    },
    "keywords": [
      "大语言模型",
      "系统综述",
      "医学问答",
      "自动化综述生成",
      "模型评测",
      "MedEvidence"
    ],
    "methods": [
      "基准数据集构建（MedEvidence）",
      "多模型系统性评测",
      "性能对比分析",
      "模型行为分析"
    ],
    "problems": [
      "大语言模型能否在医学系统综述任务中达到专家结论的一致性？",
      "不同类型和规模的LLM在系统综述自动化中的表现差异如何？",
      "现有LLM在处理长文档和低质量证据时存在哪些局限？"
    ]
  },
  "2505.22850": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 物体计数",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "物体计数",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于Referring Expression Counting（REC），即根据细粒度属性和上下文差异对图像中的目标进行计数。该任务属于计算机视觉领域下的目标检测分支，具体为物体计数任务。论文提出的C-REX方法是对现有目标检测和计数方法的改进，强调在图像空间内进行对比学习以提升区分能力，因此最合适的分类路径为‘计算机科学 → 计算机视觉 → 目标检测 → 物体计数’。",
      "keywords": [
        "Referring Expression Counting",
        "目标计数",
        "对比学习",
        "C-REX",
        "监督式对比学习",
        "图像空间",
        "负样本池",
        "目标检测",
        "物体中心点检测"
      ],
      "methods": [
        "基于监督式对比学习的C-REX框架",
        "在图像空间内进行对比学习",
        "扩大负样本池以增强表征鲁棒性",
        "基于目标中心点检测的检测基线设计"
      ],
      "problems": [
        "如何提升模型对细粒度属性和上下文差异的区分能力，实现更准确的Referring Expression Counting",
        "现有方法难以区分同类别但不同指代表达的视觉相似目标",
        "如何避免图像-文本对比学习中的对齐问题，提升对比信号稳定性",
        "如何设计通用且高效的目标计数方法，兼容类无关计数任务"
      ]
    },
    "keywords": [
      "Referring Expression Counting",
      "目标计数",
      "对比学习",
      "C-REX",
      "监督式对比学习",
      "图像空间",
      "负样本池",
      "目标检测",
      "物体中心点检测"
    ],
    "methods": [
      "基于监督式对比学习的C-REX框架",
      "在图像空间内进行对比学习",
      "扩大负样本池以增强表征鲁棒性",
      "基于目标中心点检测的检测基线设计"
    ],
    "problems": [
      "如何提升模型对细粒度属性和上下文差异的区分能力，实现更准确的Referring Expression Counting",
      "现有方法难以区分同类别但不同指代表达的视觉相似目标",
      "如何避免图像-文本对比学习中的对齐问题，提升对比信号稳定性",
      "如何设计通用且高效的目标计数方法，兼容类无关计数任务"
    ]
  },
  "2505.22801": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于Open Relation Extraction（开放关系抽取），属于自然语言处理领域。虽然标准词表中没有直接的'关系抽取'或'信息抽取'，但关系抽取是问答系统等下游任务的核心组成部分，且与问答系统密切相关。因此，选择'自然语言处理 → 问答系统'作为最贴切的分类路径。",
      "keywords": [
        "Open Relation Extraction",
        "关系抽取",
        "无监督学习",
        "已知关系",
        "新颖关系",
        "聚类",
        "分类",
        "MixORE"
      ],
      "methods": [
        "两阶段框架",
        "关系分类",
        "关系聚类",
        "联合学习",
        "MixORE方法"
      ],
      "problems": [
        "如何在未标注数据中同时识别已知和新颖关系实例",
        "如何提升开放关系抽取在混合已知与新颖关系场景下的泛化能力",
        "如何联合优化已知关系分类与新颖关系聚类"
      ]
    },
    "keywords": [
      "Open Relation Extraction",
      "关系抽取",
      "无监督学习",
      "已知关系",
      "新颖关系",
      "聚类",
      "分类",
      "MixORE"
    ],
    "methods": [
      "两阶段框架",
      "关系分类",
      "关系聚类",
      "联合学习",
      "MixORE方法"
    ],
    "problems": [
      "如何在未标注数据中同时识别已知和新颖关系实例",
      "如何提升开放关系抽取在混合已知与新颖关系场景下的泛化能力",
      "如何联合优化已知关系分类与新颖关系聚类"
    ]
  },
  "2505.22854": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 风格迁移",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "风格迁移",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于基于Gaussian Splatting的多模态风格迁移方法，支持2D图像、视频、3D对象和4D场景的风格化，属于计算机视觉领域。其核心任务是风格迁移，属于生成模型的具体应用，因此选择'计算机视觉 → 生成模型 → 风格迁移'作为分类路径。",
      "keywords": [
        "Gaussian Splatting",
        "风格迁移",
        "多模态",
        "CLIP",
        "3D重建",
        "视频风格化",
        "文本引导",
        "图像引导"
      ],
      "methods": [
        "基于Gaussian Splatting的风格迁移",
        "CLIP引导的多模态优化",
        "直接在高斯基元上操作",
        "无需大规模生成模型或重新训练",
        "联合优化颜色与几何",
        "时序一致性保持"
      ],
      "problems": [
        "如何在Gaussian Splatting表示下实现高质量的风格迁移，尤其是超越简单颜色变化的复杂风格化",
        "如何支持跨2D、3D、4D等多模态的统一风格迁移框架",
        "如何在不增加模型规模的前提下实现高效、可插拔的风格迁移",
        "如何在视频和动态场景中保持风格迁移的时序一致性"
      ]
    },
    "keywords": [
      "Gaussian Splatting",
      "风格迁移",
      "多模态",
      "CLIP",
      "3D重建",
      "视频风格化",
      "文本引导",
      "图像引导"
    ],
    "methods": [
      "基于Gaussian Splatting的风格迁移",
      "CLIP引导的多模态优化",
      "直接在高斯基元上操作",
      "无需大规模生成模型或重新训练",
      "联合优化颜色与几何",
      "时序一致性保持"
    ],
    "problems": [
      "如何在Gaussian Splatting表示下实现高质量的风格迁移，尤其是超越简单颜色变化的复杂风格化",
      "如何支持跨2D、3D、4D等多模态的统一风格迁移框架",
      "如何在不增加模型规模的前提下实现高效、可插拔的风格迁移",
      "如何在视频和动态场景中保持风格迁移的时序一致性"
    ]
  },
  "2505.22809": {
    "classification_path": "计算机科学 → 多模态学习 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究多模态（音频-语言）大模型在‘overhearing agents’场景下的应用，聚焦于模型如何通过监听人类对话（而非直接参与）来辅助任务，属于多模态学习范畴。其核心任务是对话系统的创新交互范式（overhearing agents），但并未聚焦于具体的下游任务如问答或目标检测，因此level3设为null。",
      "keywords": [
        "overhearing agents",
        "多模态大模型",
        "音频-语言模型",
        "对话系统",
        "Dungeons & Dragons",
        "人机交互",
        "隐式音频线索"
      ],
      "methods": [
        "多模态音频-语言模型",
        "人类评估",
        "案例研究（Dungeons & Dragons）",
        "Python工具库发布"
      ],
      "problems": [
        "如何设计和评估能够监听人类对话并在后台辅助的多模态LLM代理（overhearing agents）",
        "多模态大模型是否具备通过隐式音频线索完成overhearing agent任务的能力",
        "overhearing agents在实际复杂对话场景（如Dungeons & Dragons）中的有效性与潜力"
      ]
    },
    "keywords": [
      "overhearing agents",
      "多模态大模型",
      "音频-语言模型",
      "对话系统",
      "Dungeons & Dragons",
      "人机交互",
      "隐式音频线索"
    ],
    "methods": [
      "多模态音频-语言模型",
      "人类评估",
      "案例研究（Dungeons & Dragons）",
      "Python工具库发布"
    ],
    "problems": [
      "如何设计和评估能够监听人类对话并在后台辅助的多模态LLM代理（overhearing agents）",
      "多模态大模型是否具备通过隐式音频线索完成overhearing agent任务的能力",
      "overhearing agents在实际复杂对话场景（如Dungeons & Dragons）中的有效性与潜力"
    ]
  },
  "2505.22855": {
    "classification_path": "计算机科学 → 医学图像 → 医学图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "医学图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于数字病理学中的全景分割任务，提出了一种增量关系引导分割（IRS）方法，专门针对数字病理切片（WSIs）在时序和部分标注数据下的持续学习与分割问题。论文的主要应用场景和创新点均围绕医学图像分割展开，尤其是针对肾脏等结构的多尺度分割和新疾病类型的泛化能力。因此，最合适的分类路径为‘计算机科学 → 医学图像 → 医学图像分割’。",
      "keywords": [
        "持续学习",
        "数字病理学",
        "全景分割",
        "部分标注",
        "增量学习",
        "关系建模",
        "肾脏分割",
        "多尺度分割",
        "领域泛化"
      ],
      "methods": [
        "增量关系引导分割（IRS）",
        "空间-时间OOD持续学习",
        "增量通用命题矩阵建模解剖关系"
      ],
      "problems": [
        "如何在数字病理学中处理时序获取、部分标注的数据进行全景分割",
        "如何实现对新表型、未见疾病和多样人群的持续泛化分割",
        "如何提升医学图像分割模型的领域泛化和鲁棒性"
      ]
    },
    "keywords": [
      "持续学习",
      "数字病理学",
      "全景分割",
      "部分标注",
      "增量学习",
      "关系建模",
      "肾脏分割",
      "多尺度分割",
      "领域泛化"
    ],
    "methods": [
      "增量关系引导分割（IRS）",
      "空间-时间OOD持续学习",
      "增量通用命题矩阵建模解剖关系"
    ],
    "problems": [
      "如何在数字病理学中处理时序获取、部分标注的数据进行全景分割",
      "如何实现对新表型、未见疾病和多样人群的持续泛化分割",
      "如何提升医学图像分割模型的领域泛化和鲁棒性"
    ]
  },
  "2505.22823": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于提升大语言模型生成的自然语言解释的忠实性，属于自然语言处理领域。论文主要研究模型自我批判与迭代优化解释的框架，涉及模型对自身输出的后处理与解释改进。虽然论文与大语言模型相关，但其核心任务是提升模型解释的可信度，属于自然语言处理中的可解释性与问答系统相关任务。标准领域词表中，'问答系统'最贴合论文关注的自然语言解释生成与评估任务，因此选择该分类路径。",
      "keywords": [
        "自然语言解释",
        "大语言模型",
        "自我批判",
        "解释忠实性",
        "特征归因",
        "后处理"
      ],
      "methods": [
        "自我批判与迭代优化框架（SR-NLE）",
        "自然语言自反馈",
        "基于特征归因的反馈机制"
      ],
      "problems": [
        "如何提升大语言模型生成的自然语言解释的忠实性",
        "如何利用模型自身能力在无外部监督下优化解释",
        "如何设计有效的反馈机制指导解释后处理"
      ]
    },
    "keywords": [
      "自然语言解释",
      "大语言模型",
      "自我批判",
      "解释忠实性",
      "特征归因",
      "后处理"
    ],
    "methods": [
      "自我批判与迭代优化框架（SR-NLE）",
      "自然语言自反馈",
      "基于特征归因的反馈机制"
    ],
    "problems": [
      "如何提升大语言模型生成的自然语言解释的忠实性",
      "如何利用模型自身能力在无外部监督下优化解释",
      "如何设计有效的反馈机制指导解释后处理"
    ]
  },
  "2505.22858": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解 → 活动识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": "活动识别",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于开放世界下的第一视角（egocentric）活动识别问题，属于计算机视觉领域。其核心任务是从视频数据中识别和推断人类活动，尤其是在未见类别和大规模搜索空间下的识别，属于视频理解的典型应用。论文提出的方法和实验均围绕活动识别展开，因此四级分类选择'活动识别'最为贴切。",
      "keywords": [
        "开放世界",
        "第一视角",
        "活动识别",
        "跳跃扩散",
        "概率残差搜索",
        "视觉-语言模型",
        "常识先验"
      ],
      "methods": [
        "概率残差搜索框架（ProbRes）",
        "跳跃-扩散搜索机制",
        "结构化常识先验构建语义空间",
        "视觉-语言模型自适应预测",
        "随机搜索高似然标签"
      ],
      "problems": [
        "如何在开放世界环境下高效识别未见的第一视角活动",
        "如何在部分可观测和大规模搜索空间中平衡探索与利用",
        "如何利用常识先验和视觉-语言模型提升活动识别的泛化能力"
      ]
    },
    "keywords": [
      "开放世界",
      "第一视角",
      "活动识别",
      "跳跃扩散",
      "概率残差搜索",
      "视觉-语言模型",
      "常识先验"
    ],
    "methods": [
      "概率残差搜索框架（ProbRes）",
      "跳跃-扩散搜索机制",
      "结构化常识先验构建语义空间",
      "视觉-语言模型自适应预测",
      "随机搜索高似然标签"
    ],
    "problems": [
      "如何在开放世界环境下高效识别未见的第一视角活动",
      "如何在部分可观测和大规模搜索空间中平衡探索与利用",
      "如何利用常识先验和视觉-语言模型提升活动识别的泛化能力"
    ]
  },
  "2505.22830": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注大语言模型（LLMs）在生成阅读理解和推理类问答数据集（如CondaQA和DROP）时的有效性与挑战性，并对比了LLM生成与人工众包数据集的质量和难度。该研究核心属于自然语言处理领域，具体聚焦于问答系统的数据集构建与评测，因此选择'自然语言处理 → 问答系统'作为最合适的分类路径。由于标准词表中没有更细的任务（如'阅读理解'或'数据集构建'），level3设为null。",
      "keywords": [
        "大语言模型",
        "数据集生成",
        "阅读理解",
        "问答系统",
        "评测基准",
        "推理能力",
        "众包"
      ],
      "methods": [
        "大语言模型生成数据集",
        "与人工众包数据集对比分析",
        "案例研究",
        "有效性与难度评估"
      ],
      "problems": [
        "LLM生成的数据集在有效性和难度上是否能与人工众包数据集媲美？",
        "使用LLM生成评测基准时可能丧失了哪些关键特性？",
        "如何评估和提升LLM生成数据集的挑战性和针对性？"
      ]
    },
    "keywords": [
      "大语言模型",
      "数据集生成",
      "阅读理解",
      "问答系统",
      "评测基准",
      "推理能力",
      "众包"
    ],
    "methods": [
      "大语言模型生成数据集",
      "与人工众包数据集对比分析",
      "案例研究",
      "有效性与难度评估"
    ],
    "problems": [
      "LLM生成的数据集在有效性和难度上是否能与人工众包数据集媲美？",
      "使用LLM生成评测基准时可能丧失了哪些关键特性？",
      "如何评估和提升LLM生成数据集的挑战性和针对性？"
    ]
  },
  "2505.22859": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 非刚性三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "非刚性三维重建",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要关注于通过动态高斯曲面实现非刚性场景的4D跟踪与重建，涉及相机定位与非刚性表面重建的联合优化。其核心任务属于三维重建领域，具体聚焦于非刚性三维重建问题，因此选择'计算机视觉 → 三维重建 → 非刚性三维重建'作为最合适的分层分类路径。",
      "keywords": [
        "4D SLAM",
        "非刚性重建",
        "动态表面高斯",
        "相机定位",
        "可微渲染",
        "场景动态建模",
        "深度信号",
        "数据集"
      ],
      "methods": [
        "基于高斯曲面的SLAM方法",
        "多层感知机（MLP）表示的变形场",
        "可微渲染优化",
        "新型相机位姿估计技术",
        "表面正则化项",
        "合成数据集与评测协议"
      ],
      "problems": [
        "如何在动态非刚性场景下实现联合的相机定位与表面重建",
        "如何利用深度信号提升非刚性三维重建的准确性",
        "如何在缺乏真实4D数据集的情况下进行方法评估与验证"
      ]
    },
    "keywords": [
      "4D SLAM",
      "非刚性重建",
      "动态表面高斯",
      "相机定位",
      "可微渲染",
      "场景动态建模",
      "深度信号",
      "数据集"
    ],
    "methods": [
      "基于高斯曲面的SLAM方法",
      "多层感知机（MLP）表示的变形场",
      "可微渲染优化",
      "新型相机位姿估计技术",
      "表面正则化项",
      "合成数据集与评测协议"
    ],
    "problems": [
      "如何在动态非刚性场景下实现联合的相机定位与表面重建",
      "如何利用深度信号提升非刚性三维重建的准确性",
      "如何在缺乏真实4D数据集的情况下进行方法评估与验证"
    ]
  },
  "2505.22842": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于Transformer语言模型中的位置编码与上下文长度外推问题，属于自然语言处理领域。论文提出了一种新的贝叶斯注意力机制（BAM），用于改进生成模型（如Transformer）在长上下文下的泛化能力。虽然涉及概率建模和理论分析，但核心贡献在于提升自然语言生成模型的泛化能力，因此选择'自然语言处理→生成模型'作为最合适的分类路径。",
      "keywords": [
        "Transformer",
        "位置编码",
        "贝叶斯注意力机制",
        "上下文长度外推",
        "概率建模",
        "长上下文泛化"
      ],
      "methods": [
        "贝叶斯注意力机制（BAM）",
        "将位置编码建模为概率先验",
        "Generalized Gaussian positional prior",
        "统一NoPE和ALiBi等方法"
      ],
      "problems": [
        "现有位置编码方法理论基础不清晰，泛化能力有限",
        "如何实现Transformer模型在远超训练长度的上下文下准确的信息检索与生成",
        "如何以概率建模方式统一和改进现有位置编码方法"
      ]
    },
    "keywords": [
      "Transformer",
      "位置编码",
      "贝叶斯注意力机制",
      "上下文长度外推",
      "概率建模",
      "长上下文泛化"
    ],
    "methods": [
      "贝叶斯注意力机制（BAM）",
      "将位置编码建模为概率先验",
      "Generalized Gaussian positional prior",
      "统一NoPE和ALiBi等方法"
    ],
    "problems": [
      "现有位置编码方法理论基础不清晰，泛化能力有限",
      "如何实现Transformer模型在远超训练长度的上下文下准确的信息检索与生成",
      "如何以概率建模方式统一和改进现有位置编码方法"
    ]
  },
  "2505.22869": {
    "classification_path": "计算机科学 → 多模态学习 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文提出了一种基于扩散语言模型的蛋白质序列生成方法，能够融合多种模态（功能、序列、结构）约束，属于多模态学习范畴。其核心方法为扩散模型，应用于蛋白质的组合功能生成，因此选择'多模态学习 → 生成模型 → 扩散模型'作为最合适的分类路径。",
      "keywords": [
        "蛋白质生成",
        "多模态条件",
        "扩散模型",
        "功能蛋白设计",
        "序列-结构约束",
        "Annotation-Guided Feature Modulation",
        "Residue-Controlled Functional Encoding"
      ],
      "methods": [
        "扩散语言模型",
        "Annotation-Guided Feature Modulation (AGFM)",
        "Residue-Controlled Functional Encoding (RCFE)",
        "集成3D结构编码器"
      ],
      "problems": [
        "如何在蛋白质生成中同时满足多种模态（功能、序列、结构）约束",
        "如何通过可组合的功能注释实现蛋白质功能的精确控制",
        "如何提升多功能蛋白的生成成功率与多样性"
      ]
    },
    "keywords": [
      "蛋白质生成",
      "多模态条件",
      "扩散模型",
      "功能蛋白设计",
      "序列-结构约束",
      "Annotation-Guided Feature Modulation",
      "Residue-Controlled Functional Encoding"
    ],
    "methods": [
      "扩散语言模型",
      "Annotation-Guided Feature Modulation (AGFM)",
      "Residue-Controlled Functional Encoding (RCFE)",
      "集成3D结构编码器"
    ],
    "problems": [
      "如何在蛋白质生成中同时满足多种模态（功能、序列、结构）约束",
      "如何通过可组合的功能注释实现蛋白质功能的精确控制",
      "如何提升多功能蛋白的生成成功率与多样性"
    ]
  },
  "2505.22848": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于自然语言推理（NLI）任务中的解释性问题，提出了一种用于解释分类的语言学本体（LITEX），并在e-SNLI数据集上进行了注释和分析。自然语言推理属于自然语言处理领域，且与问答系统密切相关，因为NLI本质上是对文本对之间关系的理解与推断。标准领域词表中没有更细的NLI分类，因此选择'自然语言处理 → 问答系统'作为最贴切的路径。",
      "keywords": [
        "自然语言推理",
        "解释生成",
        "标签内变异",
        "本体分类",
        "e-SNLI",
        "人类标注差异",
        "自由文本解释"
      ],
      "methods": [
        "提出LITEX语言学本体",
        "对e-SNLI数据集进行本体注释",
        "注释一致性验证",
        "本体与标签/高亮/解释的对齐分析",
        "基于本体的解释生成实验"
      ],
      "problems": [
        "如何系统性理解自然语言推理任务中标签内变异现象（即同一标签下不同的推理理由）",
        "如何构建和验证用于解释分类的语言学本体",
        "如何提升模型生成的解释与人类解释的相似性"
      ]
    },
    "keywords": [
      "自然语言推理",
      "解释生成",
      "标签内变异",
      "本体分类",
      "e-SNLI",
      "人类标注差异",
      "自由文本解释"
    ],
    "methods": [
      "提出LITEX语言学本体",
      "对e-SNLI数据集进行本体注释",
      "注释一致性验证",
      "本体与标签/高亮/解释的对齐分析",
      "基于本体的解释生成实验"
    ],
    "problems": [
      "如何系统性理解自然语言推理任务中标签内变异现象（即同一标签下不同的推理理由）",
      "如何构建和验证用于解释分类的语言学本体",
      "如何提升模型生成的解释与人类解释的相似性"
    ]
  },
  "2505.22908": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于3D Gaussian Splatting（3DGS）的压缩方法，属于三维数据的高效表示与存储优化。3DGS主要应用于三维场景的重建与渲染，属于计算机视觉领域下的三维重建方向。论文提出的SHTC方法是针对3DGS的压缩优化，未涉及具体如人体姿态估计等更细分的三维重建任务，因此分类到'三维重建'层级最为合适。",
      "keywords": [
        "3D Gaussian Splatting",
        "压缩",
        "稀疏性",
        "分层变换编码",
        "KLT",
        "残差编码",
        "端到端优化",
        "率失真优化"
      ],
      "methods": [
        "Sparsity-guided Hierarchical Transform Coding (SHTC)",
        "端到端优化的分析-合成变换",
        "KLT（Karhunen-Loève变换）用于数据去相关",
        "稀疏编码增强层",
        "线性变换降维",
        "ISTA（迭代收缩-阈值算法）解码残差",
        "轻量级上下文建模"
      ],
      "problems": [
        "如何高效压缩3D Gaussian Splatting（3DGS）以降低存储和传输开销",
        "如何通过端到端优化的变换编码提升3DGS压缩的率失真性能",
        "如何在保证高效压缩的同时减少模型参数和计算开销"
      ]
    },
    "keywords": [
      "3D Gaussian Splatting",
      "压缩",
      "稀疏性",
      "分层变换编码",
      "KLT",
      "残差编码",
      "端到端优化",
      "率失真优化"
    ],
    "methods": [
      "Sparsity-guided Hierarchical Transform Coding (SHTC)",
      "端到端优化的分析-合成变换",
      "KLT（Karhunen-Loève变换）用于数据去相关",
      "稀疏编码增强层",
      "线性变换降维",
      "ISTA（迭代收缩-阈值算法）解码残差",
      "轻量级上下文建模"
    ],
    "problems": [
      "如何高效压缩3D Gaussian Splatting（3DGS）以降低存储和传输开销",
      "如何通过端到端优化的变换编码提升3DGS压缩的率失真性能",
      "如何在保证高效压缩的同时减少模型参数和计算开销"
    ]
  },
  "2505.22867": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于多语言新闻叙事分类任务，属于自然语言处理领域。其核心方法为基于大语言模型的分层提示（prompting），用于对新闻文本进行多级分类。虽然论文涉及大语言模型，但主要任务是文本的自动理解与分类，最贴近标准词表中的‘自然语言处理’。在三级领域中，‘问答系统’最接近该论文的多步推理与分类流程（即通过多轮prompting逐步细化分类），而其他三级领域如‘生成模型’、‘对话系统’等与该任务关联度较低，因此选择‘问答系统’。四级领域暂无更细致标准任务可选，设为null。",
      "keywords": [
        "多语言叙事分类",
        "分层提示",
        "大语言模型",
        "新闻文本分析",
        "SemEval"
      ],
      "methods": [
        "Hierarchical Three-Step Prompting (H3Prompt)",
        "大语言模型分步推理",
        "多级分类"
      ],
      "problems": [
        "如何对多语言新闻文本进行分层叙事分类",
        "如何利用大语言模型提升多级分类的准确性",
        "如何自动化识别和归类网络新闻中的主叙事与子叙事"
      ]
    },
    "keywords": [
      "多语言叙事分类",
      "分层提示",
      "大语言模型",
      "新闻文本分析",
      "SemEval"
    ],
    "methods": [
      "Hierarchical Three-Step Prompting (H3Prompt)",
      "大语言模型分步推理",
      "多级分类"
    ],
    "problems": [
      "如何对多语言新闻文本进行分层叙事分类",
      "如何利用大语言模型提升多级分类的准确性",
      "如何自动化识别和归类网络新闻中的主叙事与子叙事"
    ]
  },
  "2505.22911": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "小样本学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于材料识别任务，属于计算机视觉领域中的目标检测范畴。论文提出了基于图注意力网络的分层材料识别方法，并强调了模型在小样本学习场景下的泛化能力，因此选择'目标检测'作为三级领域，'小样本学习'作为四级领域最为贴切。",
      "keywords": [
        "材料识别",
        "分层分类",
        "图注意力网络",
        "小样本学习",
        "深度图像",
        "本地外观"
      ],
      "methods": [
        "基于图注意力网络的分层材料识别",
        "利用材料分类体系和多模态数据集",
        "深度图像增强",
        "小样本学习方法"
      ],
      "problems": [
        "如何从本地外观实现分层材料识别",
        "如何利用材料分类体系提升识别性能",
        "如何在小样本条件下快速学习新材料类别",
        "如何提升模型在真实复杂环境下的泛化能力"
      ]
    },
    "keywords": [
      "材料识别",
      "分层分类",
      "图注意力网络",
      "小样本学习",
      "深度图像",
      "本地外观"
    ],
    "methods": [
      "基于图注意力网络的分层材料识别",
      "利用材料分类体系和多模态数据集",
      "深度图像增强",
      "小样本学习方法"
    ],
    "problems": [
      "如何从本地外观实现分层材料识别",
      "如何利用材料分类体系提升识别性能",
      "如何在小样本条件下快速学习新材料类别",
      "如何提升模型在真实复杂环境下的泛化能力"
    ]
  },
  "2505.22888": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大规模推理模型（LRMs）在多语言环境下的推理能力，尤其关注模型在不同语言下生成推理过程（thinking trace）时的表现及其对答案准确率的影响。该研究属于自然语言处理领域，具体涉及多语言问答与推理能力的评估和提升，因此选择'自然语言处理'为二级领域，'问答系统'为三级领域。论文未聚焦于对话系统、生成模型等其他细分任务，最贴切的三级领域为'问答系统'。",
      "keywords": [
        "大规模推理模型",
        "多语言推理",
        "思维链",
        "推理过程可控性",
        "准确率权衡",
        "XReasoning基准"
      ],
      "methods": [
        "多语言推理基准评测（XReasoning）",
        "提示词干预（prompt-based intervention）",
        "小样本后训练（few-shot post-training）"
      ],
      "problems": [
        "当前大规模推理模型在多语言环境下推理能力有限，常回退到英文或产生碎片化推理",
        "强制模型用用户语言推理会提升可读性但降低答案准确率，存在可控性与准确率的权衡",
        "如何通过后训练等方法缓解多语言推理与准确率之间的矛盾"
      ]
    },
    "keywords": [
      "大规模推理模型",
      "多语言推理",
      "思维链",
      "推理过程可控性",
      "准确率权衡",
      "XReasoning基准"
    ],
    "methods": [
      "多语言推理基准评测（XReasoning）",
      "提示词干预（prompt-based intervention）",
      "小样本后训练（few-shot post-training）"
    ],
    "problems": [
      "当前大规模推理模型在多语言环境下推理能力有限，常回退到英文或产生碎片化推理",
      "强制模型用用户语言推理会提升可读性但降低答案准确率，存在可控性与准确率的权衡",
      "如何通过后训练等方法缓解多语言推理与准确率之间的矛盾"
    ]
  },
  "2505.22914": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文核心任务是基于多模态输入（点云、图像、文本）进行CAD三维模型重建，属于典型的三维重建问题。虽然方法涉及多模态学习和强化学习，但主要贡献和实验均聚焦于三维CAD重建任务，因此选择'计算机视觉 → 三维重建'作为最合适的分类路径。",
      "keywords": [
        "多模态",
        "CAD重建",
        "三维重建",
        "强化学习",
        "视觉语言模型",
        "大语言模型",
        "点云",
        "图像",
        "文本输入"
      ],
      "methods": [
        "多模态输入处理",
        "视觉语言模型",
        "两阶段训练（监督微调+在线强化学习微调）",
        "Group Relative Preference Optimization (GRPO)",
        "程序化反馈"
      ],
      "problems": [
        "如何利用多种输入模态（点云、图像、文本）提升CAD三维重建的通用性和鲁棒性",
        "如何通过在线强化学习优化CAD重建模型性能",
        "如何将大语言模型训练范式应用于三维CAD重建任务"
      ]
    },
    "keywords": [
      "多模态",
      "CAD重建",
      "三维重建",
      "强化学习",
      "视觉语言模型",
      "大语言模型",
      "点云",
      "图像",
      "文本输入"
    ],
    "methods": [
      "多模态输入处理",
      "视觉语言模型",
      "两阶段训练（监督微调+在线强化学习微调）",
      "Group Relative Preference Optimization (GRPO)",
      "程序化反馈"
    ],
    "problems": [
      "如何利用多种输入模态（点云、图像、文本）提升CAD三维重建的通用性和鲁棒性",
      "如何通过在线强化学习优化CAD重建模型性能",
      "如何将大语言模型训练范式应用于三维CAD重建任务"
    ]
  },
  "2505.22897": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文关注视觉-语言模型（VLMs）的社会偏见评估，核心是通过大规模视觉问答（VQA）基准测试VLMs在多模态输入下的社会偏见表现。虽然涉及视觉和语言，但研究重点是多模态模型的社会属性理解与问答能力，因此选择'多模态学习'为二级领域，'问答系统'为三级领域。四级领域暂无更细分标准任务，故为null。",
      "keywords": [
        "视觉-语言模型",
        "社会偏见",
        "多模态学习",
        "视觉问答",
        "刻板印象",
        "社会心理学",
        "模型评估"
      ],
      "methods": [
        "大规模视觉问答基准（VIGNETTE）",
        "社会心理学理论分析",
        "多维度偏见评估（事实性、感知、刻板印象、决策）",
        "定量与定性分析"
      ],
      "problems": [
        "如何系统性评估视觉-语言模型中的社会偏见？",
        "现有VLM偏见研究为何局限于狭窄场景，如何扩展到更复杂的社会刻板印象？",
        "VLMs如何在多模态输入下对身份、特质和能力做出带有偏见的推断？",
        "VLMs在社会语境下如何编码和再现社会层级与歧视模式？"
      ]
    },
    "keywords": [
      "视觉-语言模型",
      "社会偏见",
      "多模态学习",
      "视觉问答",
      "刻板印象",
      "社会心理学",
      "模型评估"
    ],
    "methods": [
      "大规模视觉问答基准（VIGNETTE）",
      "社会心理学理论分析",
      "多维度偏见评估（事实性、感知、刻板印象、决策）",
      "定量与定性分析"
    ],
    "problems": [
      "如何系统性评估视觉-语言模型中的社会偏见？",
      "现有VLM偏见研究为何局限于狭窄场景，如何扩展到更复杂的社会刻板印象？",
      "VLMs如何在多模态输入下对身份、特质和能力做出带有偏见的推断？",
      "VLMs在社会语境下如何编码和再现社会层级与歧视模式？"
    ]
  },
  "2505.22918": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于视觉生成任务，提出了一种针对Diffusion Transformers（扩散模型）中注意力机制的高稀疏性方法，旨在提升高分辨率图像和视频生成的效率。其主要创新点在于通过统计重塑注意力分布，实现极高稀疏度下的高质量视觉生成。根据标准领域词表，最合适的分类路径为‘计算机科学 → 计算机视觉 → 生成模型 → 扩散模型’。",
      "keywords": [
        "稀疏注意力",
        "视觉生成",
        "扩散模型",
        "Diffusion Transformers",
        "注意力机制",
        "高分辨率生成"
      ],
      "methods": [
        "Re-ttention（基于注意力统计重塑的超高稀疏注意力机制）",
        "利用扩散模型的时序冗余",
        "基于历史softmax分布调整注意力分数"
      ],
      "problems": [
        "如何在极高稀疏度下保持视觉生成质量",
        "如何降低扩散模型中注意力机制的计算复杂度和延迟",
        "现有稀疏注意力方法在高稀疏度下视觉质量下降的问题"
      ]
    },
    "keywords": [
      "稀疏注意力",
      "视觉生成",
      "扩散模型",
      "Diffusion Transformers",
      "注意力机制",
      "高分辨率生成"
    ],
    "methods": [
      "Re-ttention（基于注意力统计重塑的超高稀疏注意力机制）",
      "利用扩散模型的时序冗余",
      "基于历史softmax分布调整注意力分数"
    ],
    "problems": [
      "如何在极高稀疏度下保持视觉生成质量",
      "如何降低扩散模型中注意力机制的计算复杂度和延迟",
      "现有稀疏注意力方法在高稀疏度下视觉质量下降的问题"
    ]
  },
  "2505.22910": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究大语言模型（LLMs）在归因推理任务中的偏见评估，属于自然语言处理领域。虽然论文关注大语言模型，但其核心问题是模型如何在文本理解和推理中表现出归因偏见，这与自然语言处理中的问答系统、推理任务密切相关。标准词表中没有更细致的归因推理或偏见评估分类，'问答系统'最贴合论文中模型对事件归因的推理与回答任务，因此选择该路径。",
      "keywords": [
        "归因偏见",
        "大语言模型",
        "社会心理学",
        "归因理论",
        "公平性",
        "推理",
        "人口统计学",
        "偏见评估"
      ],
      "methods": [
        "认知理论驱动的偏见评估框架",
        "归因推理分析",
        "人口统计学分组实验"
      ],
      "problems": [
        "大语言模型在归因推理中是否存在人口统计学相关的偏见",
        "如何系统性评估和识别模型在归因任务中的推理差异",
        "归因偏见对模型公平性和社会影响的潜在风险"
      ]
    },
    "keywords": [
      "归因偏见",
      "大语言模型",
      "社会心理学",
      "归因理论",
      "公平性",
      "推理",
      "人口统计学",
      "偏见评估"
    ],
    "methods": [
      "认知理论驱动的偏见评估框架",
      "归因推理分析",
      "人口统计学分组实验"
    ],
    "problems": [
      "大语言模型在归因推理中是否存在人口统计学相关的偏见",
      "如何系统性评估和识别模型在归因任务中的推理差异",
      "归因偏见对模型公平性和社会影响的潜在风险"
    ]
  },
  "2505.22926": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要研究如何利用扩散模型（Diffusion Models）生成合成图像以增强蛋白质亚细胞定位的多标签分类任务。其核心方法为基于扩散模型的生成式数据增强，并与传统分类器（如ResNet）进行对比。虽然应用场景为生物医学图像，但研究重点在于生成模型（尤其是扩散模型）在计算机视觉任务中的应用，因此选择'计算机视觉 → 生成模型 → 扩散模型'作为最合适的分层分类。",
      "keywords": [
        "扩散模型",
        "合成数据增强",
        "蛋白质亚细胞定位",
        "多标签分类",
        "生物医学图像"
      ],
      "methods": [
        "简化的类条件去噪扩散概率模型（DDPM）",
        "Mix Loss混合训练策略",
        "Mix Representation混合训练策略",
        "ResNet骨干网络基线分类器"
      ],
      "problems": [
        "合成图像能否提升蛋白质亚细胞定位的多标签分类性能",
        "如何有效整合扩散模型生成的合成数据与真实数据以提升模型泛化能力",
        "生成式数据增强在生物医学图像分类中的实际效果与挑战"
      ]
    },
    "keywords": [
      "扩散模型",
      "合成数据增强",
      "蛋白质亚细胞定位",
      "多标签分类",
      "生物医学图像"
    ],
    "methods": [
      "简化的类条件去噪扩散概率模型（DDPM）",
      "Mix Loss混合训练策略",
      "Mix Representation混合训练策略",
      "ResNet骨干网络基线分类器"
    ],
    "problems": [
      "合成图像能否提升蛋白质亚细胞定位的多标签分类性能",
      "如何有效整合扩散模型生成的合成数据与真实数据以提升模型泛化能力",
      "生成式数据增强在生物医学图像分类中的实际效果与挑战"
    ]
  },
  "2505.22919": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了一个用于评估大语言模型在急诊室临床推理和决策任务中的基准数据集。论文核心关注点是基于临床文本的推理与问答任务，属于自然语言处理领域。虽然涉及大语言模型，但主要任务是临床场景下的问答与推理评测，最贴切的三级领域为'问答系统'，四级领域暂无更细致标准分类。",
      "keywords": [
        "大语言模型",
        "临床推理",
        "急诊室",
        "基准数据集",
        "问答系统",
        "医疗决策",
        "多阶段评测"
      ],
      "methods": [
        "基准数据集构建",
        "多阶段任务设计（分诊、初步评估、治疗选择、处置规划、最终诊断）",
        "临床推理过程结构化",
        "人工与模型推理对比评测"
      ],
      "problems": [
        "如何系统性评估大语言模型在急诊室临床推理和决策中的能力？",
        "现有医学问答基准无法覆盖真实临床推理流程，如何设计更贴近实际的评测任务？",
        "大语言模型生成的临床推理与真实医生推理之间存在哪些差距？"
      ]
    },
    "keywords": [
      "大语言模型",
      "临床推理",
      "急诊室",
      "基准数据集",
      "问答系统",
      "医疗决策",
      "多阶段评测"
    ],
    "methods": [
      "基准数据集构建",
      "多阶段任务设计（分诊、初步评估、治疗选择、处置规划、最终诊断）",
      "临床推理过程结构化",
      "人工与模型推理对比评测"
    ],
    "problems": [
      "如何系统性评估大语言模型在急诊室临床推理和决策中的能力？",
      "现有医学问答基准无法覆盖真实临床推理流程，如何设计更贴近实际的评测任务？",
      "大语言模型生成的临床推理与真实医生推理之间存在哪些差距？"
    ]
  },
  "2505.22938": {
    "classification_path": "计算机科学 → 计算机视觉",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": null,
      "level3": null,
      "depth": 2,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于图像处理中常用的中值滤波算法的高效实现，属于图像处理的基础方法。虽然标准词表中没有更细的'图像处理'或'图像滤波'等三级分类，但在现有词表下，'计算机视觉'是最贴切的二级领域。论文未涉及目标检测、图像分割等具体任务，因此后续层级设为null。",
      "keywords": [
        "中值滤波",
        "图像处理",
        "去噪",
        "高效算法",
        "任意核形状",
        "边缘保持"
      ],
      "methods": [
        "高效中值滤波算法",
        "支持任意比特深度与核形状",
        "避免方形核伪影"
      ],
      "problems": [
        "如何高效实现支持任意比特深度、任意核大小和形状的中值滤波",
        "解决传统中值滤波在核形状和效率上的局限性",
        "减少方形核带来的伪影和交叉阴影"
      ]
    },
    "keywords": [
      "中值滤波",
      "图像处理",
      "去噪",
      "高效算法",
      "任意核形状",
      "边缘保持"
    ],
    "methods": [
      "高效中值滤波算法",
      "支持任意比特深度与核形状",
      "避免方形核伪影"
    ],
    "problems": [
      "如何高效实现支持任意比特深度、任意核大小和形状的中值滤波",
      "解决传统中值滤波在核形状和效率上的局限性",
      "减少方形核带来的伪影和交叉阴影"
    ]
  },
  "2505.22921": {
    "classification_path": "计算机科学 → 大语言模型 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于提升大语言模型在长文本和多轮对话中的上下文保持能力，提出结构化记忆机制以增强语义信息的长期保留和检索。虽然涉及多项自然语言处理任务，但核心创新点和实验均围绕大语言模型的架构改进及其在对话和问答等场景下的表现，因此选择“大语言模型→对话系统”作为最合适的分类路径。",
      "keywords": [
        "大语言模型",
        "结构化记忆机制",
        "上下文表示",
        "长期依赖",
        "语义保持",
        "对话系统",
        "遗忘机制"
      ],
      "methods": [
        "显式记忆单元",
        "门控写入机制",
        "基于注意力的读取模块",
        "遗忘函数",
        "联合训练目标"
      ],
      "problems": [
        "提升大语言模型对长文本和多轮对话的上下文保持能力",
        "缓解传统语言模型在处理长期依赖时的上下文丢失和语义漂移问题",
        "优化记忆内容的动态更新与检索策略"
      ]
    },
    "keywords": [
      "大语言模型",
      "结构化记忆机制",
      "上下文表示",
      "长期依赖",
      "语义保持",
      "对话系统",
      "遗忘机制"
    ],
    "methods": [
      "显式记忆单元",
      "门控写入机制",
      "基于注意力的读取模块",
      "遗忘函数",
      "联合训练目标"
    ],
    "problems": [
      "提升大语言模型对长文本和多轮对话的上下文保持能力",
      "缓解传统语言模型在处理长期依赖时的上下文丢失和语义漂移问题",
      "优化记忆内容的动态更新与检索策略"
    ]
  },
  "2505.22944": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 视频生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "视频生成",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文提出了一种用于可控视频生成的统一框架，核心在于通过轨迹输入实现对视频中运动的精细控制。论文主要关注视频内容的生成与运动控制，属于计算机视觉领域下的生成模型分支，具体任务为视频生成。虽然涉及运动控制和局部变形，但本质任务是生成高质量、可控的视频序列，因此选择'计算机视觉→生成模型→视频生成'作为最合适的分层分类。",
      "keywords": [
        "可控视频生成",
        "运动控制",
        "轨迹输入",
        "生成模型",
        "视频运动操控",
        "运动注入器",
        "图像到视频"
      ],
      "methods": [
        "轨迹投影到潜空间",
        "轻量级运动注入器",
        "基于关键点的运动路径控制",
        "与预训练图像到视频生成模型结合"
      ],
      "problems": [
        "如何实现对视频生成过程中不同层次（摄像机、物体、局部）的运动进行统一且精细的控制？",
        "如何通过用户定义的轨迹输入提升视频生成的可控性和视觉质量？",
        "如何设计兼容多种主流视频生成骨干网络的运动控制方法？"
      ]
    },
    "keywords": [
      "可控视频生成",
      "运动控制",
      "轨迹输入",
      "生成模型",
      "视频运动操控",
      "运动注入器",
      "图像到视频"
    ],
    "methods": [
      "轨迹投影到潜空间",
      "轻量级运动注入器",
      "基于关键点的运动路径控制",
      "与预训练图像到视频生成模型结合"
    ],
    "problems": [
      "如何实现对视频生成过程中不同层次（摄像机、物体、局部）的运动进行统一且精细的控制？",
      "如何通过用户定义的轨迹输入提升视频生成的可控性和视觉质量？",
      "如何设计兼容多种主流视频生成骨干网络的运动控制方法？"
    ]
  },
  "2505.22934": {
    "classification_path": "计算机科学 → 大语言模型 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LMs）的模型合并问题，尤其是针对使用低秩适应（LoRA）微调后的模型。其核心贡献是提出一种新的模型合并方法（OSRM），以提升多任务模型的鲁棒性和性能。虽然涉及模型合并和参数高效微调，但主要研究对象和应用场景均为大语言模型，因此选择“大语言模型”作为二级领域。由于标准词表下没有更细的合适任务，且论文属于生成模型范畴，三级领域选择“生成模型”，四级领域暂无更具体任务，设为null。",
      "keywords": [
        "大语言模型",
        "模型合并",
        "LoRA",
        "低秩适应",
        "参数高效微调",
        "正交子空间",
        "多任务学习",
        "鲁棒性"
      ],
      "methods": [
        "Orthogonal Subspaces for Robust model Merging (OSRM)",
        "正交子空间约束",
        "模型参数与数据分布交互分析",
        "与现有合并算法集成"
      ],
      "problems": [
        "LoRA微调模型在模型合并时性能显著下降的问题",
        "模型参数与数据分布交互对合并效果的影响",
        "如何减少多任务模型合并中的任务间干扰",
        "提升合并后模型的鲁棒性与单任务性能"
      ]
    },
    "keywords": [
      "大语言模型",
      "模型合并",
      "LoRA",
      "低秩适应",
      "参数高效微调",
      "正交子空间",
      "多任务学习",
      "鲁棒性"
    ],
    "methods": [
      "Orthogonal Subspaces for Robust model Merging (OSRM)",
      "正交子空间约束",
      "模型参数与数据分布交互分析",
      "与现有合并算法集成"
    ],
    "problems": [
      "LoRA微调模型在模型合并时性能显著下降的问题",
      "模型参数与数据分布交互对合并效果的影响",
      "如何减少多任务模型合并中的任务间干扰",
      "提升合并后模型的鲁棒性与单任务性能"
    ]
  },
  "2505.22971": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 高动态范围成像",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "高动态范围成像",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于高动态范围（HDR）图像的生成，提出了一种新的迭代融合框架iHDR，能够处理任意数量的曝光输入。其核心任务是通过深度学习方法将多张低动态范围（LDR）图像融合为高质量的HDR图像，属于典型的计算机视觉领域下的生成模型应用。高动态范围成像是生成模型在图像领域的具体任务，因此选择'计算机视觉 → 生成模型 → 高动态范围成像'作为分类路径。",
      "keywords": [
        "高动态范围成像",
        "HDR",
        "图像融合",
        "多曝光",
        "深度学习",
        "去鬼影",
        "迭代融合"
      ],
      "methods": [
        "迭代HDR融合框架（iHDR）",
        "双输入HDR融合网络（DiHDR）",
        "基于物理的域映射网络（ToneNet）",
        "深度学习"
      ],
      "problems": [
        "现有HDR成像方法通常只能处理固定数量的输入，难以适应任意数量的曝光帧",
        "如何实现灵活且高质量的多曝光图像融合",
        "如何在动态场景下有效去除鬼影现象"
      ]
    },
    "keywords": [
      "高动态范围成像",
      "HDR",
      "图像融合",
      "多曝光",
      "深度学习",
      "去鬼影",
      "迭代融合"
    ],
    "methods": [
      "迭代HDR融合框架（iHDR）",
      "双输入HDR融合网络（DiHDR）",
      "基于物理的域映射网络（ToneNet）",
      "深度学习"
    ],
    "problems": [
      "现有HDR成像方法通常只能处理固定数量的输入，难以适应任意数量的曝光帧",
      "如何实现灵活且高质量的多曝光图像融合",
      "如何在动态场景下有效去除鬼影现象"
    ]
  },
  "2505.22937": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "论文聚焦于基于DistilBERT的问答系统在移动端CPU上的高效推理与优化，核心任务是自然语言处理中的问答系统。虽然涉及模型压缩与推理优化，但主要贡献和实验均围绕问答系统展开，因此选择'自然语言处理 → 问答系统'作为最合适的分类路径，未细分到更具体的四级任务。",
      "keywords": [
        "DistilBERT",
        "问答系统",
        "SQuAD",
        "模型压缩",
        "推理优化",
        "数据增强",
        "CPU部署",
        "实时应用"
      ],
      "methods": [
        "DistilBERT微调",
        "数据增强",
        "超参数优化",
        "推理效率评估",
        "基于CPU的部署"
      ],
      "problems": [
        "如何在资源受限的移动端CPU上高效部署问答系统？",
        "如何通过模型压缩和数据增强提升问答系统的推理效率与准确率？",
        "在保证准确率的前提下，如何优化Transformer模型以适应实时应用需求？"
      ]
    },
    "keywords": [
      "DistilBERT",
      "问答系统",
      "SQuAD",
      "模型压缩",
      "推理优化",
      "数据增强",
      "CPU部署",
      "实时应用"
    ],
    "methods": [
      "DistilBERT微调",
      "数据增强",
      "超参数优化",
      "推理效率评估",
      "基于CPU的部署"
    ],
    "problems": [
      "如何在资源受限的移动端CPU上高效部署问答系统？",
      "如何通过模型压缩和数据增强提升问答系统的推理效率与准确率？",
      "在保证准确率的前提下，如何优化Transformer模型以适应实时应用需求？"
    ]
  },
  "2505.22976": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 世界模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "世界模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于世界模型的空间一致性问题，提出了新的数据集和基准，主要用于评估和推动具备记忆能力的世界模型在空间一致性上的表现。世界模型属于生成模型的一个具体应用方向，尤其在视觉领域（如Minecraft环境下的视频生成与空间建模）有广泛应用。虽然涉及强化学习和规划，但核心贡献在于视觉世界模型的空间一致性生成与评测，因此归入计算机视觉→生成模型→世界模型。",
      "keywords": [
        "世界模型",
        "空间一致性",
        "记忆模块",
        "基准测试",
        "Minecraft",
        "视觉生成",
        "导航视频"
      ],
      "methods": [
        "数据集构建（基于Minecraft环境的导航视频采集）",
        "基准设计（空间一致性评测）",
        "记忆模块集成",
        "世界模型评测"
      ],
      "problems": [
        "如何设计具备空间一致性的世界模型",
        "如何通过记忆模块提升世界模型的长时空一致性",
        "缺乏专门用于空间一致性和记忆能力评测的数据集与基准",
        "现有基准忽视了长距离空间一致性需求"
      ]
    },
    "keywords": [
      "世界模型",
      "空间一致性",
      "记忆模块",
      "基准测试",
      "Minecraft",
      "视觉生成",
      "导航视频"
    ],
    "methods": [
      "数据集构建（基于Minecraft环境的导航视频采集）",
      "基准设计（空间一致性评测）",
      "记忆模块集成",
      "世界模型评测"
    ],
    "problems": [
      "如何设计具备空间一致性的世界模型",
      "如何通过记忆模块提升世界模型的长时空一致性",
      "缺乏专门用于空间一致性和记忆能力评测的数据集与基准",
      "现有基准忽视了长距离空间一致性需求"
    ]
  },
  "2505.22942": {
    "classification_path": "计算机科学 → 强化学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "强化学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究基于大语言模型（LLM）的Web智能体在企业级Web导航任务中的推理能力提升，核心方法为基于规则的强化学习（R1-style RL），以增强智能体的推理与规划能力。虽然涉及大语言模型，但论文的创新点和主要方法集中在强化学习框架下提升智能体的推理能力，并在Web问答/导航任务中验证，因此选择'强化学习'为二级领域，'问答系统'为三级领域。四级领域暂无更细分标准任务，设为null。",
      "keywords": [
        "大语言模型",
        "Web智能体",
        "强化学习",
        "推理能力",
        "Web导航",
        "企业应用"
      ],
      "methods": [
        "基于规则的R1-style强化学习",
        "结构化奖励函数",
        "无监督中间推理学习"
      ],
      "problems": [
        "提升LLM驱动Web智能体在动态Web环境下的推理与规划能力",
        "克服基于监督微调Web智能体泛化性和鲁棒性不足的问题",
        "无需大量专家标注或演示，提升Web导航任务的表现"
      ]
    },
    "keywords": [
      "大语言模型",
      "Web智能体",
      "强化学习",
      "推理能力",
      "Web导航",
      "企业应用"
    ],
    "methods": [
      "基于规则的R1-style强化学习",
      "结构化奖励函数",
      "无监督中间推理学习"
    ],
    "problems": [
      "提升LLM驱动Web智能体在动态Web环境下的推理与规划能力",
      "克服基于监督微调Web智能体泛化性和鲁棒性不足的问题",
      "无需大量专家标注或演示，提升Web导航任务的表现"
    ]
  },
  "2505.22977": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于基于扩散模型（DiT-based）的姿态引导人像动画生成，属于计算机视觉领域中的生成模型方向。具体方法为扩散模型在复杂人体动作动画中的应用，因此选择'扩散模型'作为第4级分类最为贴切。",
      "keywords": [
        "扩散模型",
        "人像动画",
        "姿态引导",
        "复杂动作",
        "视频生成",
        "数据集",
        "结构稳定性",
        "外观一致性"
      ],
      "methods": [
        "DiT-based视频生成基线",
        "空间低频增强RoPE模块",
        "可学习频率缩放",
        "高质量数据集与基准（Open-HyperMotionX Dataset, HyperMotionX Bench）"
      ],
      "problems": [
        "现有方法在复杂人体动作动画生成中的局限性",
        "缺乏高质量复杂人体动作动画评测基准",
        "提升复杂动态人体动作序列的结构稳定性与外观一致性"
      ]
    },
    "keywords": [
      "扩散模型",
      "人像动画",
      "姿态引导",
      "复杂动作",
      "视频生成",
      "数据集",
      "结构稳定性",
      "外观一致性"
    ],
    "methods": [
      "DiT-based视频生成基线",
      "空间低频增强RoPE模块",
      "可学习频率缩放",
      "高质量数据集与基准（Open-HyperMotionX Dataset, HyperMotionX Bench）"
    ],
    "problems": [
      "现有方法在复杂人体动作动画生成中的局限性",
      "缺乏高质量复杂人体动作动画评测基准",
      "提升复杂动态人体动作序列的结构稳定性与外观一致性"
    ]
  },
  "2505.22943": {
    "classification_path": "计算机科学 → 多模态学习 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注多模态预训练模型（如CLIP）的组合性脆弱性，并利用大语言模型生成对抗性文本样本进行攻击和评测。研究内容涉及多模态（文本、图像、视频、音频）表示的对抗性生成与评测，属于多模态学习领域。具体方法为利用生成模型（LLMs）生成对抗样本，因此归入'多模态学习 → 生成模型'最为贴切。论文未聚焦于具体的下游任务（如目标检测、问答等），因此level3设为null。",
      "keywords": [
        "多模态表示",
        "对抗性组合性",
        "CLIP",
        "大语言模型",
        "文本攻击",
        "样本多样性",
        "零样本学习"
      ],
      "methods": [
        "多模态对抗性基准（MAC）",
        "大语言模型生成对抗样本",
        "拒绝采样微调",
        "多样性过滤"
      ],
      "problems": [
        "多模态预训练模型（如CLIP）在组合性理解上的脆弱性",
        "如何利用大语言模型生成具有欺骗性的文本攻击多模态模型",
        "如何提升对抗样本的攻击成功率与多样性"
      ]
    },
    "keywords": [
      "多模态表示",
      "对抗性组合性",
      "CLIP",
      "大语言模型",
      "文本攻击",
      "样本多样性",
      "零样本学习"
    ],
    "methods": [
      "多模态对抗性基准（MAC）",
      "大语言模型生成对抗样本",
      "拒绝采样微调",
      "多样性过滤"
    ],
    "problems": [
      "多模态预训练模型（如CLIP）在组合性理解上的脆弱性",
      "如何利用大语言模型生成具有欺骗性的文本攻击多模态模型",
      "如何提升对抗样本的攻击成功率与多样性"
    ]
  },
  "2505.22978": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于无需精确相机位姿的3D高斯点云重建方法，核心任务是通过形状与射线估计实现高质量的三维场景重建，属于计算机视觉领域下的三维重建方向。论文未聚焦于人体、医学等特定应用，因此选择通用的“三维重建”作为三级分类，四级分类暂无更细致的标准任务可选，故为null。",
      "keywords": [
        "3D Gaussian splatting",
        "pose-free",
        "shape-ray estimation",
        "scene reconstruction",
        "multi-view"
      ],
      "methods": [
        "SHARE框架",
        "联合形状与相机射线估计",
        "基于锚点对齐的高斯预测",
        "构建姿态感知的规范体积表示"
      ],
      "problems": [
        "在缺乏精确相机位姿的情况下实现高质量的三维重建",
        "减少因相机位姿误差导致的几何失配",
        "提升三维高斯点云在真实场景中的泛化与鲁棒性"
      ]
    },
    "keywords": [
      "3D Gaussian splatting",
      "pose-free",
      "shape-ray estimation",
      "scene reconstruction",
      "multi-view"
    ],
    "methods": [
      "SHARE框架",
      "联合形状与相机射线估计",
      "基于锚点对齐的高斯预测",
      "构建姿态感知的规范体积表示"
    ],
    "problems": [
      "在缺乏精确相机位姿的情况下实现高质量的三维重建",
      "减少因相机位姿误差导致的几何失配",
      "提升三维高斯点云在真实场景中的泛化与鲁棒性"
    ]
  },
  "2505.22945": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要研究大语言模型在多语言和跨语言环境下对记忆文本的召回能力，采用了直接问答（如识别书名和作者）、填空（name cloze）、前缀生成等任务，这些任务本质上属于自然语言处理领域中的问答系统范畴。虽然涉及大语言模型，但论文核心是探究模型的跨语言理解与记忆能力，最贴切的标准分类为‘自然语言处理 → 问答系统’。",
      "keywords": [
        "大语言模型",
        "跨语言",
        "多语言",
        "记忆召回",
        "世界文学",
        "文本对齐",
        "问答",
        "填空",
        "前缀生成"
      ],
      "methods": [
        "多语言对齐数据集构建（OWL）",
        "直接问答（识别书名和作者）",
        "name cloze（实体填空）",
        "prefix probing（前缀生成）",
        "模型家族与规模对比",
        "扰动实验（如掩码、词序打乱）"
      ],
      "problems": [
        "大语言模型在多语言和跨语言环境下能否召回预训练中记忆的文本内容？",
        "模型对不同语言、不同翻译版本的记忆召回能力有何差异？",
        "文本扰动（如掩码、词序打乱）对模型记忆召回能力的影响如何？"
      ]
    },
    "keywords": [
      "大语言模型",
      "跨语言",
      "多语言",
      "记忆召回",
      "世界文学",
      "文本对齐",
      "问答",
      "填空",
      "前缀生成"
    ],
    "methods": [
      "多语言对齐数据集构建（OWL）",
      "直接问答（识别书名和作者）",
      "name cloze（实体填空）",
      "prefix probing（前缀生成）",
      "模型家族与规模对比",
      "扰动实验（如掩码、词序打乱）"
    ],
    "problems": [
      "大语言模型在多语言和跨语言环境下能否召回预训练中记忆的文本内容？",
      "模型对不同语言、不同翻译版本的记忆召回能力有何差异？",
      "文本扰动（如掩码、词序打乱）对模型记忆召回能力的影响如何？"
    ]
  },
  "2505.22980": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于基于文本条件的多目标视频生成，核心方法为无训练的扩散模型，并结合大语言模型进行运动轨迹控制。论文主要贡献在于提升现有视频扩散模型在多目标生成上的表现，属于计算机视觉领域下的生成模型，具体任务为扩散模型在视频生成中的应用。",
      "keywords": [
        "多目标视频生成",
        "文本条件生成",
        "扩散模型",
        "大语言模型",
        "注意力机制",
        "无训练方法"
      ],
      "methods": [
        "利用大语言模型指导对象轨迹",
        "噪声重新初始化实现运动控制",
        "注意力机制操控以分离对象特征",
        "无训练（training-free）生成流程"
      ],
      "problems": [
        "现有文本到视频扩散模型难以生成多个独立对象及其复杂交互",
        "对象特征混淆与运动受限",
        "如何在无需额外训练的情况下提升多目标视频生成的准确性与动态表现"
      ]
    },
    "keywords": [
      "多目标视频生成",
      "文本条件生成",
      "扩散模型",
      "大语言模型",
      "注意力机制",
      "无训练方法"
    ],
    "methods": [
      "利用大语言模型指导对象轨迹",
      "噪声重新初始化实现运动控制",
      "注意力机制操控以分离对象特征",
      "无训练（training-free）生成流程"
    ],
    "problems": [
      "现有文本到视频扩散模型难以生成多个独立对象及其复杂交互",
      "对象特征混淆与运动受限",
      "如何在无需额外训练的情况下提升多目标视频生成的准确性与动态表现"
    ]
  },
  "2505.22946": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 视觉问答",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "视觉问答",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究视觉语言模型（VLMs）在理解否定（negation）方面的能力，提出了一个新的视觉问答（VQA）基准NegVQA，并对多种VLM进行了评测。论文核心任务是多模态下的视觉问答，且聚焦于模型对否定语义的理解能力，因此最合适的分类路径为‘多模态学习 → 问答系统 → 视觉问答’。",
      "keywords": [
        "视觉语言模型",
        "否定理解",
        "视觉问答",
        "多模态学习",
        "基准评测",
        "模型泛化"
      ],
      "methods": [
        "基准数据集构建",
        "大语言模型生成否定问题",
        "多模型对比评测",
        "性能趋势分析"
      ],
      "problems": [
        "当前视觉语言模型在否定理解上的能力不足",
        "如何系统性评估VLMs对否定语义的理解能力",
        "模型规模与否定理解性能之间的关系"
      ]
    },
    "keywords": [
      "视觉语言模型",
      "否定理解",
      "视觉问答",
      "多模态学习",
      "基准评测",
      "模型泛化"
    ],
    "methods": [
      "基准数据集构建",
      "大语言模型生成否定问题",
      "多模型对比评测",
      "性能趋势分析"
    ],
    "problems": [
      "当前视觉语言模型在否定理解上的能力不足",
      "如何系统性评估VLMs对否定语义的理解能力",
      "模型规模与否定理解性能之间的关系"
    ]
  },
  "2505.23008": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 文档视觉问答",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "文档视觉问答",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于基于视觉和文本的文档问答任务（DocVQA），涉及视觉-语言模型（VLMs）在低资源语言（匈牙利语）上的应用与数据集构建。该任务属于多模态学习下的问答系统，具体为文档视觉问答（DocVQA），因此选择'多模态学习→问答系统→文档视觉问答'作为最合适的分层分类路径。",
      "keywords": [
        "文档视觉问答",
        "多模态学习",
        "匈牙利语",
        "低资源语言",
        "数据集构建",
        "视觉语言模型",
        "OCR"
      ],
      "methods": [
        "合成数据集生成（HuDocVQA）",
        "人工标注数据集（HuDocVQA-manual）",
        "数据质量过滤与去重",
        "PDF转录数据集（HuCCPDF）",
        "模型微调（Llama 3.2 11B Instruct）"
      ],
      "problems": [
        "如何在低资源语言（如匈牙利语）上构建高质量的文档视觉问答数据集？",
        "现有视觉语言模型在低资源语言DocVQA任务上的性能不足如何改进？",
        "如何通过合成与人工数据集提升多模态问答模型在低资源语言上的表现？"
      ]
    },
    "keywords": [
      "文档视觉问答",
      "多模态学习",
      "匈牙利语",
      "低资源语言",
      "数据集构建",
      "视觉语言模型",
      "OCR"
    ],
    "methods": [
      "合成数据集生成（HuDocVQA）",
      "人工标注数据集（HuDocVQA-manual）",
      "数据质量过滤与去重",
      "PDF转录数据集（HuCCPDF）",
      "模型微调（Llama 3.2 11B Instruct）"
    ],
    "problems": [
      "如何在低资源语言（如匈牙利语）上构建高质量的文档视觉问答数据集？",
      "现有视觉语言模型在低资源语言DocVQA任务上的性能不足如何改进？",
      "如何通过合成与人工数据集提升多模态问答模型在低资源语言上的表现？"
    ]
  },
  "2505.22950": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于长文档的抽取式摘要生成，属于自然语言处理领域。论文提出了一种基于结构化推理的提示框架（StrucSum），用于提升大语言模型在零样本摘要任务中的表现。虽然论文涉及大语言模型，但其核心任务是文档摘要生成，属于自然语言处理下的生成模型方向。标准词表中没有更细的摘要生成或文档摘要任务，因此选择'生成模型'作为第三级分类，第四级设为null。",
      "keywords": [
        "长文档摘要",
        "大语言模型",
        "结构化推理",
        "提示工程",
        "抽取式摘要",
        "图结构",
        "零样本学习"
      ],
      "methods": [
        "StrucSum框架",
        "邻居感知提示（Neighbor-Aware Prompting, NAP）",
        "中心性感知提示（Centrality-Aware Prompting, CAP）",
        "中心性引导掩码（Centrality-Guided Masking, CGM）"
      ],
      "problems": [
        "提升大语言模型在长文档抽取式摘要中的结构建模与关键信息识别能力",
        "在无需训练或任务特定微调的情况下提升摘要质量和事实一致性"
      ]
    },
    "keywords": [
      "长文档摘要",
      "大语言模型",
      "结构化推理",
      "提示工程",
      "抽取式摘要",
      "图结构",
      "零样本学习"
    ],
    "methods": [
      "StrucSum框架",
      "邻居感知提示（Neighbor-Aware Prompting, NAP）",
      "中心性感知提示（Centrality-Aware Prompting, CAP）",
      "中心性引导掩码（Centrality-Guided Masking, CGM）"
    ],
    "problems": [
      "提升大语言模型在长文档抽取式摘要中的结构建模与关键信息识别能力",
      "在无需训练或任务特定微调的情况下提升摘要质量和事实一致性"
    ]
  },
  "2505.23010": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 图像超分辨率",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "图像超分辨率",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于遥感图像的超分辨率重建任务，属于计算机视觉领域。其核心是利用视觉-语言模型提取语义知识，指导超分辨率生成过程。根据标准领域词表，‘生成模型’下的‘图像超分辨率’最贴合该论文的主要研究内容和任务，因此选择此分类路径。",
      "keywords": [
        "遥感图像",
        "超分辨率",
        "语义知识",
        "视觉-语言模型",
        "高分辨率重建"
      ],
      "methods": [
        "语义特征提取模块（SFEM）",
        "视觉-语言模型（VLM）",
        "语义定位模块（SLM）",
        "可学习调制模块（LMM）",
        "语义引导的超分辨率框架（SeG-SR）"
      ],
      "problems": [
        "现有遥感图像超分辨率方法忽略高层次语义理解，导致重建结果存在语义不一致伪影",
        "如何有效融合高层次语义知识提升遥感图像超分辨率性能"
      ]
    },
    "keywords": [
      "遥感图像",
      "超分辨率",
      "语义知识",
      "视觉-语言模型",
      "高分辨率重建"
    ],
    "methods": [
      "语义特征提取模块（SFEM）",
      "视觉-语言模型（VLM）",
      "语义定位模块（SLM）",
      "可学习调制模块（LMM）",
      "语义引导的超分辨率框架（SeG-SR）"
    ],
    "problems": [
      "现有遥感图像超分辨率方法忽略高层次语义理解，导致重建结果存在语义不一致伪影",
      "如何有效融合高层次语义知识提升遥感图像超分辨率性能"
    ]
  },
  "2505.22956": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于利用大语言模型（LLMs）在在线评论中进行论证挖掘，包括论点检测、抽取和关系分类。虽然直接的'论证挖掘'不在标准词表中，但其核心任务属于自然语言处理领域，且与问答系统等理解和抽取任务最为接近。其他三级领域如'生成模型'、'目标检测'等均不适用，因此选择'自然语言处理 → 问答系统'作为最贴近的分类路径。",
      "keywords": [
        "大语言模型",
        "论证挖掘",
        "在线评论",
        "论点检测",
        "关系分类",
        "情感分析"
      ],
      "methods": [
        "大语言模型评估",
        "多任务学习",
        "误差分析",
        "定量评估"
      ],
      "problems": [
        "大语言模型在主题相关、预定义论点挖掘中的表现如何？",
        "LLMs在处理长文本和情感化语言时存在哪些系统性不足？",
        "自动化论证分析在实际应用（如内容审核、观点分析）中的局限性和挑战是什么？"
      ]
    },
    "keywords": [
      "大语言模型",
      "论证挖掘",
      "在线评论",
      "论点检测",
      "关系分类",
      "情感分析"
    ],
    "methods": [
      "大语言模型评估",
      "多任务学习",
      "误差分析",
      "定量评估"
    ],
    "problems": [
      "大语言模型在主题相关、预定义论点挖掘中的表现如何？",
      "LLMs在处理长文本和情感化语言时存在哪些系统性不足？",
      "自动化论证分析在实际应用（如内容审核、观点分析）中的局限性和挑战是什么？"
    ]
  },
  "2505.23012": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解 → 动作识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": "动作识别",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于基于骨骼数据的人体动作识别任务，提出了时空关节密度驱动的自监督学习方法，并在多个动作识别数据集上进行了实验。骨骼动作识别属于计算机视觉领域下的视频理解分支中的具体任务，因此选择'计算机视觉 → 视频理解 → 动作识别'作为最合适的分层分类路径。",
      "keywords": [
        "骨骼动作识别",
        "时空关节密度",
        "自监督学习",
        "对比学习",
        "动作分类"
      ],
      "methods": [
        "时空关节密度(STJD)测量",
        "STJD-CL对比学习策略",
        "STJD-MP重建框架"
      ],
      "problems": [
        "如何利用骨骼序列中静态与动态关节的交互信息提升动作识别性能",
        "如何在自监督学习框架下有效挖掘骨骼动作序列的判别特征"
      ]
    },
    "keywords": [
      "骨骼动作识别",
      "时空关节密度",
      "自监督学习",
      "对比学习",
      "动作分类"
    ],
    "methods": [
      "时空关节密度(STJD)测量",
      "STJD-CL对比学习策略",
      "STJD-MP重建框架"
    ],
    "problems": [
      "如何利用骨骼序列中静态与动态关节的交互信息提升动作识别性能",
      "如何在自监督学习框架下有效挖掘骨骼动作序列的判别特征"
    ]
  },
  "2505.22959": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于基于大语言模型（LLM）的健康、安全与环境（HSE）合规性评估，核心任务是通过问答和推理能力评估模型在专业领域法规理解与推理的表现。论文提出了HSE-Bench数据集，包含大量基于法规、案例和实际场景的问题，并系统性评测了多种LLM的问答与推理能力。虽然涉及多模态和推理，但主线任务是基于文本的合规性问答与推理，因此最贴切的分类为‘自然语言处理 → 问答系统’。",
      "keywords": [
        "大语言模型",
        "HSE合规性",
        "问答系统",
        "法律推理",
        "基准数据集",
        "推理流程",
        "多模态模型",
        "专家推理"
      ],
      "methods": [
        "HSE-Bench基准数据集构建",
        "IRAC推理流程集成",
        "多种LLM评测（基础模型、推理模型、多模态模型）",
        "Reasoning of Expert (RoE)提示工程"
      ],
      "problems": [
        "当前大语言模型在HSE合规性评估中的推理能力和局限性",
        "如何系统性评测LLM在专业法规领域的问答与推理表现",
        "提升LLM在结构化法律推理和合规性决策中的准确性"
      ]
    },
    "keywords": [
      "大语言模型",
      "HSE合规性",
      "问答系统",
      "法律推理",
      "基准数据集",
      "推理流程",
      "多模态模型",
      "专家推理"
    ],
    "methods": [
      "HSE-Bench基准数据集构建",
      "IRAC推理流程集成",
      "多种LLM评测（基础模型、推理模型、多模态模型）",
      "Reasoning of Expert (RoE)提示工程"
    ],
    "problems": [
      "当前大语言模型在HSE合规性评估中的推理能力和局限性",
      "如何系统性评测LLM在专业法规领域的问答与推理表现",
      "提升LLM在结构化法律推理和合规性决策中的准确性"
    ]
  },
  "2505.23031": {
    "classification_path": "计算机科学 → 计算机视觉 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于细粒度视觉分类（Fine-Grained Visual Classification, FGVC），属于计算机视觉领域。其核心创新在于在缺乏实例级标签、仅有包级标签的隐私保护场景下实现高精度分类，采用了Learning from Label Proportions（LLP）范式，并提出了分层学习方法。虽然涉及医学图像等应用，但方法本质为通用的细粒度分类与弱监督学习，且与小样本学习（如弱标签、标签稀缺）密切相关。标准词表中‘小样本学习’最贴合论文的主要任务，‘医学图像分割’等不适用，‘目标检测’等也不符合，因此选择‘小样本学习’为三级领域，四级领域暂无更细分标准任务，设为null。",
      "keywords": [
        "细粒度视觉分类",
        "隐私保护",
        "标签比例学习",
        "分层学习",
        "弱监督学习"
      ],
      "methods": [
        "Learning from Label Proportions (LLP)",
        "分层细粒度标签比例学习（LHFGLP）",
        "Unrolled Hierarchical Fine-Grained Sparse Dictionary Learning",
        "Hierarchical Proportion Loss"
      ],
      "problems": [
        "如何在缺乏实例级标签、仅有包级标签的隐私敏感场景下实现高精度细粒度视觉分类",
        "如何利用细粒度数据的分层结构提升弱监督分类性能",
        "如何在保护隐私的前提下提升细粒度视觉分类的准确率"
      ]
    },
    "keywords": [
      "细粒度视觉分类",
      "隐私保护",
      "标签比例学习",
      "分层学习",
      "弱监督学习"
    ],
    "methods": [
      "Learning from Label Proportions (LLP)",
      "分层细粒度标签比例学习（LHFGLP）",
      "Unrolled Hierarchical Fine-Grained Sparse Dictionary Learning",
      "Hierarchical Proportion Loss"
    ],
    "problems": [
      "如何在缺乏实例级标签、仅有包级标签的隐私敏感场景下实现高精度细粒度视觉分类",
      "如何利用细粒度数据的分层结构提升弱监督分类性能",
      "如何在保护隐私的前提下提升细粒度视觉分类的准确率"
    ]
  },
  "2505.22961": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于提升大语言模型在说服性对话中的对手建模能力，核心任务是构建具备理论心智（Theory of Mind）能力的说服型对话体代理人。虽然涉及大语言模型和强化学习，但主要贡献在于对话系统中对手感知与推理能力的提升，属于自然语言处理下的对话系统方向。标准领域词表中没有更细的任务可选，因此level3为null。",
      "keywords": [
        "说服性对话",
        "理论心智",
        "对手建模",
        "大语言模型",
        "对话系统",
        "对手感知",
        "强化学习"
      ],
      "methods": [
        "理论心智增强模块（Theory of Mind modules）",
        "对手立场预测（文本编码器+MLP分类器）",
        "基于强化学习的训练方案",
        "反对意见生成与分析"
      ],
      "problems": [
        "现有大语言模型在说服性对话中缺乏对手感知与理论心智推理能力，导致说服策略单一、缺乏多样性",
        "如何让说服型对话体主动建模并动态分析对手的观点和心理状态",
        "如何通过理论心智增强模块提升说服型对话体的有效性和多样性"
      ]
    },
    "keywords": [
      "说服性对话",
      "理论心智",
      "对手建模",
      "大语言模型",
      "对话系统",
      "对手感知",
      "强化学习"
    ],
    "methods": [
      "理论心智增强模块（Theory of Mind modules）",
      "对手立场预测（文本编码器+MLP分类器）",
      "基于强化学习的训练方案",
      "反对意见生成与分析"
    ],
    "problems": [
      "现有大语言模型在说服性对话中缺乏对手感知与理论心智推理能力，导致说服策略单一、缺乏多样性",
      "如何让说服型对话体主动建模并动态分析对手的观点和心理状态",
      "如何通过理论心智增强模块提升说服型对话体的有效性和多样性"
    ]
  },
  "2505.23040": {
    "classification_path": "计算机科学 → 医学图像 → 小样本学习 → 医学图像分类",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "小样本学习",
      "level3": "医学图像分类",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于医学图像（脑癌和皮肤癌）分类，主要研究深度模型（CNN、ViT、CLIP变体）在数据受限和隐私保护场景下的优化与泛化能力。论文涉及联邦学习、传统机器学习方法（如SVM）提升小样本下的泛化能力，属于医学图像领域下的小样本学习任务，具体应用为医学图像分类。",
      "keywords": [
        "医学图像分类",
        "深度学习",
        "卷积神经网络",
        "视觉Transformer",
        "CLIP",
        "联邦学习",
        "小样本学习",
        "数据隐私",
        "多模态学习",
        "支持向量机"
      ],
      "methods": [
        "CLIP变体（结合CNN和ViT作为图像编码器）",
        "多模型集成",
        "联邦学习（两种方法）",
        "传统机器学习方法（支持向量机）",
        "多模态学习"
      ],
      "problems": [
        "医学图像领域数据稀缺与隐私保护下的分类性能提升",
        "CLIP等预训练模型在医学图像领域的适用性与优化",
        "提升深度模型在未见领域数据上的泛化能力"
      ]
    },
    "keywords": [
      "医学图像分类",
      "深度学习",
      "卷积神经网络",
      "视觉Transformer",
      "CLIP",
      "联邦学习",
      "小样本学习",
      "数据隐私",
      "多模态学习",
      "支持向量机"
    ],
    "methods": [
      "CLIP变体（结合CNN和ViT作为图像编码器）",
      "多模型集成",
      "联邦学习（两种方法）",
      "传统机器学习方法（支持向量机）",
      "多模态学习"
    ],
    "problems": [
      "医学图像领域数据稀缺与隐私保护下的分类性能提升",
      "CLIP等预训练模型在医学图像领域的适用性与优化",
      "提升深度模型在未见领域数据上的泛化能力"
    ]
  },
  "2505.22964": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究EHR（电子健康记录）领域的大模型扩展规律，核心关注模型规模、数据量、计算资源与性能之间的关系，属于机器学习领域的基础研究。虽然涉及transformer和foundation model，但其本质是探讨模型扩展（scaling laws）在医疗健康数据上的表现，属于机器学习方法论。由于标准词表中没有直接对应'扩展规律'或'foundation model'的三级分类，且论文强调在有限资源下的性能提升与泛化能力，最接近的是'小样本学习'，因为其也关注在有限数据/资源下的模型表现。",
      "keywords": [
        "扩展规律",
        "电子健康记录",
        "基础模型",
        "transformer",
        "MIMIC-IV",
        "临床预测",
        "资源高效训练"
      ],
      "methods": [
        "transformer架构训练",
        "经验性扩展规律分析",
        "IsoFLOPs曲线分析",
        "幂律关系建模"
      ],
      "problems": [
        "EHR基础模型是否遵循类似于自然语言处理大模型的扩展规律？",
        "如何通过扩展规律预测EHR模型的性能与资源消耗关系？",
        "如何设计资源高效的EHR基础模型以提升临床预测任务表现？"
      ]
    },
    "keywords": [
      "扩展规律",
      "电子健康记录",
      "基础模型",
      "transformer",
      "MIMIC-IV",
      "临床预测",
      "资源高效训练"
    ],
    "methods": [
      "transformer架构训练",
      "经验性扩展规律分析",
      "IsoFLOPs曲线分析",
      "幂律关系建模"
    ],
    "problems": [
      "EHR基础模型是否遵循类似于自然语言处理大模型的扩展规律？",
      "如何通过扩展规律预测EHR模型的性能与资源消耗关系？",
      "如何设计资源高效的EHR基础模型以提升临床预测任务表现？"
    ]
  },
  "2505.23043": {
    "classification_path": "计算机科学 → 多模态学习 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文系统性研究了统一视觉-语言模型（VLMs）在理解与生成任务上的泛化能力，核心关注多模态输入（视觉+语言）下的模型统一架构及其在生成与理解任务间的互补与迁移。虽然涉及视觉理解与生成，但论文主旨在于多模态统一建模及其泛化机制，最贴切的二级领域为'多模态学习'。三级领域中，论文重点分析了生成与理解任务的交互与泛化，且实验和分析主要围绕生成模型的泛化能力，因此选择'生成模型'作为三级领域。四级领域未涉及具体如'图像描述生成'等细分任务，设为null。",
      "keywords": [
        "统一视觉-语言模型",
        "多模态学习",
        "生成模型",
        "视觉理解",
        "任务泛化",
        "跨任务迁移"
      ],
      "methods": [
        "统一架构设计",
        "混合任务训练",
        "多模态输入输出对齐",
        "定制数据集实验",
        "跨任务泛化分析"
      ],
      "problems": [
        "统一视觉-语言模型在理解与生成任务间是否存在互补与泛化能力？",
        "混合训练对理解与生成任务性能的影响及其可扩展性如何？",
        "多模态输入输出空间的对齐对模型泛化能力有何作用？",
        "生成任务中获得的知识能否迁移到理解任务？"
      ]
    },
    "keywords": [
      "统一视觉-语言模型",
      "多模态学习",
      "生成模型",
      "视觉理解",
      "任务泛化",
      "跨任务迁移"
    ],
    "methods": [
      "统一架构设计",
      "混合任务训练",
      "多模态输入输出对齐",
      "定制数据集实验",
      "跨任务泛化分析"
    ],
    "problems": [
      "统一视觉-语言模型在理解与生成任务间是否存在互补与泛化能力？",
      "混合训练对理解与生成任务性能的影响及其可扩展性如何？",
      "多模态输入输出空间的对齐对模型泛化能力有何作用？",
      "生成任务中获得的知识能否迁移到理解任务？"
    ]
  },
  "2505.22993": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统 → 事实核查",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": "事实核查",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于复杂主张的事实核查（claim verification），核心任务是对自然语言中的主张进行验证，属于自然语言处理领域。论文提出的VeGraph框架主要用于提升事实核查中的实体消歧与推理能力，属于问答系统下的事实核查具体任务，因此选择'自然语言处理 → 问答系统 → 事实核查'作为分类路径。",
      "keywords": [
        "事实核查",
        "实体消歧",
        "图表示",
        "大语言模型",
        "主张验证",
        "知识库",
        "推理"
      ],
      "methods": [
        "图结构表示",
        "三元组分解",
        "交互式实体消歧",
        "大语言模型推理",
        "知识库交互"
      ],
      "problems": [
        "复杂主张中的实体消歧难题影响事实核查准确性",
        "如何提升大语言模型在复杂主张验证中的推理与解释能力",
        "缺乏有效的实体消歧策略导致验证流程受阻"
      ]
    },
    "keywords": [
      "事实核查",
      "实体消歧",
      "图表示",
      "大语言模型",
      "主张验证",
      "知识库",
      "推理"
    ],
    "methods": [
      "图结构表示",
      "三元组分解",
      "交互式实体消歧",
      "大语言模型推理",
      "知识库交互"
    ],
    "problems": [
      "复杂主张中的实体消歧难题影响事实核查准确性",
      "如何提升大语言模型在复杂主张验证中的推理与解释能力",
      "缺乏有效的实体消歧策略导致验证流程受阻"
    ]
  },
  "2505.23044": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 语义三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "语义三维重建",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文主要关注从稀疏、无位姿图像中高效重建带有语义信息的三维场景，属于计算机视觉领域。其核心任务是三维重建，并进一步聚焦于语义三维重建（即不仅重建几何，还要重建语义标签）。论文提出了新的冗余感知高斯表示和双场语义表达机制，属于三维重建下的具体任务'语义三维重建'，因此选择该分类路径。",
      "keywords": [
        "三维重建",
        "语义三维重建",
        "稀疏图像",
        "无位姿图像",
        "高斯表示",
        "特征压缩",
        "冗余消除"
      ],
      "methods": [
        "冗余感知高斯表示",
        "双场语义表示（粗特征场+细特征场）",
        "选择性高斯机制",
        "前馈式三维重建框架"
      ],
      "problems": [
        "如何在稀疏、无位姿图像下高效进行语义三维重建",
        "如何在不显著增加内存和存储开销的情况下提升语义表达能力",
        "如何消除像素级冗余以减少三维场景表示的冗余和内存消耗"
      ]
    },
    "keywords": [
      "三维重建",
      "语义三维重建",
      "稀疏图像",
      "无位姿图像",
      "高斯表示",
      "特征压缩",
      "冗余消除"
    ],
    "methods": [
      "冗余感知高斯表示",
      "双场语义表示（粗特征场+细特征场）",
      "选择性高斯机制",
      "前馈式三维重建框架"
    ],
    "problems": [
      "如何在稀疏、无位姿图像下高效进行语义三维重建",
      "如何在不显著增加内存和存储开销的情况下提升语义表达能力",
      "如何消除像素级冗余以减少三维场景表示的冗余和内存消耗"
    ]
  },
  "2505.23001": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文关注于大语言模型在开放基准测试集上的污染检测，主要涉及自然语言处理领域的模型评测与安全性。论文的方法（DyePack）用于检测模型是否在训练中使用了测试集，实验覆盖了多项自然语言处理任务，包括多项选择和开放式生成，均属于问答系统的典型任务。虽然论文与大语言模型相关，但其核心问题是NLP模型的评测安全与问答任务的污染检测，因此选择'自然语言处理→问答系统'作为最合适的分类路径。",
      "keywords": [
        "测试集污染",
        "大语言模型",
        "基准测试",
        "后门攻击",
        "模型评测",
        "问答系统",
        "开放基准",
        "安全性"
      ],
      "methods": [
        "DyePack框架",
        "多后门嵌入",
        "随机目标设计",
        "精确假阳性率计算",
        "无内部访问检测"
      ],
      "problems": [
        "如何在不访问模型内部信息的情况下检测大语言模型是否在训练中使用了测试集（即测试集污染）？",
        "如何设计一种方法能够在保证极低假阳性率的前提下，准确标记出被污染的模型？"
      ]
    },
    "keywords": [
      "测试集污染",
      "大语言模型",
      "基准测试",
      "后门攻击",
      "模型评测",
      "问答系统",
      "开放基准",
      "安全性"
    ],
    "methods": [
      "DyePack框架",
      "多后门嵌入",
      "随机目标设计",
      "精确假阳性率计算",
      "无内部访问检测"
    ],
    "problems": [
      "如何在不访问模型内部信息的情况下检测大语言模型是否在训练中使用了测试集（即测试集污染）？",
      "如何设计一种方法能够在保证极低假阳性率的前提下，准确标记出被污染的模型？"
    ]
  },
  "2505.23045": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 视觉问答",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "视觉问答",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于视觉问答（Visual Question Answering, VQA）任务，研究视觉与语言两种模态下的组合泛化能力，提出了多源组合泛化（MSCG）问题，并设计了相应的训练框架和数据集。VQA属于多模态学习下的问答系统的具体任务，因此选择'多模态学习 → 问答系统 → 视觉问答'作为最合适的分层分类路径。",
      "keywords": [
        "视觉问答",
        "多模态学习",
        "组合泛化",
        "多源组合泛化",
        "检索增强训练",
        "GQA-MSCG数据集"
      ],
      "methods": [
        "检索增强训练框架",
        "跨模态统一表示学习",
        "语义等价原语检索与特征聚合",
        "新数据集构建（GQA-MSCG）"
      ],
      "problems": [
        "如何提升视觉问答模型对多源新组合（跨模态原语组合）的泛化能力",
        "如何学习不同模态下原语的一致性表示",
        "如何评估和验证VQA模型在多源组合泛化上的表现"
      ]
    },
    "keywords": [
      "视觉问答",
      "多模态学习",
      "组合泛化",
      "多源组合泛化",
      "检索增强训练",
      "GQA-MSCG数据集"
    ],
    "methods": [
      "检索增强训练框架",
      "跨模态统一表示学习",
      "语义等价原语检索与特征聚合",
      "新数据集构建（GQA-MSCG）"
    ],
    "problems": [
      "如何提升视觉问答模型对多源新组合（跨模态原语组合）的泛化能力",
      "如何学习不同模态下原语的一致性表示",
      "如何评估和验证VQA模型在多源组合泛化上的表现"
    ]
  },
  "2505.23006": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统 → 生产级对话系统构建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": "生产级对话系统构建",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于将大语言模型应用于实际工业场景下的对话系统，尤其关注如何在电商等服务领域构建可控、可扩展、可靠的生产级对话代理。虽然涉及大语言模型，但核心任务是对话系统的工程化落地与优化，因此选择‘自然语言处理 → 对话系统 → 生产级对话系统构建’最为贴切。",
      "keywords": [
        "对话系统",
        "大语言模型",
        "生产级应用",
        "工作流图",
        "可控性",
        "可扩展性",
        "电商"
      ],
      "methods": [
        "工作流图驱动的对话系统设计",
        "大语言模型能力与规则约束结合",
        "实际案例分析与优化"
      ],
      "problems": [
        "如何在实际工业场景中应用大语言模型构建对话系统",
        "如何在保证灵活对话能力的同时满足服务约束",
        "如何提升对话系统的可控性、可扩展性与可靠性"
      ]
    },
    "keywords": [
      "对话系统",
      "大语言模型",
      "生产级应用",
      "工作流图",
      "可控性",
      "可扩展性",
      "电商"
    ],
    "methods": [
      "工作流图驱动的对话系统设计",
      "大语言模型能力与规则约束结合",
      "实际案例分析与优化"
    ],
    "problems": [
      "如何在实际工业场景中应用大语言模型构建对话系统",
      "如何在保证灵活对话能力的同时满足服务约束",
      "如何提升对话系统的可控性、可扩展性与可靠性"
    ]
  },
  "2505.23054": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "三维重建",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于从部分视角（partial-view）图像进行三维物体重建，属于计算机视觉领域。其核心任务是三维重建，尤其针对不完整观测下的重建问题。论文提出了融合多源先验和局部密集观测的无训练新方法，并在不可见区域重建上取得了优异效果。虽然涉及生成模型和扩散模型（如DDIM采样），但主要贡献和任务仍然是三维重建，因此选择'三维重建'作为level2和level3。",
      "keywords": [
        "三维重建",
        "部分视角",
        "零样本学习",
        "扩散模型",
        "多视角一致性",
        "无监督学习",
        "先验融合"
      ],
      "methods": [
        "融合多源先验的无训练重建方法",
        "基于DDIM采样的先验对齐策略",
        "多视角一致性生成",
        "几何结构迭代优化"
      ],
      "problems": [
        "如何在仅有部分视角观测的情况下实现高质量的三维重建",
        "如何解决不可见区域生成与可见区域不一致的问题",
        "如何在缺乏均匀分布视角的情况下提升重建一致性和质量"
      ]
    },
    "keywords": [
      "三维重建",
      "部分视角",
      "零样本学习",
      "扩散模型",
      "多视角一致性",
      "无监督学习",
      "先验融合"
    ],
    "methods": [
      "融合多源先验的无训练重建方法",
      "基于DDIM采样的先验对齐策略",
      "多视角一致性生成",
      "几何结构迭代优化"
    ],
    "problems": [
      "如何在仅有部分视角观测的情况下实现高质量的三维重建",
      "如何解决不可见区域生成与可见区域不一致的问题",
      "如何在缺乏均匀分布视角的情况下提升重建一致性和质量"
    ]
  },
  "2505.23015": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）在下游自然语言生成任务（如机器翻译和问答）中的后门样本检测。虽然涉及大语言模型，但其核心问题是自然语言处理中的安全性，且实验数据集包括问答和机器翻译，属于NLP范畴。标准词表中没有直接的'安全性'或'后门检测'，但论文主要应用场景为问答系统，因此选择'自然语言处理 → 问答系统'作为最贴切的分类路径。",
      "keywords": [
        "大语言模型",
        "后门攻击",
        "样本检测",
        "TF-IDF聚类",
        "参考过滤",
        "安全性",
        "问答系统",
        "机器翻译"
      ],
      "methods": [
        "参考过滤机制（Reference-Filtration）",
        "TF-IDF聚类（Tfidf-Clustering）",
        "基于类内距离的异常检测"
      ],
      "problems": [
        "如何高效检测并剔除大语言模型微调数据中的隐蔽后门样本",
        "现有检测方法无法有效应用于生成任务或会影响生成性能",
        "提升大语言模型在下游任务中的安全性"
      ]
    },
    "keywords": [
      "大语言模型",
      "后门攻击",
      "样本检测",
      "TF-IDF聚类",
      "参考过滤",
      "安全性",
      "问答系统",
      "机器翻译"
    ],
    "methods": [
      "参考过滤机制（Reference-Filtration）",
      "TF-IDF聚类（Tfidf-Clustering）",
      "基于类内距离的异常检测"
    ],
    "problems": [
      "如何高效检测并剔除大语言模型微调数据中的隐蔽后门样本",
      "现有检测方法无法有效应用于生成任务或会影响生成性能",
      "提升大语言模型在下游任务中的安全性"
    ]
  },
  "2505.23068": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 低光照图像增强",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "低光照图像增强",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于低光照图像增强（Low-light Image Enhancement, LLIE）及其与去模糊的联合任务，属于计算机视觉领域。论文提出了统一的生成式模型（URWKV）用于图像退化恢复，核心任务是低光照图像增强，属于生成模型在图像增强方向的具体应用。标准领域词表中没有直接的'图像增强'，但'生成模型'下的'低光照图像增强'是最贴切的具体任务。",
      "keywords": [
        "低光照图像增强",
        "图像去模糊",
        "生成模型",
        "多状态机制",
        "特征融合",
        "自适应归一化"
      ],
      "methods": [
        "Unified Receptance Weighted Key Value (URWKV)模型",
        "Luminance-adaptive Normalization (LAN)",
        "多状态特征聚合",
        "State-aware Selective Fusion (SSF)模块",
        "指数滑动平均"
      ],
      "problems": [
        "如何在低光照图像中灵活有效地恢复多种复杂退化",
        "如何利用多状态机制提升图像增强与去模糊的性能",
        "如何减少传统跳跃连接带来的信息退化问题"
      ]
    },
    "keywords": [
      "低光照图像增强",
      "图像去模糊",
      "生成模型",
      "多状态机制",
      "特征融合",
      "自适应归一化"
    ],
    "methods": [
      "Unified Receptance Weighted Key Value (URWKV)模型",
      "Luminance-adaptive Normalization (LAN)",
      "多状态特征聚合",
      "State-aware Selective Fusion (SSF)模块",
      "指数滑动平均"
    ],
    "problems": [
      "如何在低光照图像中灵活有效地恢复多种复杂退化",
      "如何利用多状态机制提升图像增强与去模糊的性能",
      "如何减少传统跳跃连接带来的信息退化问题"
    ]
  },
  "2505.23026": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型中的知识编辑（KE）方法，尤其是在存在上下文（如对话历史）时的鲁棒性问题。虽然涉及大语言模型，但核心研究内容是如何在对话或上下文环境下编辑和评估知识，因此最贴切的二级领域为‘自然语言处理’，三级领域为‘对话系统’。论文没有聚焦于问答系统、生成模型等其他具体任务，而是针对对话上下文中的知识编辑问题，因此选择‘对话系统’作为最合适的三级领域。",
      "keywords": [
        "知识编辑",
        "大语言模型",
        "上下文鲁棒性",
        "对话系统",
        "模型评估",
        "注意力机制"
      ],
      "methods": [
        "CHED基准测试",
        "CoRE知识编辑方法",
        "最小化上下文敏感方差",
        "注意力分数分析"
      ],
      "problems": [
        "现有知识编辑方法在有上下文时编辑效果不佳",
        "如何评估和提升知识编辑方法在对话上下文中的鲁棒性",
        "如何在不损害模型整体能力的前提下提升编辑成功率"
      ]
    },
    "keywords": [
      "知识编辑",
      "大语言模型",
      "上下文鲁棒性",
      "对话系统",
      "模型评估",
      "注意力机制"
    ],
    "methods": [
      "CHED基准测试",
      "CoRE知识编辑方法",
      "最小化上下文敏感方差",
      "注意力分数分析"
    ],
    "problems": [
      "现有知识编辑方法在有上下文时编辑效果不佳",
      "如何评估和提升知识编辑方法在对话上下文中的鲁棒性",
      "如何在不损害模型整体能力的前提下提升编辑成功率"
    ]
  },
  "2505.23085": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 人体姿态估计",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "人体姿态估计",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于从单目视频中估计3D人体几何结构，强调时序一致性和人体尺度的准确建模。其核心任务是对人体进行三维重建，并解决人体姿态与几何估计的时序一致性问题。虽然方法上采用了扩散模型，但主要贡献和应用场景属于三维重建中的人体姿态估计，因此选择'计算机视觉 → 三维重建 → 人体姿态估计'作为最合适的分层分类。",
      "keywords": [
        "3D人体几何估计",
        "时序一致性",
        "单目视频",
        "深度估计",
        "法线估计",
        "扩散模型",
        "人体尺度建模"
      ],
      "methods": [
        "图像到视频扩散模型",
        "根相对深度表示",
        "图像模型与视频模型协同",
        "小样本4D训练数据利用"
      ],
      "problems": [
        "如何从单目视频中准确且时序一致地估计3D人体几何结构",
        "如何在高质量4D训练数据稀缺的情况下提升模型泛化能力",
        "如何实现对人体真实尺度的准确建模"
      ]
    },
    "keywords": [
      "3D人体几何估计",
      "时序一致性",
      "单目视频",
      "深度估计",
      "法线估计",
      "扩散模型",
      "人体尺度建模"
    ],
    "methods": [
      "图像到视频扩散模型",
      "根相对深度表示",
      "图像模型与视频模型协同",
      "小样本4D训练数据利用"
    ],
    "problems": [
      "如何从单目视频中准确且时序一致地估计3D人体几何结构",
      "如何在高质量4D训练数据稀缺的情况下提升模型泛化能力",
      "如何实现对人体真实尺度的准确建模"
    ]
  },
  "2505.23029": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究如何从文本嵌入空间中无监督地挖掘心理语言学属性（如形象性和具体性），属于自然语言处理领域。虽然涉及视觉-语义联系，但核心方法和实验均基于文本分布结构分析，未直接涉及多模态学习或计算机视觉。论文提出了一种新的无监督度量方法（NSM），用于估计文本的心理语言学属性，这属于自然语言处理中的生成模型范畴，因为其核心是通过分布式表示生成和推断语义属性。标准领域词表中没有更细致的任务可选，因此level3为null。",
      "keywords": [
        "心理语言学属性",
        "形象性",
        "具体性",
        "文本嵌入",
        "分布式表示",
        "无监督学习",
        "Neighborhood Stability Measure"
      ],
      "methods": [
        "Neighborhood Stability Measure (NSM)",
        "无监督分布结构分析",
        "语义嵌入空间邻域分析"
      ],
      "problems": [
        "如何仅利用文本嵌入空间结构无监督地估计词语的形象性和具体性",
        "如何设计分布无关的度量方法以反映心理语言学属性",
        "现有无监督方法在心理语言学属性预测上的准确性不足，如何提升"
      ]
    },
    "keywords": [
      "心理语言学属性",
      "形象性",
      "具体性",
      "文本嵌入",
      "分布式表示",
      "无监督学习",
      "Neighborhood Stability Measure"
    ],
    "methods": [
      "Neighborhood Stability Measure (NSM)",
      "无监督分布结构分析",
      "语义嵌入空间邻域分析"
    ],
    "problems": [
      "如何仅利用文本嵌入空间结构无监督地估计词语的形象性和具体性",
      "如何设计分布无关的度量方法以反映心理语言学属性",
      "现有无监督方法在心理语言学属性预测上的准确性不足，如何提升"
    ]
  },
  "2505.23093": {
    "classification_path": "计算机科学 → 计算机视觉 → 图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于轻量级语义分割方法的设计与优化，属于计算机视觉领域下的图像分割任务。虽然论文提出了新的方法LeMoRe，但其核心任务是提升语义分割的效率与表现，并未涉及医学图像、三维重建等更细分的应用场景，因此归类为'计算机视觉 → 图像分割'最为合适。标准词表中没有更细的'轻量级语义分割'或'语义分割'四级分类，因此level3设为null。",
      "keywords": [
        "轻量级语义分割",
        "显式建模",
        "隐式建模",
        "嵌套注意力机制",
        "全局依赖",
        "计算效率"
      ],
      "methods": [
        "显式与隐式特征建模结合",
        "嵌套注意力机制",
        "基于笛卡尔方向的特征建模",
        "高效全局依赖捕获"
      ],
      "problems": [
        "如何在轻量级语义分割中兼顾效率与表现",
        "现有方法受限于参数量大和计算量高的架构设计",
        "如何通过高效建模提升分割模型的代表性和泛化能力"
      ]
    },
    "keywords": [
      "轻量级语义分割",
      "显式建模",
      "隐式建模",
      "嵌套注意力机制",
      "全局依赖",
      "计算效率"
    ],
    "methods": [
      "显式与隐式特征建模结合",
      "嵌套注意力机制",
      "基于笛卡尔方向的特征建模",
      "高效全局依赖捕获"
    ],
    "problems": [
      "如何在轻量级语义分割中兼顾效率与表现",
      "现有方法受限于参数量大和计算量高的架构设计",
      "如何通过高效建模提升分割模型的代表性和泛化能力"
    ]
  },
  "2505.23030": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究多种现代NLP系统在医学影像（胸部X光）报告自动标注任务中的性能比较，核心任务为从临床文本中抽取医学实体及其断言状态，属于自然语言处理领域。虽然涉及医学应用，但主要方法和评测对象均为NLP系统，且任务为信息抽取和断言检测，最接近标准词表中的‘问答系统’（涵盖信息抽取、实体识别等临床文本理解任务）。医学图像相关内容仅为应用背景，未涉及图像处理或分割等视觉任务，因此不归入‘医学图像’。",
      "keywords": [
        "自然语言处理",
        "实体抽取",
        "断言检测",
        "医学报告标注",
        "胸部X光",
        "临床文本",
        "系统评测"
      ],
      "methods": [
        "实体抽取",
        "断言状态识别",
        "多系统比较评测",
        "Fleiss Kappa一致性分析",
        "准确率评估"
      ],
      "problems": [
        "现代通用NLP系统能否可靠地自动标注儿科胸部X光报告？",
        "不同NLP系统在医学实体抽取和断言检测任务上的性能差异如何？",
        "在部署NLP工具用于临床报告标注前，是否需要独立验证和评审？"
      ]
    },
    "keywords": [
      "自然语言处理",
      "实体抽取",
      "断言检测",
      "医学报告标注",
      "胸部X光",
      "临床文本",
      "系统评测"
    ],
    "methods": [
      "实体抽取",
      "断言状态识别",
      "多系统比较评测",
      "Fleiss Kappa一致性分析",
      "准确率评估"
    ],
    "problems": [
      "现代通用NLP系统能否可靠地自动标注儿科胸部X光报告？",
      "不同NLP系统在医学实体抽取和断言检测任务上的性能差异如何？",
      "在部署NLP工具用于临床报告标注前，是否需要独立验证和评审？"
    ]
  },
  "2505.23102": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 图像增强",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "图像增强",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要关注低光照图像增强（Low-Light Image Enhancement），属于计算机视觉领域中的图像增强任务。虽然方法中融合了强化学习和多模态（CLIP）技术，但核心任务是提升图像质量，属于生成模型下的图像增强应用。因此，选择'计算机视觉 → 生成模型 → 图像增强'作为最合适的分层分类路径。",
      "keywords": [
        "低光照图像增强",
        "CLIP",
        "强化学习",
        "图像增强",
        "Bézier曲线",
        "零参考",
        "高分辨率",
        "多模态"
      ],
      "methods": [
        "基于CLIP的奖励设计",
        "强化学习参数估计",
        "Bézier曲线全局色调调整",
        "简单图像处理模块"
      ],
      "problems": [
        "如何在无参考情况下获得感知质量良好的增强图像",
        "如何在高分辨率图像增强中保持计算效率"
      ]
    },
    "keywords": [
      "低光照图像增强",
      "CLIP",
      "强化学习",
      "图像增强",
      "Bézier曲线",
      "零参考",
      "高分辨率",
      "多模态"
    ],
    "methods": [
      "基于CLIP的奖励设计",
      "强化学习参数估计",
      "Bézier曲线全局色调调整",
      "简单图像处理模块"
    ],
    "problems": [
      "如何在无参考情况下获得感知质量良好的增强图像",
      "如何在高分辨率图像增强中保持计算效率"
    ]
  },
  "2505.23035": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于人类与AI对话过程中英语表达方式的变化，分析了人机交互中语言风格的演变及其对对话系统设计的影响。虽然涉及人机交互，但核心内容是自然语言在对话系统中的适应与变体，因此选择'自然语言处理'为二级领域，'对话系统'为三级领域。四级领域暂无更细致标准任务可选，故为null。",
      "keywords": [
        "Machine-Facing English",
        "register theory",
        "human-AI interaction",
        "syntactic rigidity",
        "pragmatic simplification",
        "directive syntax",
        "controlled vocabulary",
        "conversational interfaces"
      ],
      "methods": [
        "定性观察",
        "主题分析",
        "自然语言声明式提示（NLD-P）",
        "人类策划的产品测试"
      ],
      "problems": [
        "人类与AI持续互动如何塑造英语表达的新变体",
        "MFE特征对机器可解析性与自然流畅性的影响",
        "对话系统设计中表达效率与语言丰富性的权衡",
        "多语言用户在AI交互中的表达与理解挑战"
      ]
    },
    "keywords": [
      "Machine-Facing English",
      "register theory",
      "human-AI interaction",
      "syntactic rigidity",
      "pragmatic simplification",
      "directive syntax",
      "controlled vocabulary",
      "conversational interfaces"
    ],
    "methods": [
      "定性观察",
      "主题分析",
      "自然语言声明式提示（NLD-P）",
      "人类策划的产品测试"
    ],
    "problems": [
      "人类与AI持续互动如何塑造英语表达的新变体",
      "MFE特征对机器可解析性与自然流畅性的影响",
      "对话系统设计中表达效率与语言丰富性的权衡",
      "多语言用户在AI交互中的表达与理解挑战"
    ]
  },
  "2505.23107": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了一种通用的EEG信号分类适配器（EAD），旨在解决不同采集设备和通道数变化下的EEG信号分类问题，核心在于学习鲁棒的EEG表征并实现跨设备、跨任务的泛化能力。论文强调了零样本（zero-shot）分类能力和在多数据集上的泛化表现，属于典型的小样本学习/泛化学习范畴。虽然EEG属于生物信号，但论文的主要贡献在于机器学习方法的泛化能力，因此归入‘机器学习→小样本学习’最为贴切。",
      "keywords": [
        "EEG",
        "信号分类",
        "表征学习",
        "适配器",
        "泛化能力",
        "零样本学习"
      ],
      "methods": [
        "EEG适配器（EAD）框架",
        "基于深度学习的表征学习",
        "跨设备兼容性",
        "零样本分类评估"
      ],
      "problems": [
        "如何在不同采集设备和通道数变化下实现统一的EEG信号分类",
        "如何提升EEG分类模型的泛化能力和零样本学习能力"
      ]
    },
    "keywords": [
      "EEG",
      "信号分类",
      "表征学习",
      "适配器",
      "泛化能力",
      "零样本学习"
    ],
    "methods": [
      "EEG适配器（EAD）框架",
      "基于深度学习的表征学习",
      "跨设备兼容性",
      "零样本分类评估"
    ],
    "problems": [
      "如何在不同采集设备和通道数变化下实现统一的EEG信号分类",
      "如何提升EEG分类模型的泛化能力和零样本学习能力"
    ]
  },
  "2505.23037": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于社交媒体评论的细粒度方面分析，涉及多语言评论的方面术语生成与分析，属于自然语言处理领域。虽然论文未直接涉及传统的问答系统，但在标准词表下，'问答系统'涵盖了对文本内容的理解与信息抽取等任务。由于标准词表未包含'情感分析'、'评论分析'等更细分任务，'问答系统'是最接近的三级领域。四级领域暂无更具体的标准任务可选，因此level3设为null。",
      "keywords": [
        "多语言",
        "社交媒体",
        "方面分析",
        "评论分析",
        "大语言模型",
        "CAT-G",
        "DPO",
        "评论聚类",
        "评论摘要"
      ],
      "methods": [
        "多语言大语言模型",
        "有监督微调",
        "评论方面术语生成（CAT-G）",
        "DPO对齐"
      ],
      "problems": [
        "如何提升多语言社交媒体评论的细粒度理解",
        "如何自动生成和识别评论中的方面术语以辅助下游NLP任务",
        "如何评估和比较大语言模型在不同语言下的评论分析能力"
      ]
    },
    "keywords": [
      "多语言",
      "社交媒体",
      "方面分析",
      "评论分析",
      "大语言模型",
      "CAT-G",
      "DPO",
      "评论聚类",
      "评论摘要"
    ],
    "methods": [
      "多语言大语言模型",
      "有监督微调",
      "评论方面术语生成（CAT-G）",
      "DPO对齐"
    ],
    "problems": [
      "如何提升多语言社交媒体评论的细粒度理解",
      "如何自动生成和识别评论中的方面术语以辅助下游NLP任务",
      "如何评估和比较大语言模型在不同语言下的评论分析能力"
    ]
  },
  "2505.23109": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文核心在于通过机器学习方法（特征选择、聚类）从大规模认知测试数据中识别个体化的认知损伤模式，用于早期痴呆检测和个性化随访测试。虽然应用场景为医学，但未涉及医学图像，因此不选“医学图像”相关分类。论文方法侧重于从有限样本中学习认知损伤模式，属于小样本学习范畴，最贴切的三级领域为“小样本学习”。",
      "keywords": [
        "认知损伤模式",
        "早期痴呆检测",
        "特征选择",
        "聚类分析",
        "个性化测试",
        "MCI",
        "NACC数据库"
      ],
      "methods": [
        "集成包裹式特征选择",
        "聚类分析",
        "标准化认知测试",
        "模式识别"
      ],
      "problems": [
        "如何从大规模认知测试数据中识别个体化的认知损伤模式？",
        "如何利用这些模式实现早期痴呆的个性化检测和随访？",
        "如何提高认知障碍检测的效率和适用性，减少全面测试的负担？"
      ]
    },
    "keywords": [
      "认知损伤模式",
      "早期痴呆检测",
      "特征选择",
      "聚类分析",
      "个性化测试",
      "MCI",
      "NACC数据库"
    ],
    "methods": [
      "集成包裹式特征选择",
      "聚类分析",
      "标准化认知测试",
      "模式识别"
    ],
    "problems": [
      "如何从大规模认知测试数据中识别个体化的认知损伤模式？",
      "如何利用这些模式实现早期痴呆的个性化检测和随访？",
      "如何提高认知障碍检测的效率和适用性，减少全面测试的负担？"
    ]
  },
  "2505.23038": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": "小样本学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于命名实体识别（NER）任务，属于自然语言处理领域。论文提出了一种基于多小参数大语言模型的集成学习方法，结合了In-Context Learning（ICL）和生成式大语言模型，旨在提升NER任务的性能并降低计算资源消耗。由于论文核心创新点在于利用小参数LLMs进行ICL范式下的NER任务，且强调参数高效和小样本泛化能力，因此在三级领域选择‘生成模型’，四级领域选择‘小样本学习’最为贴切。",
      "keywords": [
        "命名实体识别",
        "集成学习",
        "小参数大语言模型",
        "In-Context Learning",
        "参数高效",
        "自验证机制"
      ],
      "methods": [
        "多模型集成学习",
        "任务分解式多阶段集成",
        "基于span的句子相似度检索",
        "自验证机制"
      ],
      "problems": [
        "如何在NER任务中利用小参数开源大语言模型实现高效、低成本的In-Context Learning",
        "如何通过集成学习提升小参数LLMs在NER任务中的性能",
        "如何缓解集成过程中噪声带来的负面影响"
      ]
    },
    "keywords": [
      "命名实体识别",
      "集成学习",
      "小参数大语言模型",
      "In-Context Learning",
      "参数高效",
      "自验证机制"
    ],
    "methods": [
      "多模型集成学习",
      "任务分解式多阶段集成",
      "基于span的句子相似度检索",
      "自验证机制"
    ],
    "problems": [
      "如何在NER任务中利用小参数开源大语言模型实现高效、低成本的In-Context Learning",
      "如何通过集成学习提升小参数LLMs在NER任务中的性能",
      "如何缓解集成过程中噪声带来的负面影响"
    ]
  },
  "2505.23115": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文主要关注于自动驾驶场景下的3D占用预测任务，采用扩散模型这一生成模型方法。根据标准领域词表，'计算机视觉'是最合适的二级领域，因为任务涉及视觉输入和3D场景理解。三级领域选择'生成模型'，四级领域选择'扩散模型'，因为论文核心方法为扩散生成模型。虽然任务与三维重建相关，但论文强调生成式建模和扩散模型方法，因此归入'生成模型→扩散模型'最为贴切。",
      "keywords": [
        "3D占用预测",
        "自动驾驶",
        "扩散模型",
        "生成模型",
        "三维场景理解",
        "噪声鲁棒性",
        "下游规划"
      ],
      "methods": [
        "基于扩散的生成模型",
        "三维场景先验建模",
        "视觉输入到3D占用网格预测"
      ],
      "problems": [
        "如何提升自动驾驶中3D占用预测的准确性和鲁棒性",
        "如何应对视觉输入中的噪声、不完整观测和复杂三维结构",
        "如何利用生成模型提升在遮挡或低可见性区域的预测表现"
      ]
    },
    "keywords": [
      "3D占用预测",
      "自动驾驶",
      "扩散模型",
      "生成模型",
      "三维场景理解",
      "噪声鲁棒性",
      "下游规划"
    ],
    "methods": [
      "基于扩散的生成模型",
      "三维场景先验建模",
      "视觉输入到3D占用网格预测"
    ],
    "problems": [
      "如何提升自动驾驶中3D占用预测的准确性和鲁棒性",
      "如何应对视觉输入中的噪声、不完整观测和复杂三维结构",
      "如何利用生成模型提升在遮挡或低可见性区域的预测表现"
    ]
  },
  "2505.23052": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于检索增强大语言模型（RAG）在知识密集型任务中的查询路由问题，属于自然语言处理领域。其核心任务是提升多模型问答系统的路由效率和效果，因此最合适的三级领域为'问答系统'。虽然涉及大语言模型，但主要创新点和实验均围绕RAG场景下的问答路由展开，未涉及代码生成、对话系统等其他具体任务，四级领域暂无更细分标准任务可选，故level3为null。",
      "keywords": [
        "检索增强生成",
        "大语言模型",
        "查询路由",
        "知识密集型任务",
        "对比学习",
        "文档嵌入",
        "RAGRouter"
      ],
      "methods": [
        "RAG-aware路由设计",
        "文档嵌入与RAG能力嵌入",
        "对比学习",
        "score-threshold机制"
      ],
      "problems": [
        "如何在多检索增强大语言模型环境下为每个查询智能选择最合适的模型",
        "如何将外部检索文档的动态影响纳入路由决策",
        "现有静态知识表示路由方法在RAG场景下性能不足，如何改进"
      ]
    },
    "keywords": [
      "检索增强生成",
      "大语言模型",
      "查询路由",
      "知识密集型任务",
      "对比学习",
      "文档嵌入",
      "RAGRouter"
    ],
    "methods": [
      "RAG-aware路由设计",
      "文档嵌入与RAG能力嵌入",
      "对比学习",
      "score-threshold机制"
    ],
    "problems": [
      "如何在多检索增强大语言模型环境下为每个查询智能选择最合适的模型",
      "如何将外部检索文档的动态影响纳入路由决策",
      "现有静态知识表示路由方法在RAG场景下性能不足，如何改进"
    ]
  },
  "2505.23119": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究基于扩散模型的场景文本图像超分辨率（STISR），属于计算机视觉领域。其核心方法是利用扩散模型进行图像生成与增强，并结合OCR和文本检测等多模态信息进行引导。扩散模型是当前生成模型中的主流方法之一，因此选择'生成模型'作为三级领域，'扩散模型'作为四级领域最为贴切。",
      "keywords": [
        "图像超分辨率",
        "扩散模型",
        "多语言OCR",
        "场景文本",
        "跨模态引导",
        "文本检测"
      ],
      "methods": [
        "多模态扩散模型",
        "文本检测与OCR引导",
        "UTF-8文本编码与跨注意力机制",
        "字符先验融合"
      ],
      "problems": [
        "现有扩散模型在场景文本图像超分辨率任务中对文本区域定位不准，字符形状建模不足，导致生成结果不一致和伪影问题",
        "如何结合多语言OCR信息和字符先验，有效提升低分辨率场景文本图像的超分辨率质量和可读性"
      ]
    },
    "keywords": [
      "图像超分辨率",
      "扩散模型",
      "多语言OCR",
      "场景文本",
      "跨模态引导",
      "文本检测"
    ],
    "methods": [
      "多模态扩散模型",
      "文本检测与OCR引导",
      "UTF-8文本编码与跨注意力机制",
      "字符先验融合"
    ],
    "problems": [
      "现有扩散模型在场景文本图像超分辨率任务中对文本区域定位不准，字符形状建模不足，导致生成结果不一致和伪影问题",
      "如何结合多语言OCR信息和字符先验，有效提升低分辨率场景文本图像的超分辨率质量和可读性"
    ]
  },
  "2505.23060": {
    "classification_path": "计算机科学 → 自然语言处理 → 代码生成 → 代码自我修正",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "代码生成",
      "level3": "代码自我修正",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于小型语言模型在代码生成任务中的自我修正能力提升，提出了针对多轮代码修正的强化学习方法。虽然涉及强化学习，但主要任务是代码生成中的自我修正，因此选择'自然语言处理'为二级领域，'代码生成'为三级领域，'代码自我修正'为具体任务。",
      "keywords": [
        "代码生成",
        "自我修正",
        "小型语言模型",
        "强化学习",
        "多轮修正",
        "CoCoS",
        "MBPP",
        "HumanEval"
      ],
      "methods": [
        "在线强化学习目标",
        "累积奖励函数",
        "细粒度奖励设计",
        "多轮自我修正训练"
      ],
      "problems": [
        "小型语言模型能否有效进行自我反思和自我修正以提升代码生成质量？",
        "如何设计训练目标和奖励机制以提升小型语言模型在多轮代码修正中的表现？"
      ]
    },
    "keywords": [
      "代码生成",
      "自我修正",
      "小型语言模型",
      "强化学习",
      "多轮修正",
      "CoCoS",
      "MBPP",
      "HumanEval"
    ],
    "methods": [
      "在线强化学习目标",
      "累积奖励函数",
      "细粒度奖励设计",
      "多轮自我修正训练"
    ],
    "problems": [
      "小型语言模型能否有效进行自我反思和自我修正以提升代码生成质量？",
      "如何设计训练目标和奖励机制以提升小型语言模型在多轮代码修正中的表现？"
    ]
  },
  "2505.23120": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究基于音频驱动的手势视频生成，属于计算机视觉领域中的生成模型任务。论文提出了两阶段网络，第二阶段明确采用了扩散模型（Stabilized Diffusion Video Generation），并针对视频中动作与细节的生成进行了改进。因此，最合适的分类路径为‘计算机科学 → 计算机视觉 → 生成模型 → 扩散模型’。",
      "keywords": [
        "手势视频生成",
        "音频驱动",
        "动作掩码",
        "两阶段网络",
        "扩散模型",
        "姿态生成",
        "音视频同步"
      ],
      "methods": [
        "Motion Mask-Guided Two-Stage Network (MMGT)",
        "Spatial Mask-Guided Audio Pose Generation (SMGA) Network",
        "Motion Masked Hierarchical Audio Attention (MM-HAA)",
        "Stabilized Diffusion Video Generation"
      ],
      "problems": [
        "如何从音频驱动的静态图像生成高质量、同步的手势视频",
        "如何捕捉和生成大幅度动作及区域细节，减少伪影和失真",
        "如何在不依赖额外先验信息的情况下提升生成视频的动作幅度和细节表现"
      ]
    },
    "keywords": [
      "手势视频生成",
      "音频驱动",
      "动作掩码",
      "两阶段网络",
      "扩散模型",
      "姿态生成",
      "音视频同步"
    ],
    "methods": [
      "Motion Mask-Guided Two-Stage Network (MMGT)",
      "Spatial Mask-Guided Audio Pose Generation (SMGA) Network",
      "Motion Masked Hierarchical Audio Attention (MM-HAA)",
      "Stabilized Diffusion Video Generation"
    ],
    "problems": [
      "如何从音频驱动的静态图像生成高质量、同步的手势视频",
      "如何捕捉和生成大幅度动作及区域细节，减少伪影和失真",
      "如何在不依赖额外先验信息的情况下提升生成视频的动作幅度和细节表现"
    ]
  },
  "2505.23065": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于社交网络服务中视觉与文本内容的结合，评测多模态大语言模型在多种任务（如理解、推荐、信息检索等）上的表现。论文核心是多模态（视觉+语言）模型的评测基准，且主要任务为多模态问答，因此选择'多模态学习'为二级领域，'问答系统'为三级领域。四级领域暂无更细分标准任务，设为null。",
      "keywords": [
        "多模态大语言模型",
        "社交网络服务",
        "基准评测",
        "视觉-语言理解",
        "问答系统"
      ],
      "methods": [
        "多模态基准构建",
        "多任务评测",
        "模型性能分析"
      ],
      "problems": [
        "如何系统性评测多模态大语言模型在真实社交网络场景下的能力",
        "现有基准缺乏对社交网络多模态上下文的覆盖",
        "多模态模型在社交语境理解中的挑战"
      ]
    },
    "keywords": [
      "多模态大语言模型",
      "社交网络服务",
      "基准评测",
      "视觉-语言理解",
      "问答系统"
    ],
    "methods": [
      "多模态基准构建",
      "多任务评测",
      "模型性能分析"
    ],
    "problems": [
      "如何系统性评测多模态大语言模型在真实社交网络场景下的能力",
      "现有基准缺乏对社交网络多模态上下文的覆盖",
      "多模态模型在社交语境理解中的挑战"
    ]
  },
  "2505.23129": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 自动驾驶场景理解",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "自动驾驶场景理解",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要聚焦于端到端自动驾驶中的轨迹生成与评估，核心方法基于Bird's-Eye-View（BEV）视觉表征，结合BEVFormer等视觉模型进行多目标轨迹提议与评分。虽然涉及强化学习和多目标评分，但整体框架和创新点集中在视觉感知与三维空间下的轨迹生成与理解，属于计算机视觉领域下的三维重建分支，具体应用为自动驾驶场景理解。",
      "keywords": [
        "端到端自动驾驶",
        "Bird's-Eye-View",
        "轨迹生成",
        "多目标评分",
        "BEVFormer",
        "仿真监督"
      ],
      "methods": [
        "基于BEV的轨迹提议机制",
        "可学习锚点查询",
        "迭代偏移解码",
        "仿真监督多目标评分模块"
      ],
      "problems": [
        "如何生成多样且符合交通规则的自动驾驶轨迹",
        "如何通过学习的多目标评分机制鲁棒地选择最优轨迹",
        "如何有效解耦轨迹生成与安全感知评分以提升自动驾驶性能"
      ]
    },
    "keywords": [
      "端到端自动驾驶",
      "Bird's-Eye-View",
      "轨迹生成",
      "多目标评分",
      "BEVFormer",
      "仿真监督"
    ],
    "methods": [
      "基于BEV的轨迹提议机制",
      "可学习锚点查询",
      "迭代偏移解码",
      "仿真监督多目标评分模块"
    ],
    "problems": [
      "如何生成多样且符合交通规则的自动驾驶轨迹",
      "如何通过学习的多目标评分机制鲁棒地选择最优轨迹",
      "如何有效解耦轨迹生成与安全感知评分以提升自动驾驶性能"
    ]
  },
  "2505.23078": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型 → 文档级文本生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": "文档级文本生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于文档级文本生成任务，提出了基于最小贝叶斯风险（MBR）解码和最优传输（OT）的新方法。该研究属于自然语言处理领域下的生成模型分支，具体应用于文档级文本生成任务（如文档级机器翻译、文本简化、密集图像描述），因此选择'自然语言处理 → 生成模型 → 文档级文本生成'作为最合适的分层分类路径。",
      "keywords": [
        "文档级文本生成",
        "最小贝叶斯风险解码",
        "最优传输",
        "Wasserstein距离",
        "机器翻译",
        "文本简化",
        "图像描述"
      ],
      "methods": [
        "最小贝叶斯风险（MBR）解码",
        "基于最优传输的MBR变体（MBR-OT）",
        "Wasserstein距离用于文档级效用计算"
      ],
      "problems": [
        "如何提升文档级文本生成任务的生成质量",
        "如何将MBR解码有效应用于文档级文本生成",
        "如何设计适用于文档级的效用函数以克服现有句子级效用函数的局限"
      ]
    },
    "keywords": [
      "文档级文本生成",
      "最小贝叶斯风险解码",
      "最优传输",
      "Wasserstein距离",
      "机器翻译",
      "文本简化",
      "图像描述"
    ],
    "methods": [
      "最小贝叶斯风险（MBR）解码",
      "基于最优传输的MBR变体（MBR-OT）",
      "Wasserstein距离用于文档级效用计算"
    ],
    "problems": [
      "如何提升文档级文本生成任务的生成质量",
      "如何将MBR解码有效应用于文档级文本生成",
      "如何设计适用于文档级的效用函数以克服现有句子级效用函数的局限"
    ]
  },
  "2505.23130": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 图像风格迁移",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "图像风格迁移",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究基于视觉-语言模型和自然语言推理的智能照片艺术润色系统，核心任务是模拟专业艺术家的创作过程，实现对照片的艺术化调整。其主要贡献在于自动化地将用户的艺术意图转化为具体的图像风格调整参数，并通过迭代优化实现目标艺术效果。该任务属于计算机视觉领域下的生成模型，具体应用为图像风格迁移（即将图像调整为具有特定艺术风格的效果），因此选择'计算机视觉 → 生成模型 → 图像风格迁移'作为分类路径。",
      "keywords": [
        "照片润色",
        "视觉-语言模型",
        "艺术风格迁移",
        "自然语言推理",
        "人机交互",
        "图像生成"
      ],
      "methods": [
        "视觉-语言模型（VLM）",
        "自然语言推理",
        "艺术分析与策略规划",
        "API参数化控制（Lightroom）",
        "迭代优化",
        "文本解释生成"
      ],
      "problems": [
        "如何让非专业用户实现具有艺术深度的照片润色",
        "如何将自然语言描述的艺术意图转化为具体的图像调整操作",
        "如何提升自动化照片润色系统的交互性与解释性",
        "如何使自动化润色效果接近专业艺术家水平"
      ]
    },
    "keywords": [
      "照片润色",
      "视觉-语言模型",
      "艺术风格迁移",
      "自然语言推理",
      "人机交互",
      "图像生成"
    ],
    "methods": [
      "视觉-语言模型（VLM）",
      "自然语言推理",
      "艺术分析与策略规划",
      "API参数化控制（Lightroom）",
      "迭代优化",
      "文本解释生成"
    ],
    "problems": [
      "如何让非专业用户实现具有艺术深度的照片润色",
      "如何将自然语言描述的艺术意图转化为具体的图像调整操作",
      "如何提升自动化照片润色系统的交互性与解释性",
      "如何使自动化润色效果接近专业艺术家水平"
    ]
  },
  "2505.23108": {
    "classification_path": "计算机科学 → 自然语言处理 → 小样本学习 → 关系抽取",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "小样本学习",
      "level3": "关系抽取",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于利用大语言模型（LLMs）生成多样化的训练样本以提升关系抽取（Relation Extraction, RE）任务在零样本或小样本场景下的表现。其核心研究内容属于自然语言处理领域，具体涉及小样本学习方法在关系抽取任务中的应用，因此选择'自然语言处理'为二级领域，'小样本学习'为三级领域，'关系抽取'为四级领域。",
      "keywords": [
        "大语言模型",
        "关系抽取",
        "训练数据生成",
        "多样性",
        "小样本学习",
        "In-Context Learning",
        "Direct Preference Optimization"
      ],
      "methods": [
        "基于In-Context Learning的多样性提示",
        "Direct Preference Optimization (DPO)微调大语言模型",
        "生成式数据增强"
      ],
      "problems": [
        "如何提升大语言模型生成的关系抽取训练样本的多样性",
        "如何在保证生成样本正确性的同时提升其多样性",
        "生成样本训练下游非LLM模型与直接用LLM做RE的性能对比"
      ]
    },
    "keywords": [
      "大语言模型",
      "关系抽取",
      "训练数据生成",
      "多样性",
      "小样本学习",
      "In-Context Learning",
      "Direct Preference Optimization"
    ],
    "methods": [
      "基于In-Context Learning的多样性提示",
      "Direct Preference Optimization (DPO)微调大语言模型",
      "生成式数据增强"
    ],
    "problems": [
      "如何提升大语言模型生成的关系抽取训练样本的多样性",
      "如何在保证生成样本正确性的同时提升其多样性",
      "生成样本训练下游非LLM模型与直接用LLM做RE的性能对比"
    ]
  },
  "2505.23134": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 视频理解",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "视频理解",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要关注于基于参考图像的视频外观编辑，属于计算机视觉领域。其核心方法为生成模型（conditional generative model），并针对视频中的外观一致性传播和编辑，属于视频理解下的具体生成任务。虽然涉及零样本初始化和注意力机制，但主要贡献在于视频外观编辑的生成与一致性传播，因此选择‘计算机视觉 → 生成模型 → 视频理解’作为最合适的分层分类。",
      "keywords": [
        "视频外观编辑",
        "参考图像",
        "生成模型",
        "零样本初始化",
        "注意力机制",
        "外观一致性",
        "视频传播"
      ],
      "methods": [
        "基于参考图像的锚帧编辑",
        "注意力机制引导的外观传播",
        "零样本初始化",
        "条件生成模型",
        "视频一致性评估"
      ],
      "problems": [
        "现有文本引导方法在视频编辑中存在歧义，难以实现细粒度控制",
        "如何实现基于参考图像的视频外观编辑并保证外观一致性",
        "如何在大幅运动场景下实现鲁棒且高效的视频外观传播",
        "如何评估视频外观编辑的一致性和准确性"
      ]
    },
    "keywords": [
      "视频外观编辑",
      "参考图像",
      "生成模型",
      "零样本初始化",
      "注意力机制",
      "外观一致性",
      "视频传播"
    ],
    "methods": [
      "基于参考图像的锚帧编辑",
      "注意力机制引导的外观传播",
      "零样本初始化",
      "条件生成模型",
      "视频一致性评估"
    ],
    "problems": [
      "现有文本引导方法在视频编辑中存在歧义，难以实现细粒度控制",
      "如何实现基于参考图像的视频外观编辑并保证外观一致性",
      "如何在大幅运动场景下实现鲁棒且高效的视频外观传播",
      "如何评估视频外观编辑的一致性和准确性"
    ]
  },
  "2505.23114": {
    "classification_path": "计算机科学 → 大语言模型 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于大语言模型（LLM）的对齐问题，核心内容是通过分析和诊断人类偏好数据来提升LLM的对齐效率。虽然涉及数据分析和可视化，但主要贡献在于为大语言模型的对齐任务（尤其是对话/指令响应）提供数据筛选与诊断工具，因此选择“大语言模型→对话系统”最为贴切。未细化到更具体的任务，level3设为null。",
      "keywords": [
        "大语言模型对齐",
        "人类偏好数据",
        "数据诊断",
        "数据效率",
        "GPT-4o",
        "Alignment Data Map"
      ],
      "methods": [
        "Alignment Data Map构建",
        "GPT-4o辅助评分",
        "均值-方差分析",
        "高质量样本筛选"
      ],
      "problems": [
        "如何高效收集和利用人类偏好数据以对齐大语言模型",
        "如何诊断和筛选偏好数据中的高质量样本",
        "如何发现低影响或误标注的数据样本"
      ]
    },
    "keywords": [
      "大语言模型对齐",
      "人类偏好数据",
      "数据诊断",
      "数据效率",
      "GPT-4o",
      "Alignment Data Map"
    ],
    "methods": [
      "Alignment Data Map构建",
      "GPT-4o辅助评分",
      "均值-方差分析",
      "高质量样本筛选"
    ],
    "problems": [
      "如何高效收集和利用人类偏好数据以对齐大语言模型",
      "如何诊断和筛选偏好数据中的高质量样本",
      "如何发现低影响或误标注的数据样本"
    ]
  },
  "2505.23143": {
    "classification_path": "计算机科学 → 医学图像 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于胸部X光片的自动化解读，核心贡献是提出了一个模拟临床推理流程的多阶段视觉问答数据集（CXRTrek）以及相应的视觉-语言大模型（CXRTrekNet），用于医学影像的问答式推理。虽然涉及多模态和大模型，但主要任务是医学图像领域下的问答系统，且没有涉及医学图像分割、目标检测等具体任务，因此选择'医学图像 → 问答系统'作为最合适的分类路径。",
      "keywords": [
        "胸部X光片",
        "医学影像",
        "视觉问答",
        "临床推理",
        "多阶段推理",
        "视觉-语言模型",
        "数据集"
      ],
      "methods": [
        "多阶段视觉问答数据集构建（CXRTrek）",
        "视觉-语言大模型（CXRTrekNet）",
        "临床推理流程建模",
        "跨阶段依赖建模"
      ],
      "problems": [
        "现有医学AI模型缺乏对临床诊断推理流程的建模",
        "模型推理过程与真实临床场景不一致，缺乏可追溯性",
        "如何构建能反映真实诊断推理流程的医学影像问答数据集",
        "如何设计能有效建模多阶段推理依赖关系的视觉-语言模型"
      ]
    },
    "keywords": [
      "胸部X光片",
      "医学影像",
      "视觉问答",
      "临床推理",
      "多阶段推理",
      "视觉-语言模型",
      "数据集"
    ],
    "methods": [
      "多阶段视觉问答数据集构建（CXRTrek）",
      "视觉-语言大模型（CXRTrekNet）",
      "临床推理流程建模",
      "跨阶段依赖建模"
    ],
    "problems": [
      "现有医学AI模型缺乏对临床诊断推理流程的建模",
      "模型推理过程与真实临床场景不一致，缺乏可追溯性",
      "如何构建能反映真实诊断推理流程的医学影像问答数据集",
      "如何设计能有效建模多阶段推理依赖关系的视觉-语言模型"
    ]
  },
  "2505.23118": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 医学多模态推理",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "医学多模态推理",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于提升医学场景下的多模态推理能力，提出了针对医学多模态推理的两阶段后训练流程。虽然涉及自然语言和医学图像，但核心创新在于多模态信息融合与推理能力提升，属于多模态学习范畴。具体任务为医学多模态推理，属于问答系统下的细分应用。",
      "keywords": [
        "多模态推理",
        "医学场景",
        "后训练",
        "模型微调",
        "医学问答",
        "推理能力提升"
      ],
      "methods": [
        "两阶段后训练流程（MedE^2）",
        "文本推理微调",
        "多模态医学案例增强",
        "偏好对齐"
      ],
      "problems": [
        "如何提升医学领域多模态模型的推理能力",
        "如何通过后训练流程有效引导和增强模型的医学推理表现",
        "医学多模态推理模型在实际临床决策中的可靠性与实用性验证"
      ]
    },
    "keywords": [
      "多模态推理",
      "医学场景",
      "后训练",
      "模型微调",
      "医学问答",
      "推理能力提升"
    ],
    "methods": [
      "两阶段后训练流程（MedE^2）",
      "文本推理微调",
      "多模态医学案例增强",
      "偏好对齐"
    ],
    "problems": [
      "如何提升医学领域多模态模型的推理能力",
      "如何通过后训练流程有效引导和增强模型的医学推理表现",
      "医学多模态推理模型在实际临床决策中的可靠性与实用性验证"
    ]
  },
  "2505.23145": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于基于扩散模型（如Stable Diffusion 3）的图像编辑方法，提出了一种无反演、流式的图像编辑框架FlowAlign，并通过引入流匹配损失提升编辑轨迹的稳定性和一致性。论文的主要创新点和实验均围绕扩散模型在图像生成与编辑中的应用展开，因此最合适的分类路径为‘计算机科学 → 计算机视觉 → 生成模型 → 扩散模型’。",
      "keywords": [
        "图像编辑",
        "扩散模型",
        "流模型",
        "无反演",
        "轨迹正则化",
        "Stable Diffusion",
        "流匹配损失",
        "可逆编辑"
      ],
      "methods": [
        "无反演流式图像编辑",
        "流匹配损失正则化",
        "ODE轨迹控制",
        "可逆编辑操作"
      ],
      "problems": [
        "如何在无反演的流式图像编辑中提升编辑轨迹的稳定性和源图一致性",
        "如何在扩散模型驱动的图像编辑中实现语义对齐与结构保持的平衡",
        "如何实现可逆且一致的图像编辑过程"
      ]
    },
    "keywords": [
      "图像编辑",
      "扩散模型",
      "流模型",
      "无反演",
      "轨迹正则化",
      "Stable Diffusion",
      "流匹配损失",
      "可逆编辑"
    ],
    "methods": [
      "无反演流式图像编辑",
      "流匹配损失正则化",
      "ODE轨迹控制",
      "可逆编辑操作"
    ],
    "problems": [
      "如何在无反演的流式图像编辑中提升编辑轨迹的稳定性和源图一致性",
      "如何在扩散模型驱动的图像编辑中实现语义对齐与结构保持的平衡",
      "如何实现可逆且一致的图像编辑过程"
    ]
  },
  "2505.23121": {
    "classification_path": "计算机科学 → 多模态学习 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于多模态大语言模型在多轮多模态对话中的上下文建模能力提升，提出了ContextQFormer模块，并构建了多轮多模态对话数据集TMDialog。论文核心任务是提升多模态对话系统的上下文理解与交互能力，属于多模态学习下的对话系统范畴。虽然涉及大语言模型，但主要创新点和实验均围绕多模态对话展开，因此选择'多模态学习 → 对话系统'作为最合适的分类路径。",
      "keywords": [
        "多模态对话",
        "上下文建模",
        "ContextQFormer",
        "多轮对话",
        "大语言模型",
        "TMDialog数据集"
      ],
      "methods": [
        "引入ContextQFormer上下文建模模块",
        "利用记忆块增强上下文表示",
        "构建并使用TMDialog多轮多模态对话数据集",
        "与多模态对话基线模型对比实验"
      ],
      "problems": [
        "提升多模态大语言模型在多轮对话中的上下文理解能力",
        "解决现有多模态模型在长上下文多轮交互中的性能不足",
        "缺乏支持长对话、多模态交互的数据集"
      ]
    },
    "keywords": [
      "多模态对话",
      "上下文建模",
      "ContextQFormer",
      "多轮对话",
      "大语言模型",
      "TMDialog数据集"
    ],
    "methods": [
      "引入ContextQFormer上下文建模模块",
      "利用记忆块增强上下文表示",
      "构建并使用TMDialog多轮多模态对话数据集",
      "与多模态对话基线模型对比实验"
    ],
    "problems": [
      "提升多模态大语言模型在多轮对话中的上下文理解能力",
      "解决现有多模态模型在长上下文多轮交互中的性能不足",
      "缺乏支持长对话、多模态交互的数据集"
    ]
  },
  "2505.23155": {
    "classification_path": "计算机科学 → 多模态学习 → 视频理解 → 音视频事件解析",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "视频理解",
      "level3": "音视频事件解析",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究音频与视觉信息的联合解析，属于多模态学习领域。其核心任务是对视频流中的音频、视觉及音视频事件进行解析，属于视频理解的范畴。论文提出了新的在线音视频事件解析任务（On-AVEP），并针对该任务提出了Predictive Future Modeling (PreFM) 框架，因此最合适的四级分类为‘音视频事件解析’。",
      "keywords": [
        "多模态学习",
        "音视频事件解析",
        "在线推理",
        "未来预测建模",
        "实时视频理解"
      ],
      "methods": [
        "Predictive Future Modeling (PreFM)",
        "预测性多模态未来建模",
        "模态无关鲁棒表示",
        "时序优先机制"
      ],
      "problems": [
        "如何在实时场景下高效解析音频、视觉及音视频事件",
        "如何在上下文有限的在线环境中提升事件解析的准确性",
        "如何在保证模型性能的同时降低计算资源消耗"
      ]
    },
    "keywords": [
      "多模态学习",
      "音视频事件解析",
      "在线推理",
      "未来预测建模",
      "实时视频理解"
    ],
    "methods": [
      "Predictive Future Modeling (PreFM)",
      "预测性多模态未来建模",
      "模态无关鲁棒表示",
      "时序优先机制"
    ],
    "problems": [
      "如何在实时场景下高效解析音频、视觉及音视频事件",
      "如何在上下文有限的在线环境中提升事件解析的准确性",
      "如何在保证模型性能的同时降低计算资源消耗"
    ]
  },
  "2505.23126": {
    "classification_path": "计算机科学 → 自然语言处理 → 代码生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "代码生成",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于基于示例的编程（Programming by Examples），并以历史语言学为灵感，提出了一个用于推理能力评测的新基准。该任务本质上属于自然语言处理领域下的代码生成方向，因为它涉及通过自然语言示例推断程序规则，且与传统的代码生成任务高度相关。虽然论文也涉及大语言模型的推理能力评测，但主要任务是基于示例的程序归纳，因此选择'自然语言处理 → 代码生成'作为最合适的分类路径。",
      "keywords": [
        "Programming by Examples",
        "Benchmark",
        "Reasoning",
        "Historical Linguistics",
        "Large Language Models",
        "Inductive Reasoning"
      ],
      "methods": [
        "自动化基准生成管道",
        "动态难度控制",
        "大语言模型推理能力评测"
      ],
      "problems": [
        "现有大语言模型在历史语言学启发的归纳推理任务上的能力不足",
        "如何自动化生成可控难度且无污染的推理基准",
        "评估和分析大语言模型在多步推理任务中的表现"
      ]
    },
    "keywords": [
      "Programming by Examples",
      "Benchmark",
      "Reasoning",
      "Historical Linguistics",
      "Large Language Models",
      "Inductive Reasoning"
    ],
    "methods": [
      "自动化基准生成管道",
      "动态难度控制",
      "大语言模型推理能力评测"
    ],
    "problems": [
      "现有大语言模型在历史语言学启发的归纳推理任务上的能力不足",
      "如何自动化生成可控难度且无污染的推理基准",
      "评估和分析大语言模型在多步推理任务中的表现"
    ]
  },
  "2505.23158": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了一种用于3D Gaussian Splatting的层次细节（LOD）方法，主要关注于大规模场景的高效三维渲染与重建，核心任务属于三维重建领域。虽然涉及渲染优化，但其本质是通过层次化和分块等技术提升三维场景的重建与可视化效率，因此归类为‘计算机视觉 → 三维重建’最为合适。",
      "keywords": [
        "Level-of-Detail",
        "3D Gaussian Splatting",
        "大规模场景",
        "高效渲染",
        "层次细节",
        "GPU内存优化",
        "空间分块",
        "实时渲染"
      ],
      "methods": [
        "分层LOD表示",
        "基于相机距离的高斯子集选择",
        "深度感知3D平滑滤波",
        "基于重要性的剪枝与微调",
        "空间分块与动态加载",
        "不透明度混合机制"
      ],
      "problems": [
        "如何在内存受限设备上实现大规模3D场景的实时高质量渲染",
        "如何降低三维高斯渲染的时间和GPU内存消耗",
        "如何在分块渲染时避免块边界的视觉伪影"
      ]
    },
    "keywords": [
      "Level-of-Detail",
      "3D Gaussian Splatting",
      "大规模场景",
      "高效渲染",
      "层次细节",
      "GPU内存优化",
      "空间分块",
      "实时渲染"
    ],
    "methods": [
      "分层LOD表示",
      "基于相机距离的高斯子集选择",
      "深度感知3D平滑滤波",
      "基于重要性的剪枝与微调",
      "空间分块与动态加载",
      "不透明度混合机制"
    ],
    "problems": [
      "如何在内存受限设备上实现大规模3D场景的实时高质量渲染",
      "如何降低三维高斯渲染的时间和GPU内存消耗",
      "如何在分块渲染时避免块边界的视觉伪影"
    ]
  },
  "2505.23140": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于提升大语言模型在机器翻译任务中的表现，属于自然语言处理领域。虽然论文涉及大语言模型，但其核心任务是机器翻译，且方法为动态语义聚焦，属于生成模型范畴。标准词表中未包含'机器翻译'或'翻译'等更细分任务，因此选择'生成模型'作为三级领域，四级领域设为null。",
      "keywords": [
        "大语言模型",
        "机器翻译",
        "上下文敏感单元",
        "动态聚焦锚定",
        "语义聚焦",
        "多语言",
        "翻译准确性"
      ],
      "methods": [
        "动态分析与识别翻译难点",
        "结构化注入语义聚焦信息",
        "无需额外训练的增强方法"
      ],
      "problems": [
        "大语言模型在处理上下文敏感单元时的翻译错误",
        "多义词等难点导致的翻译失败",
        "提升大语言模型在多语言机器翻译任务中的准确性和鲁棒性"
      ]
    },
    "keywords": [
      "大语言模型",
      "机器翻译",
      "上下文敏感单元",
      "动态聚焦锚定",
      "语义聚焦",
      "多语言",
      "翻译准确性"
    ],
    "methods": [
      "动态分析与识别翻译难点",
      "结构化注入语义聚焦信息",
      "无需额外训练的增强方法"
    ],
    "problems": [
      "大语言模型在处理上下文敏感单元时的翻译错误",
      "多义词等难点导致的翻译失败",
      "提升大语言模型在多语言机器翻译任务中的准确性和鲁棒性"
    ]
  },
  "2505.23161": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 文本到图像生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "文本到图像生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究如何利用CLIP模型本身（无需额外解码器或训练）实现图像生成任务，包括文本到图像生成、风格迁移和图像重建。虽然CLIP是多模态模型，但论文核心贡献在于将其用于图像生成，因此归入计算机视觉-生成模型-文本到图像生成最为合适。",
      "keywords": [
        "CLIP",
        "隐式反演",
        "图像生成",
        "文本到图像",
        "风格迁移",
        "图像重建",
        "频率感知",
        "正交Procrustes投影",
        "自然图像统计"
      ],
      "methods": [
        "频率感知隐式神经表示优化",
        "分层频率生成策略",
        "对抗鲁棒初始化",
        "正交Procrustes投影对齐文本与图像嵌入",
        "混合损失函数锚定自然图像统计"
      ],
      "problems": [
        "如何在不引入额外解码器或训练的情况下，仅用CLIP实现高质量图像生成",
        "如何稳定从共享嵌入空间到图像的逆映射过程",
        "如何提升CLIP在生成任务中的表现和泛化能力"
      ]
    },
    "keywords": [
      "CLIP",
      "隐式反演",
      "图像生成",
      "文本到图像",
      "风格迁移",
      "图像重建",
      "频率感知",
      "正交Procrustes投影",
      "自然图像统计"
    ],
    "methods": [
      "频率感知隐式神经表示优化",
      "分层频率生成策略",
      "对抗鲁棒初始化",
      "正交Procrustes投影对齐文本与图像嵌入",
      "混合损失函数锚定自然图像统计"
    ],
    "problems": [
      "如何在不引入额外解码器或训练的情况下，仅用CLIP实现高质量图像生成",
      "如何稳定从共享嵌入空间到图像的逆映射过程",
      "如何提升CLIP在生成任务中的表现和泛化能力"
    ]
  },
  "2505.23146": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究跨领域双语词典自动构建（Bilingual Lexicon Induction），属于自然语言处理领域。虽然标准三级领域没有直接对应'词典归纳'或'词汇翻译'，但BLI与跨语言词汇对齐、词汇翻译等任务密切相关，通常归属于自然语言处理下的语言理解、翻译或问答系统等应用。考虑到标准词表，'问答系统'是最接近的具体任务，因为BLI的目标是自动获取词语的跨语言对应关系，服务于下游问答、翻译等任务，因此选择'问答系统'作为三级领域，四级领域无更细分，设为null。",
      "keywords": [
        "Bilingual Lexicon Induction",
        "跨领域",
        "预训练语言模型",
        "词嵌入对齐",
        "领域自适应",
        "Code Switch"
      ],
      "methods": [
        "基于预训练语言模型的词嵌入获取",
        "跨领域词嵌入对齐",
        "引入Code Switch策略",
        "对比Muse和Vecmap等BLI基线方法"
      ],
      "problems": [
        "如何在领域数据有限、专业词汇低频的情况下提升跨领域双语词典归纳的准确性",
        "静态词嵌入在专业领域词汇语义表达上的局限性",
        "现有BLI方法在专业领域（如医学）表现不佳，如何改进"
      ]
    },
    "keywords": [
      "Bilingual Lexicon Induction",
      "跨领域",
      "预训练语言模型",
      "词嵌入对齐",
      "领域自适应",
      "Code Switch"
    ],
    "methods": [
      "基于预训练语言模型的词嵌入获取",
      "跨领域词嵌入对齐",
      "引入Code Switch策略",
      "对比Muse和Vecmap等BLI基线方法"
    ],
    "problems": [
      "如何在领域数据有限、专业词汇低频的情况下提升跨领域双语词典归纳的准确性",
      "静态词嵌入在专业领域词汇语义表达上的局限性",
      "现有BLI方法在专业领域（如医学）表现不佳，如何改进"
    ]
  },
  "2505.23171": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文提出了RoboTransfer，一个基于扩散模型的视频生成框架，专注于机器人视觉策略迁移。其核心创新在于结合多视角几何一致性和对场景组件的显式控制，属于计算机视觉领域下的生成模型，具体方法为扩散模型。虽然应用场景为机器人学，但主要技术贡献和方法创新集中在视觉生成模型，因此选择'计算机视觉 → 生成模型 → 扩散模型'作为最合适的分类路径。",
      "keywords": [
        "扩散模型",
        "视频生成",
        "几何一致性",
        "多视角",
        "机器人视觉策略迁移",
        "仿真到现实",
        "数据合成"
      ],
      "methods": [
        "基于扩散的视频生成框架",
        "多视角几何一致性建模",
        "跨视角特征交互",
        "全局深度/法线条件",
        "场景组件显式控制"
      ],
      "problems": [
        "如何高效生成具有几何一致性和高视觉保真度的多视角机器人操作视频",
        "如何缩小仿真到现实的视觉策略迁移鸿沟",
        "如何通过合成数据提升机器人视觉策略的泛化能力"
      ]
    },
    "keywords": [
      "扩散模型",
      "视频生成",
      "几何一致性",
      "多视角",
      "机器人视觉策略迁移",
      "仿真到现实",
      "数据合成"
    ],
    "methods": [
      "基于扩散的视频生成框架",
      "多视角几何一致性建模",
      "跨视角特征交互",
      "全局深度/法线条件",
      "场景组件显式控制"
    ],
    "problems": [
      "如何高效生成具有几何一致性和高视觉保真度的多视角机器人操作视频",
      "如何缩小仿真到现实的视觉策略迁移鸿沟",
      "如何通过合成数据提升机器人视觉策略的泛化能力"
    ]
  },
  "2505.23166": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注文学文本的主题建模，提出利用生成式语言模型对文学片段进行抽象复述（retelling），再用LDA进行主题建模。其核心创新点在于将生成模型（语言模型）的输出作为主题建模的输入，属于自然语言处理领域下的生成模型应用。论文没有涉及如问答系统、对话系统等更细分的具体任务，因此level3为null。",
      "keywords": [
        "主题建模",
        "文学文本",
        "生成式语言模型",
        "LDA",
        "抽象复述",
        "文化分析"
      ],
      "methods": [
        "利用生成式语言模型对文学片段进行抽象复述",
        "对复述文本应用LDA进行主题建模",
        "与专家注释结果对比分析"
      ],
      "problems": [
        "传统主题建模方法难以处理文学文本的抽象主题",
        "如何利用生成式语言模型提升文学主题建模的准确性和信息量",
        "如何将自动化方法应用于文化分析任务"
      ]
    },
    "keywords": [
      "主题建模",
      "文学文本",
      "生成式语言模型",
      "LDA",
      "抽象复述",
      "文化分析"
    ],
    "methods": [
      "利用生成式语言模型对文学片段进行抽象复述",
      "对复述文本应用LDA进行主题建模",
      "与专家注释结果对比分析"
    ],
    "problems": [
      "传统主题建模方法难以处理文学文本的抽象主题",
      "如何利用生成式语言模型提升文学主题建模的准确性和信息量",
      "如何将自动化方法应用于文化分析任务"
    ]
  },
  "2505.23179": {
    "classification_path": "计算机科学 → 多模态学习 → 目标检测 → 小目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "目标检测",
      "level3": "小目标检测",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于提升多模态大模型（MLLMs）在复杂真实场景下的细粒度视觉感知能力，尤其是在密集人群等复杂环境中的目标检测与理解。方法核心为通过强化学习（RL）优化MLLMs的视觉感知流程，提升其对细粒度目标（如小目标、遮挡目标）的检测和理解能力。根据标准领域词表，'多模态学习'最能反映MLLMs的研究背景，'目标检测'对应论文的主要任务，'小目标检测'则贴合论文强调的复杂、密集场景下的细粒度感知问题。",
      "keywords": [
        "多模态大模型",
        "视觉感知",
        "强化学习",
        "复杂场景理解",
        "目标检测",
        "小目标检测",
        "奖励建模"
      ],
      "methods": [
        "基于强化学习的多模态视觉感知框架（DIP-R1）",
        "三阶段奖励建模（推理、观察、决策）",
        "方差引导的观察奖励",
        "加权精确率-召回率奖励"
      ],
      "problems": [
        "如何提升多模态大模型在复杂真实场景下的细粒度视觉感知能力",
        "如何通过强化学习优化模型对密集、遮挡等复杂区域的目标检测与理解",
        "如何设计有效的奖励机制以引导模型更好地观察和决策"
      ]
    },
    "keywords": [
      "多模态大模型",
      "视觉感知",
      "强化学习",
      "复杂场景理解",
      "目标检测",
      "小目标检测",
      "奖励建模"
    ],
    "methods": [
      "基于强化学习的多模态视觉感知框架（DIP-R1）",
      "三阶段奖励建模（推理、观察、决策）",
      "方差引导的观察奖励",
      "加权精确率-召回率奖励"
    ],
    "problems": [
      "如何提升多模态大模型在复杂真实场景下的细粒度视觉感知能力",
      "如何通过强化学习优化模型对密集、遮挡等复杂区域的目标检测与理解",
      "如何设计有效的奖励机制以引导模型更好地观察和决策"
    ]
  },
  "2505.23170": {
    "classification_path": "计算机科学 → 语音与音频处理 → 语音识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "语音与音频处理",
      "level2": "语音识别",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究多语言语音中的音素识别（phone recognition），属于语音识别的细分任务。虽然涉及多语言和跨语言泛化，但核心任务是对语音信号中的音素进行识别，最符合'语音与音频处理 → 语音识别'的标准分类。标准领域词表中没有更细的'音素识别'，因此分类到'语音识别'层级。",
      "keywords": [
        "多语言语音识别",
        "音素识别",
        "跨语言",
        "高效模型",
        "IPAPack++",
        "Zipformer",
        "CTC",
        "转导器",
        "伪标签",
        "sociophonetic variation"
      ],
      "methods": [
        "大规模多语言语音数据集构建",
        "Zipformer骨干网络",
        "转导器模型（ZIPA-T）",
        "CTC模型（ZIPA-CR）",
        "noisy student训练",
        "伪标签学习"
      ],
      "problems": [
        "提升多语言音素识别的准确率与效率",
        "在参数量较小的情况下超越现有音素识别系统",
        "处理未见语言和社会音系变异带来的挑战",
        "分析模型在社会音系多样性建模上的局限性"
      ]
    },
    "keywords": [
      "多语言语音识别",
      "音素识别",
      "跨语言",
      "高效模型",
      "IPAPack++",
      "Zipformer",
      "CTC",
      "转导器",
      "伪标签",
      "sociophonetic variation"
    ],
    "methods": [
      "大规模多语言语音数据集构建",
      "Zipformer骨干网络",
      "转导器模型（ZIPA-T）",
      "CTC模型（ZIPA-CR）",
      "noisy student训练",
      "伪标签学习"
    ],
    "problems": [
      "提升多语言音素识别的准确率与效率",
      "在参数量较小的情况下超越现有音素识别系统",
      "处理未见语言和社会音系变异带来的挑战",
      "分析模型在社会音系多样性建模上的局限性"
    ]
  },
  "2505.23180": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于单像素成像（Single-Pixel Imaging, SPI）的重建问题，属于计算机视觉领域。SPI本质上是通过少量测量重建高维图像，属于计算机视觉中的重建类任务。虽然论文涉及深度展开（unrolling）、Plug-and-Play等优化与学习方法，但其核心任务是高效、灵活地重建图像，最贴近标准领域词表中的‘三维重建’（尽管SPI多为二维，但在标准词表下‘三维重建’泛指重建类任务）。其他三级领域如‘目标检测’、‘图像分割’等均不适用，因此选择‘三维重建’作为最接近的分类。",
      "keywords": [
        "单像素成像",
        "深度展开",
        "Plug-and-Play",
        "HQS",
        "ADMM",
        "图像重建",
        "压缩感知",
        "近端算法"
      ],
      "methods": [
        "深度展开（Unrolling）",
        "Plug-and-Play（PnP）方法",
        "HQS（Half Quadratic Splitting）展开",
        "ADMM（Alternating Direction Method of Multipliers）展开",
        "深度图像恢复器（DIR）设计",
        "近端轨迹损失函数（Proximal Trajectory Loss）"
      ],
      "problems": [
        "如何在单像素成像中兼顾灵活性与高效准确的图像重建",
        "如何设计既能适应不同压缩率又能提升重建速度和精度的神经网络模型",
        "如何将深度展开与Plug-and-Play方法的优点结合到单一模型中"
      ]
    },
    "keywords": [
      "单像素成像",
      "深度展开",
      "Plug-and-Play",
      "HQS",
      "ADMM",
      "图像重建",
      "压缩感知",
      "近端算法"
    ],
    "methods": [
      "深度展开（Unrolling）",
      "Plug-and-Play（PnP）方法",
      "HQS（Half Quadratic Splitting）展开",
      "ADMM（Alternating Direction Method of Multipliers）展开",
      "深度图像恢复器（DIR）设计",
      "近端轨迹损失函数（Proximal Trajectory Loss）"
    ],
    "problems": [
      "如何在单像素成像中兼顾灵活性与高效准确的图像重建",
      "如何设计既能适应不同压缩率又能提升重建速度和精度的神经网络模型",
      "如何将深度展开与Plug-and-Play方法的优点结合到单一模型中"
    ]
  },
  "2505.23174": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型 → 文本到表格生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": "文本到表格生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于将非结构化文本自动转换为结构化表格（Text-to-Table generation），属于自然语言处理领域。其核心是生成结构化数据，最贴近'生成模型'三级领域。具体任务为'文本到表格生成'，这是自然语言生成的一个细分应用，因此选择此分类路径。",
      "keywords": [
        "文本到表格生成",
        "结构化摘要",
        "信息抽取",
        "表格生成",
        "schema引导",
        "Map&Make",
        "自然语言处理"
      ],
      "methods": [
        "Map&Make方法",
        "命题分解",
        "schema抽取",
        "表格填充",
        "消除幻觉错误",
        "消融实验",
        "无参考评测"
      ],
      "problems": [
        "如何从复杂、非结构化文本中自动生成可解释、结构化的表格？",
        "如何抽取和推断文本中的复杂信息并映射到表格schema？",
        "如何提升Text-to-Table生成的准确性和可解释性，减少幻觉错误？"
      ]
    },
    "keywords": [
      "文本到表格生成",
      "结构化摘要",
      "信息抽取",
      "表格生成",
      "schema引导",
      "Map&Make",
      "自然语言处理"
    ],
    "methods": [
      "Map&Make方法",
      "命题分解",
      "schema抽取",
      "表格填充",
      "消除幻觉错误",
      "消融实验",
      "无参考评测"
    ],
    "problems": [
      "如何从复杂、非结构化文本中自动生成可解释、结构化的表格？",
      "如何抽取和推断文本中的复杂信息并映射到表格schema？",
      "如何提升Text-to-Table生成的准确性和可解释性，减少幻觉错误？"
    ]
  },
  "2505.23186": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究基于扩散模型的服装图像生成任务，属于计算机视觉领域中的生成模型方向。论文提出了一种新的扩散模型框架（HiGarment），用于将服装平面草图和文本描述生成真实感服装图像，属于典型的扩散模型应用。虽然涉及多模态输入（图像+文本），但核心任务是视觉生成，因此归入计算机视觉-生成模型-扩散模型最为合适。",
      "keywords": [
        "扩散模型",
        "服装图像生成",
        "多模态融合",
        "平面草图",
        "文本引导",
        "服装合成"
      ],
      "methods": [
        "多模态语义增强机制",
        "跨模态和谐注意力机制",
        "扩散模型",
        "大规模多模态服装数据集构建"
      ],
      "problems": [
        "如何仅依靠文本提示有效引导扩散模型生成具有细致面料特征的服装图像",
        "如何解决平面草图与文本描述之间可能存在的冲突，实现结构一致且可控的服装图像合成"
      ]
    },
    "keywords": [
      "扩散模型",
      "服装图像生成",
      "多模态融合",
      "平面草图",
      "文本引导",
      "服装合成"
    ],
    "methods": [
      "多模态语义增强机制",
      "跨模态和谐注意力机制",
      "扩散模型",
      "大规模多模态服装数据集构建"
    ],
    "problems": [
      "如何仅依靠文本提示有效引导扩散模型生成具有细致面料特征的服装图像",
      "如何解决平面草图与文本描述之间可能存在的冲突，实现结构一致且可控的服装图像合成"
    ]
  },
  "2505.23177": {
    "classification_path": "计算机科学 → 大语言模型 → 代码生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "代码生成",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于提升大语言模型在代码生成任务上的能力，提出了自动化合成高质量代码指令数据的框架Infinite-Instruct。论文的核心是通过数据合成和静态验证提升代码生成数据集的多样性和逻辑性，并在主流代码生成基准上验证了效果。虽然涉及数据生成和问答对构建，但主要贡献和实验均围绕大语言模型的代码生成能力提升，因此选择“大语言模型 → 代码生成”作为最合适的分类路径。",
      "keywords": [
        "代码生成",
        "大语言模型",
        "数据合成",
        "静态验证",
        "指令微调",
        "编程问题",
        "自动化数据构建"
      ],
      "methods": [
        "反向构造（Reverse Construction）",
        "回馈构造（Backfeeding Construction）",
        "知识图谱重构",
        "跨语言静态代码分析",
        "自动化数据过滤"
      ],
      "problems": [
        "如何自动合成高质量、多样化且具备良好逻辑的代码指令数据以提升大语言模型的代码生成能力？",
        "如何通过静态分析等手段过滤无效样本，保证合成数据的质量？",
        "如何在有限数据量下实现大语言模型代码生成能力的高效提升？"
      ]
    },
    "keywords": [
      "代码生成",
      "大语言模型",
      "数据合成",
      "静态验证",
      "指令微调",
      "编程问题",
      "自动化数据构建"
    ],
    "methods": [
      "反向构造（Reverse Construction）",
      "回馈构造（Backfeeding Construction）",
      "知识图谱重构",
      "跨语言静态代码分析",
      "自动化数据过滤"
    ],
    "problems": [
      "如何自动合成高质量、多样化且具备良好逻辑的代码指令数据以提升大语言模型的代码生成能力？",
      "如何通过静态分析等手段过滤无效样本，保证合成数据的质量？",
      "如何在有限数据量下实现大语言模型代码生成能力的高效提升？"
    ]
  },
  "2505.23192": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于针对文本到图像（T2I）生成模型的AIGC检测器进行对抗攻击，核心内容为生成对抗性提示以欺骗AIGC检测器。虽然涉及安全性和多模态，但主要研究对象是计算机视觉领域中的生成模型（T2I），且标准词表下没有更细的四级任务可选，因此归为‘计算机视觉 → 生成模型’。",
      "keywords": [
        "AIGC检测",
        "对抗性提示",
        "文本到图像生成",
        "生成模型",
        "Monte Carlo树搜索",
        "语义攻击"
      ],
      "methods": [
        "自动化对抗性提示生成框架",
        "语法树结构",
        "Monte Carlo树搜索变体"
      ],
      "problems": [
        "如何系统性生成能够欺骗AIGC检测器的对抗性提示",
        "如何提升AIGC检测器的鲁棒性",
        "如何构建高质量的对抗性数据集用于检测与防御系统训练"
      ]
    },
    "keywords": [
      "AIGC检测",
      "对抗性提示",
      "文本到图像生成",
      "生成模型",
      "Monte Carlo树搜索",
      "语义攻击"
    ],
    "methods": [
      "自动化对抗性提示生成框架",
      "语法树结构",
      "Monte Carlo树搜索变体"
    ],
    "problems": [
      "如何系统性生成能够欺骗AIGC检测器的对抗性提示",
      "如何提升AIGC检测器的鲁棒性",
      "如何构建高质量的对抗性数据集用于检测与防御系统训练"
    ]
  },
  "2505.23183": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于机器翻译的词级质量估计（WQE），属于自然语言处理领域。虽然标准三级领域没有直接包含'机器翻译'或'质量估计'，但在给定的标准词表中，'问答系统'是最接近的具体NLP任务类别。由于没有更细致的任务选项，选择'问答系统'作为三级领域，并将level3设为null。",
      "keywords": [
        "机器翻译",
        "质量估计",
        "无监督方法",
        "词级评估",
        "人类标注一致性",
        "不确定性量化",
        "语言模型解释性"
      ],
      "methods": [
        "无监督质量估计方法",
        "语言模型解释性技术",
        "不确定性量化",
        "多标注集评估",
        "指标对比分析"
      ],
      "problems": [
        "如何在无需大量人工标注的情况下实现高效的机器翻译词级质量估计？",
        "人类标注一致性对质量估计指标性能有何影响？",
        "无监督方法在面对标注不确定性时能否优于有监督方法？"
      ]
    },
    "keywords": [
      "机器翻译",
      "质量估计",
      "无监督方法",
      "词级评估",
      "人类标注一致性",
      "不确定性量化",
      "语言模型解释性"
    ],
    "methods": [
      "无监督质量估计方法",
      "语言模型解释性技术",
      "不确定性量化",
      "多标注集评估",
      "指标对比分析"
    ],
    "problems": [
      "如何在无需大量人工标注的情况下实现高效的机器翻译词级质量估计？",
      "人类标注一致性对质量估计指标性能有何影响？",
      "无监督方法在面对标注不确定性时能否优于有监督方法？"
    ]
  },
  "2505.23193": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "小样本学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究遥感/航空图像中的目标检测问题，属于计算机视觉领域下的目标检测任务。论文提出了利用语言引导的学习方法来提升检测性能，尤其关注于应对图像中的多种变化（如视角、光照等），并通过语义推理和关系学习损失来增强模型的鲁棒性。这些方法与小样本学习中的泛化和鲁棒性提升密切相关，因此选择'小样本学习'作为第4级具体任务。",
      "keywords": [
        "目标检测",
        "遥感图像",
        "语言引导学习",
        "视觉语义推理",
        "关系学习损失",
        "多样性变化",
        "小样本学习"
      ],
      "methods": [
        "语言引导的目标检测框架（LANGO）",
        "视觉语义推理模块",
        "关系学习损失函数"
      ],
      "problems": [
        "如何提升遥感/航空图像中目标检测对多种变化（如光照、视角等）的鲁棒性",
        "如何利用语言语义信息辅助目标检测以缓解场景和实例级别的变化影响"
      ]
    },
    "keywords": [
      "目标检测",
      "遥感图像",
      "语言引导学习",
      "视觉语义推理",
      "关系学习损失",
      "多样性变化",
      "小样本学习"
    ],
    "methods": [
      "语言引导的目标检测框架（LANGO）",
      "视觉语义推理模块",
      "关系学习损失函数"
    ],
    "problems": [
      "如何提升遥感/航空图像中目标检测对多种变化（如光照、视角等）的鲁棒性",
      "如何利用语言语义信息辅助目标检测以缓解场景和实例级别的变化影响"
    ]
  },
  "2505.23187": {
    "classification_path": "计算机科学 → 大语言模型 → 对话系统 → 多智能体协作",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "对话系统",
      "level3": "多智能体协作",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于基于大语言模型（LLM）的多智能体系统（MAS）在复杂任务中的协作与经验迁移学习。论文提出了跨任务经验学习框架（MAEL），提升了多智能体在任务推理和协作中的泛化能力。虽然涉及多智能体和强化学习思想，但核心创新点在于LLM驱动的多智能体协作与经验迁移，最贴合'大语言模型 → 对话系统 → 多智能体协作'这一分类路径。",
      "keywords": [
        "大语言模型",
        "多智能体系统",
        "跨任务学习",
        "经验迁移",
        "协作推理",
        "信息传播",
        "经验池"
      ],
      "methods": [
        "多智能体跨任务经验学习（MAEL）框架",
        "图结构多智能体协作网络建模",
        "经验池奖励存储与检索",
        "基于高奖励经验的few-shot推理"
      ],
      "problems": [
        "如何提升LLM驱动多智能体系统在结构相似任务间的泛化与协作效率",
        "如何通过跨任务经验积累减少冗余计算并提升任务求解质量"
      ]
    },
    "keywords": [
      "大语言模型",
      "多智能体系统",
      "跨任务学习",
      "经验迁移",
      "协作推理",
      "信息传播",
      "经验池"
    ],
    "methods": [
      "多智能体跨任务经验学习（MAEL）框架",
      "图结构多智能体协作网络建模",
      "经验池奖励存储与检索",
      "基于高奖励经验的few-shot推理"
    ],
    "problems": [
      "如何提升LLM驱动多智能体系统在结构相似任务间的泛化与协作效率",
      "如何通过跨任务经验积累减少冗余计算并提升任务求解质量"
    ]
  },
  "2505.23201": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于低光照环境下的实时目标检测方法，主要贡献为提出了WTEFNet框架以提升自动驾驶辅助系统中的目标检测性能。论文内容明确属于计算机视觉领域，具体任务为目标检测，未涉及如小目标检测等更细分的四级任务，因此分类深度为3。",
      "keywords": [
        "低光照目标检测",
        "实时检测",
        "自动驾驶辅助系统",
        "图像增强",
        "特征融合",
        "波形变换",
        "多模态融合",
        "GSN数据集"
      ],
      "methods": [
        "低光照增强模块（LLE）",
        "基于小波的特征提取模块（WFE）",
        "自适应融合检测模块（AFFD）",
        "多级离散小波变换",
        "语义与光照特征融合",
        "GSN夜间数据集构建",
        "嵌入式平台部署"
      ],
      "problems": [
        "低光照条件下RGB相机目标检测性能下降",
        "如何提升自动驾驶辅助系统在夜间或恶劣光照下的目标检测准确率与实时性",
        "如何有效融合图像增强与特征提取以提升检测鲁棒性"
      ]
    },
    "keywords": [
      "低光照目标检测",
      "实时检测",
      "自动驾驶辅助系统",
      "图像增强",
      "特征融合",
      "波形变换",
      "多模态融合",
      "GSN数据集"
    ],
    "methods": [
      "低光照增强模块（LLE）",
      "基于小波的特征提取模块（WFE）",
      "自适应融合检测模块（AFFD）",
      "多级离散小波变换",
      "语义与光照特征融合",
      "GSN夜间数据集构建",
      "嵌入式平台部署"
    ],
    "problems": [
      "低光照条件下RGB相机目标检测性能下降",
      "如何提升自动驾驶辅助系统在夜间或恶劣光照下的目标检测准确率与实时性",
      "如何有效融合图像增强与特征提取以提升检测鲁棒性"
    ]
  },
  "2505.23191": {
    "classification_path": "计算机科学 → 大语言模型 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）如何通过经验迁移提升在新任务上的表现，核心是无需大量人工标注或任务经验，自动将已有任务经验迁移到新任务，属于大语言模型领域下的小样本学习（few-shot learning）范畴。论文没有聚焦于具体的问答、对话等应用任务，而是提出了一种通用的经验迁移框架，因此level3为null。",
      "keywords": [
        "大语言模型",
        "经验迁移",
        "小样本学习",
        "自主学习",
        "任务泛化"
      ],
      "methods": [
        "自主经验迁移框架",
        "模块化分析",
        "跨任务迁移"
      ],
      "problems": [
        "如何降低为每个任务收集经验的人工和时间成本",
        "LLMs能否像人类一样自主迁移经验以提升新任务表现",
        "如何提升大语言模型在多样化任务上的泛化能力"
      ]
    },
    "keywords": [
      "大语言模型",
      "经验迁移",
      "小样本学习",
      "自主学习",
      "任务泛化"
    ],
    "methods": [
      "自主经验迁移框架",
      "模块化分析",
      "跨任务迁移"
    ],
    "problems": [
      "如何降低为每个任务收集经验的人工和时间成本",
      "LLMs能否像人类一样自主迁移经验以提升新任务表现",
      "如何提升大语言模型在多样化任务上的泛化能力"
    ]
  },
  "2505.23206": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 三维点云融合",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "三维点云融合",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究多模态遥感数据（如光谱和激光雷达/摄影测量）在三维空间中的融合与分类，提出了一种基于Transformer的三维点云多模态融合方法。论文核心任务是直接在3D点云空间进行特征融合与分类，属于计算机视觉领域下的三维重建方向，具体聚焦于三维点云数据的多模态融合与空间特征学习。虽然涉及多模态，但主要贡献和实验均围绕三维点云的视觉理解，因此选择'计算机视觉→三维重建→三维点云融合'作为最合适的分层分类。",
      "keywords": [
        "三维点云",
        "多模态融合",
        "Transformer",
        "交叉注意力",
        "遥感",
        "地物分类",
        "空间特征学习"
      ],
      "methods": [
        "三维点云多模态融合",
        "双分支Transformer模型",
        "基于交叉注意力的特征融合",
        "多尺度特征集成"
      ],
      "problems": [
        "如何充分利用三维点云中的多模态信息进行地物分类",
        "如何在三维空间内直接融合和学习不同模态（如光谱和几何）特征",
        "如何克服传统二维投影方法对三维空间特征学习的限制"
      ]
    },
    "keywords": [
      "三维点云",
      "多模态融合",
      "Transformer",
      "交叉注意力",
      "遥感",
      "地物分类",
      "空间特征学习"
    ],
    "methods": [
      "三维点云多模态融合",
      "双分支Transformer模型",
      "基于交叉注意力的特征融合",
      "多尺度特征集成"
    ],
    "problems": [
      "如何充分利用三维点云中的多模态信息进行地物分类",
      "如何在三维空间内直接融合和学习不同模态（如光谱和几何）特征",
      "如何克服传统二维投影方法对三维空间特征学习的限制"
    ]
  },
  "2505.23224": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于多模态大语言模型（MLLMs）的推理能力与知识边界感知，核心内容是通过推理步骤置信度校准提升多模态推理链的自我纠错能力。论文方法涉及文本与跨模态信号、监督微调与强化学习，主要应用于多模态推理与问答场景。标准领域词表中，多模态学习最贴切地反映了研究对象，问答系统则对应其主要任务。由于没有更细的多模态推理任务选项，选择问答系统作为三级领域。",
      "keywords": [
        "多模态大语言模型",
        "知识边界感知",
        "推理步骤置信度校准",
        "自我奖励信号",
        "强化学习",
        "多步推理"
      ],
      "methods": [
        "推理步骤置信度估计",
        "自我奖励信号融合（文本与跨模态）",
        "监督微调",
        "多重奖励函数强化学习"
      ],
      "problems": [
        "如何提升多模态大语言模型在推理过程中的知识边界感知能力",
        "如何在多步推理链中校准每一步的置信度，减少幻觉累积",
        "如何通过自我奖励信号和强化学习提升多模态推理的准确性与自我纠错能力"
      ]
    },
    "keywords": [
      "多模态大语言模型",
      "知识边界感知",
      "推理步骤置信度校准",
      "自我奖励信号",
      "强化学习",
      "多步推理"
    ],
    "methods": [
      "推理步骤置信度估计",
      "自我奖励信号融合（文本与跨模态）",
      "监督微调",
      "多重奖励函数强化学习"
    ],
    "problems": [
      "如何提升多模态大语言模型在推理过程中的知识边界感知能力",
      "如何在多步推理链中校准每一步的置信度，减少幻觉累积",
      "如何通过自我奖励信号和强化学习提升多模态推理的准确性与自我纠错能力"
    ]
  },
  "2505.23209": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注模型合并（model merging）以实现多任务能力，并在不使用数据的情况下探索模型精度与模型大小之间的权衡。虽然实验涵盖视觉和NLP任务，但核心创新在于提出了一种通用的、数据无关的模型合并框架FlexMerge，属于机器学习领域。由于其关注在有限数据（甚至无数据）条件下的模型泛化与合并，最贴近标准领域词表中的“小样本学习”。论文并未聚焦于具体的视觉或NLP任务，因此选择'小样本学习'作为三级领域，四级领域为null。",
      "keywords": [
        "模型合并",
        "多任务学习",
        "数据无关",
        "模型压缩",
        "精度-模型大小权衡",
        "FlexMerge"
      ],
      "methods": [
        "数据无关模型合并",
        "顺序块级合并",
        "FlexMerge框架",
        "多任务模型生成"
      ],
      "problems": [
        "如何在不使用数据的情况下合并多个单任务微调模型",
        "如何在模型精度和模型大小之间实现灵活权衡",
        "如何为多任务部署提供高效、灵活的模型合并方案"
      ]
    },
    "keywords": [
      "模型合并",
      "多任务学习",
      "数据无关",
      "模型压缩",
      "精度-模型大小权衡",
      "FlexMerge"
    ],
    "methods": [
      "数据无关模型合并",
      "顺序块级合并",
      "FlexMerge框架",
      "多任务模型生成"
    ],
    "problems": [
      "如何在不使用数据的情况下合并多个单任务微调模型",
      "如何在模型精度和模型大小之间实现灵活权衡",
      "如何为多任务部署提供高效、灵活的模型合并方案"
    ]
  },
  "2505.23229": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统 → 心理咨询对话生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": "心理咨询对话生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于心理咨询场景下的多轮对话生成，提出了基于MCTS与大语言模型结合的新方法，核心任务是生成符合心理咨询原则的对话数据。虽然涉及大语言模型和强化学习思想，但主要贡献和实验均围绕对话系统的具体应用展开，因此选择'自然语言处理→对话系统→心理咨询对话生成'作为最合适的分层分类路径。",
      "keywords": [
        "Monte Carlo Tree Search",
        "大语言模型",
        "心理咨询对话",
        "原则对齐",
        "自反性生成",
        "多轮对话",
        "PsyEval"
      ],
      "methods": [
        "MCTSr-Zero框架",
        "领域对齐目标",
        "Regeneration机制",
        "Meta-Prompt自适应",
        "多轮对话生成",
        "PsyLLM微调"
      ],
      "problems": [
        "如何在心理咨询等开放式对话场景下生成符合人类偏好和伦理原则的高质量对话",
        "如何将MCTS等结构化搜索方法有效应用于主观性强、无明确正确答案的对话生成任务",
        "如何提升大语言模型在心理咨询等人本领域中的原则一致性和表现"
      ]
    },
    "keywords": [
      "Monte Carlo Tree Search",
      "大语言模型",
      "心理咨询对话",
      "原则对齐",
      "自反性生成",
      "多轮对话",
      "PsyEval"
    ],
    "methods": [
      "MCTSr-Zero框架",
      "领域对齐目标",
      "Regeneration机制",
      "Meta-Prompt自适应",
      "多轮对话生成",
      "PsyLLM微调"
    ],
    "problems": [
      "如何在心理咨询等开放式对话场景下生成符合人类偏好和伦理原则的高质量对话",
      "如何将MCTS等结构化搜索方法有效应用于主观性强、无明确正确答案的对话生成任务",
      "如何提升大语言模型在心理咨询等人本领域中的原则一致性和表现"
    ]
  },
  "2505.23214": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 小目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "小目标检测",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于红外小目标检测（Infrared Small Target Detection, ISTD），属于目标检测的细分任务。论文提出了SAMamba框架，专门针对小目标在复杂背景下的检测难题，结合了层次化特征学习和高效的全局上下文建模。根据标准领域词表，'小目标检测'是'目标检测'下的具体任务，最贴合论文的主要研究内容。",
      "keywords": [
        "红外小目标检测",
        "层次化特征学习",
        "状态空间建模",
        "跨通道交互",
        "多尺度融合",
        "领域自适应"
      ],
      "methods": [
        "Feature Selection Adapter (FS-Adapter)",
        "Cross-Channel State-Space Interaction (CSI) 模块",
        "Detail-Preserving Contextual Fusion (DPCF) 模块",
        "SAM2 层次化特征学习",
        "Mamba 选择性序列建模"
      ],
      "problems": [
        "红外图像中小目标与复杂背景的低可区分性",
        "下采样导致的信息损失",
        "全局上下文建模效率低下",
        "自然图像与红外图像的领域差异",
        "多尺度目标检测中的细节保持"
      ]
    },
    "keywords": [
      "红外小目标检测",
      "层次化特征学习",
      "状态空间建模",
      "跨通道交互",
      "多尺度融合",
      "领域自适应"
    ],
    "methods": [
      "Feature Selection Adapter (FS-Adapter)",
      "Cross-Channel State-Space Interaction (CSI) 模块",
      "Detail-Preserving Contextual Fusion (DPCF) 模块",
      "SAM2 层次化特征学习",
      "Mamba 选择性序列建模"
    ],
    "problems": [
      "红外图像中小目标与复杂背景的低可区分性",
      "下采样导致的信息损失",
      "全局上下文建模效率低下",
      "自然图像与红外图像的领域差异",
      "多尺度目标检测中的细节保持"
    ]
  },
  "2505.23242": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 多模态问答",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "多模态问答",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于图表问答（Chart Question Answering, CQA），涉及视觉与语言的联合理解与推理，属于典型的多模态学习范畴。其核心任务是多模态问答，具体体现在对真实世界复杂图表的理解与问答能力评测与提升。因此，选择'多模态学习→问答系统→多模态问答'作为最合适的分层分类路径。",
      "keywords": [
        "多模态学习",
        "图表问答",
        "ChartMind",
        "基准数据集",
        "视觉语言模型",
        "推理能力",
        "ChartLLM",
        "上下文感知",
        "真实世界",
        "开放域输出"
      ],
      "methods": [
        "构建多任务、多语言、多格式的图表问答基准数据集（ChartMind）",
        "提出上下文感知、模型无关的ChartLLM框架",
        "关键上下文元素提取",
        "噪声减少",
        "多模态大模型推理增强",
        "与主流CQA范式（指令跟随、OCR增强、思维链）对比实验"
      ],
      "problems": [
        "现有图表问答评测方法与真实世界需求脱节，缺乏复杂、多样化场景覆盖",
        "如何提升多模态大模型在复杂真实图表问答任务中的推理与理解能力",
        "如何设计支持多任务、多语言、开放域输出的图表问答基准",
        "如何有效提取图表上下文信息以提升问答准确性"
      ]
    },
    "keywords": [
      "多模态学习",
      "图表问答",
      "ChartMind",
      "基准数据集",
      "视觉语言模型",
      "推理能力",
      "ChartLLM",
      "上下文感知",
      "真实世界",
      "开放域输出"
    ],
    "methods": [
      "构建多任务、多语言、多格式的图表问答基准数据集（ChartMind）",
      "提出上下文感知、模型无关的ChartLLM框架",
      "关键上下文元素提取",
      "噪声减少",
      "多模态大模型推理增强",
      "与主流CQA范式（指令跟随、OCR增强、思维链）对比实验"
    ],
    "problems": [
      "现有图表问答评测方法与真实世界需求脱节，缺乏复杂、多样化场景覆盖",
      "如何提升多模态大模型在复杂真实图表问答任务中的推理与理解能力",
      "如何设计支持多任务、多语言、开放域输出的图表问答基准",
      "如何有效提取图表上下文信息以提升问答准确性"
    ]
  },
  "2505.23248": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 图像超分辨率",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "图像超分辨率",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文系统综述了遥感图像超分辨率（RSISR）技术，属于计算机视觉领域。其核心任务是从低分辨率图像重建高分辨率图像，属于生成模型范畴。具体任务为图像超分辨率，且聚焦于遥感图像这一应用场景。标准领域词表中没有更细的遥感图像超分辨率分类，因此选择'生成模型→图像超分辨率'作为最合适的路径。",
      "keywords": [
        "遥感图像超分辨率",
        "高分辨率重建",
        "低分辨率图像",
        "生成模型",
        "评价指标",
        "数据集",
        "纹理保持",
        "几何结构"
      ],
      "methods": [
        "有监督学习方法",
        "无监督学习方法",
        "质量评价方法",
        "方法分类与综述"
      ],
      "problems": [
        "如何系统梳理和评价遥感图像超分辨率方法",
        "现有方法在大尺度退化下难以保持细粒度纹理和几何结构",
        "缺乏适用于真实遥感场景的评价协议和领域特定架构"
      ]
    },
    "keywords": [
      "遥感图像超分辨率",
      "高分辨率重建",
      "低分辨率图像",
      "生成模型",
      "评价指标",
      "数据集",
      "纹理保持",
      "几何结构"
    ],
    "methods": [
      "有监督学习方法",
      "无监督学习方法",
      "质量评价方法",
      "方法分类与综述"
    ],
    "problems": [
      "如何系统梳理和评价遥感图像超分辨率方法",
      "现有方法在大尺度退化下难以保持细粒度纹理和几何结构",
      "缺乏适用于真实遥感场景的评价协议和领域特定架构"
    ]
  },
  "2505.23252": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于从科学论文中自动抽取和多维管理研究方法（approaches），以提升相关方法的检索效率。其核心任务涉及信息抽取、文本结构分析和多维分类，属于自然语言处理领域。论文强调通过多维度结构化管理和查询科学方法，属于学术文献的结构化问答与检索范畴，因此选择'自然语言处理→问答系统'最为贴切。由于标准领域词表中没有更细致的任务（如'信息抽取'或'学术文献检索'），故level3设为null。",
      "keywords": [
        "多维分类",
        "科学方法管理",
        "信息抽取",
        "树结构相似度",
        "聚类算法",
        "学术文献",
        "问答系统"
      ],
      "methods": [
        "基于多层语言特征的approach模式识别（语义、篇章、句法、词汇）",
        "基于树结构的步骤相似度度量",
        "集合相似度度量",
        "自底向上的聚类算法构建多维分类树"
      ],
      "problems": [
        "如何高效从大规模科学论文中自动抽取和管理研究方法（approaches）",
        "如何构建多维度的分类体系以提升方法检索和利用效率",
        "如何通过结构化和聚类机制提升方法查询的相关性和检索速度"
      ]
    },
    "keywords": [
      "多维分类",
      "科学方法管理",
      "信息抽取",
      "树结构相似度",
      "聚类算法",
      "学术文献",
      "问答系统"
    ],
    "methods": [
      "基于多层语言特征的approach模式识别（语义、篇章、句法、词汇）",
      "基于树结构的步骤相似度度量",
      "集合相似度度量",
      "自底向上的聚类算法构建多维分类树"
    ],
    "problems": [
      "如何高效从大规模科学论文中自动抽取和管理研究方法（approaches）",
      "如何构建多维度的分类体系以提升方法检索和利用效率",
      "如何通过结构化和聚类机制提升方法查询的相关性和检索速度"
    ]
  },
  "2505.23253": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 三维纹理生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "三维纹理生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于3D形状的高保真纹理生成，提出了一个新的三维纹理生成框架UniTEX，核心创新点在于绕过传统UV映射，直接在三维空间中生成纹理函数，并结合大规模Transformer和扩散模型进行多视角纹理合成。其主要任务属于三维重建下的三维纹理生成，与三维重建领域的具体应用高度相关，因此选择'计算机视觉 → 三维重建 → 三维纹理生成'作为分类路径。",
      "keywords": [
        "3D纹理生成",
        "三维重建",
        "纹理函数",
        "扩散模型",
        "Transformer",
        "多视角合成",
        "高保真纹理"
      ],
      "methods": [
        "三维纹理函数（Texture Functions, TFs）",
        "基于Transformer的大型纹理模型（Large Texturing Model, LTM）",
        "基于LoRA的扩散Transformer（DiT）适配",
        "两阶段纹理生成框架"
      ],
      "problems": [
        "如何为3D形状生成高质量、一致性的纹理",
        "如何绕过UV映射带来的拓扑歧义问题",
        "如何利用2D先验提升3D纹理生成的质量与泛化能力"
      ]
    },
    "keywords": [
      "3D纹理生成",
      "三维重建",
      "纹理函数",
      "扩散模型",
      "Transformer",
      "多视角合成",
      "高保真纹理"
    ],
    "methods": [
      "三维纹理函数（Texture Functions, TFs）",
      "基于Transformer的大型纹理模型（Large Texturing Model, LTM）",
      "基于LoRA的扩散Transformer（DiT）适配",
      "两阶段纹理生成框架"
    ],
    "problems": [
      "如何为3D形状生成高质量、一致性的纹理",
      "如何绕过UV映射带来的拓扑歧义问题",
      "如何利用2D先验提升3D纹理生成的质量与泛化能力"
    ]
  },
  "2505.23276": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型 → 文本生成检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": "文本生成检测",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "论文聚焦于阿拉伯语大语言模型生成文本的风格分析与检测，属于自然语言处理领域。其核心任务是区分人类与机器生成的文本，涉及生成模型的分析与检测，因此选择'自然语言处理→生成模型→文本生成检测'作为最合适的分层分类路径。",
      "keywords": [
        "阿拉伯语",
        "大语言模型",
        "风格分析",
        "文本生成检测",
        "信息完整性",
        "跨领域泛化"
      ],
      "methods": [
        "风格特征分析（Stylometric Analysis）",
        "多模型文本生成（ALLaM, Jais, Llama, GPT-4）",
        "BERT检测模型",
        "多种生成策略（标题生成、内容感知生成、文本润色）",
        "跨领域分析"
      ],
      "problems": [
        "如何区分阿拉伯语中人类与大语言模型生成的文本？",
        "不同生成策略和模型架构下，机器生成文本的可检测性如何？",
        "现有检测方法在不同文本领域（学术、社交媒体）中的泛化能力如何？",
        "如何建立健壮的、语言学驱动的检测系统以维护阿拉伯语信息完整性？"
      ]
    },
    "keywords": [
      "阿拉伯语",
      "大语言模型",
      "风格分析",
      "文本生成检测",
      "信息完整性",
      "跨领域泛化"
    ],
    "methods": [
      "风格特征分析（Stylometric Analysis）",
      "多模型文本生成（ALLaM, Jais, Llama, GPT-4）",
      "BERT检测模型",
      "多种生成策略（标题生成、内容感知生成、文本润色）",
      "跨领域分析"
    ],
    "problems": [
      "如何区分阿拉伯语中人类与大语言模型生成的文本？",
      "不同生成策略和模型架构下，机器生成文本的可检测性如何？",
      "现有检测方法在不同文本领域（学术、社交媒体）中的泛化能力如何？",
      "如何建立健壮的、语言学驱动的检测系统以维护阿拉伯语信息完整性？"
    ]
  },
  "2505.23265": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 医学图像筛查",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "医学图像筛查",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究多模态大模型（MLLMs）在医学图像筛查中的美学推理能力，提出了新的数据集和方法，核心任务是让模型在医学图像筛查场景下进行多模态问答和推理。虽然涉及医学图像，但论文重点在于多模态模型的推理与问答能力提升，因此选择'多模态学习→问答系统→医学图像筛查'作为最合适的分层分类路径。",
      "keywords": [
        "多模态大模型",
        "医学图像筛查",
        "美学推理",
        "长链思维（CoT）",
        "DPA-GRPO",
        "数据集构建",
        "强化学习"
      ],
      "methods": [
        "长链思维（Chain of Thought, CoT）",
        "Group Relative Policy Optimization with Dynamic Proportional Accuracy reward (DPA-GRPO)",
        "数据集收集与构建",
        "强化学习优化"
      ],
      "problems": [
        "现有多模态大模型在医学图像美学推理任务中的表现不佳",
        "缺乏高质量医学图像筛查美学推理数据集",
        "如何提升MLLMs在医学图像筛查中的美学推理能力"
      ]
    },
    "keywords": [
      "多模态大模型",
      "医学图像筛查",
      "美学推理",
      "长链思维（CoT）",
      "DPA-GRPO",
      "数据集构建",
      "强化学习"
    ],
    "methods": [
      "长链思维（Chain of Thought, CoT）",
      "Group Relative Policy Optimization with Dynamic Proportional Accuracy reward (DPA-GRPO)",
      "数据集收集与构建",
      "强化学习优化"
    ],
    "problems": [
      "现有多模态大模型在医学图像美学推理任务中的表现不佳",
      "缺乏高质量医学图像筛查美学推理数据集",
      "如何提升MLLMs在医学图像筛查中的美学推理能力"
    ]
  },
  "2505.23277": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于RAG（检索增强生成）场景下的大语言模型上下文压缩问题，核心任务是提升问答系统在处理长文本检索时的效率和效果。论文提出的方法（Sentinel）直接用于提升问答系统的上下文处理能力，属于自然语言处理领域下的问答系统任务。虽然涉及大语言模型，但其主要贡献和实验验证均围绕问答系统展开，因此选择'自然语言处理 → 问答系统'作为最合适的分类路径。",
      "keywords": [
        "检索增强生成",
        "大语言模型",
        "上下文压缩",
        "注意力机制",
        "问答系统",
        "代理模型",
        "句子级过滤"
      ],
      "methods": [
        "基于注意力的上下文过滤",
        "代理模型注意力探查",
        "轻量级分类器",
        "无监督压缩"
      ],
      "problems": [
        "如何在RAG场景下高效压缩冗长、噪声多的检索文本",
        "如何无需专门训练压缩模型实现高效上下文过滤",
        "如何利用小规模代理模型的注意力机制提升大模型问答性能"
      ]
    },
    "keywords": [
      "检索增强生成",
      "大语言模型",
      "上下文压缩",
      "注意力机制",
      "问答系统",
      "代理模型",
      "句子级过滤"
    ],
    "methods": [
      "基于注意力的上下文过滤",
      "代理模型注意力探查",
      "轻量级分类器",
      "无监督压缩"
    ],
    "problems": [
      "如何在RAG场景下高效压缩冗长、噪声多的检索文本",
      "如何无需专门训练压缩模型实现高效上下文过滤",
      "如何利用小规模代理模型的注意力机制提升大模型问答性能"
    ]
  },
  "2505.23268": {
    "classification_path": "计算机科学 → 多模态学习 → 视频理解 → 视频摘要与高光检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "视频理解",
      "level3": "视频摘要与高光检测",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究视频摘要与高光检测任务，核心创新点在于融合视频帧与转录文本（多模态）并在强化学习框架下进行无监督训练。虽然涉及强化学习，但主要贡献在于多模态信息融合与视频理解，因此选择'多模态学习'为二级领域，'视频理解'为三级领域，具体任务为'视频摘要与高光检测'。",
      "keywords": [
        "多模态融合",
        "视频摘要",
        "高光检测",
        "无监督学习",
        "强化学习",
        "视频转录文本"
      ],
      "methods": [
        "多模态管道",
        "视频帧与转录文本融合",
        "强化学习训练",
        "无监督学习"
      ],
      "problems": [
        "如何利用视频帧与转录文本提升视频摘要与高光检测效果",
        "如何在无监督条件下训练视频摘要与高光检测模型",
        "如何克服标注数据稀缺带来的挑战"
      ]
    },
    "keywords": [
      "多模态融合",
      "视频摘要",
      "高光检测",
      "无监督学习",
      "强化学习",
      "视频转录文本"
    ],
    "methods": [
      "多模态管道",
      "视频帧与转录文本融合",
      "强化学习训练",
      "无监督学习"
    ],
    "problems": [
      "如何利用视频帧与转录文本提升视频摘要与高光检测效果",
      "如何在无监督条件下训练视频摘要与高光检测模型",
      "如何克服标注数据稀缺带来的挑战"
    ]
  },
  "2505.23291": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于知识编辑（Knowledge Editing）在大语言模型中的评测，提出了一个新的基准ScEdit，扩展了传统的事实型问答到动作型问答，并分析了现有知识编辑方法的表现。论文的核心是对知识编辑能力的评估，尤其是在问答场景下的应用，因此最合适的分类是‘自然语言处理 → 问答系统’。虽然涉及大语言模型，但论文主要关注知识编辑在问答任务中的评测与应用，‘问答系统’比‘大语言模型’更贴切。",
      "keywords": [
        "知识编辑",
        "基准评测",
        "脚本驱动",
        "问答系统",
        "大语言模型",
        "动作型问答",
        "事实型问答"
      ],
      "methods": [
        "脚本驱动基准设计",
        "token级与文本级评测方法",
        "对现有知识编辑技术的综合分析"
      ],
      "problems": [
        "现有知识编辑任务过于简单，评测方法不能反映实际应用中的挑战",
        "如何设计更具挑战性的知识编辑评测基准，覆盖事实型与动作型问答",
        "现有知识编辑方法在更复杂评测下的表现与不足"
      ]
    },
    "keywords": [
      "知识编辑",
      "基准评测",
      "脚本驱动",
      "问答系统",
      "大语言模型",
      "动作型问答",
      "事实型问答"
    ],
    "methods": [
      "脚本驱动基准设计",
      "token级与文本级评测方法",
      "对现有知识编辑技术的综合分析"
    ],
    "problems": [
      "现有知识编辑任务过于简单，评测方法不能反映实际应用中的挑战",
      "如何设计更具挑战性的知识编辑评测基准，覆盖事实型与动作型问答",
      "现有知识编辑方法在更复杂评测下的表现与不足"
    ]
  },
  "2505.23271": {
    "classification_path": "计算机科学 → 多模态学习 → 小样本学习 → 持续学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "小样本学习",
      "level3": "持续学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于基于CLIP的视觉-语言模型在持续学习（Continual Learning）场景下的适应问题，提出了LADA方法以提升多任务下的泛化能力和防止遗忘。虽然涉及计算机视觉，但核心创新点在于多模态模型的持续学习与适应，因此选择'多模态学习'为二级领域，'小样本学习'为三级领域（因持续学习常与小样本/增量学习密切相关），'持续学习'为具体任务。",
      "keywords": [
        "CLIP",
        "持续学习",
        "多模态学习",
        "适配器",
        "特征蒸馏",
        "灾难性遗忘"
      ],
      "methods": [
        "标签特定适配器（Label-specific Adapter）",
        "冻结预训练编码器",
        "特征蒸馏",
        "轻量级记忆单元"
      ],
      "problems": [
        "如何在多任务持续学习中高效适配大规模视觉-语言模型（如CLIP）",
        "如何避免推理阶段参数选择错误导致的性能下降",
        "如何防止新任务学习过程中的灾难性遗忘"
      ]
    },
    "keywords": [
      "CLIP",
      "持续学习",
      "多模态学习",
      "适配器",
      "特征蒸馏",
      "灾难性遗忘"
    ],
    "methods": [
      "标签特定适配器（Label-specific Adapter）",
      "冻结预训练编码器",
      "特征蒸馏",
      "轻量级记忆单元"
    ],
    "problems": [
      "如何在多任务持续学习中高效适配大规模视觉-语言模型（如CLIP）",
      "如何避免推理阶段参数选择错误导致的性能下降",
      "如何防止新任务学习过程中的灾难性遗忘"
    ]
  },
  "2505.23295": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文关注大语言模型在长文本生成中的事实性问题，核心研究内容为长文本问答/生成的事实准确性评估。虽然涉及大语言模型，但主要任务是对生成文本的事实性进行系统评估和分析，属于自然语言处理领域下的问答系统（长文本问答/生成）。标准词表中'问答系统'最贴合该论文的主要研究任务，未涉及更细致的四级任务，因此level3为null。",
      "keywords": [
        "大语言模型",
        "长文本生成",
        "事实性",
        "响应长度",
        "自动评估",
        "长度偏差"
      ],
      "methods": [
        "自动双层事实性评估框架",
        "受控实验",
        "假设验证（错误传播、长上下文、事实耗尽）"
      ],
      "problems": [
        "长文本生成中响应长度对事实性的影响",
        "长文本生成事实性下降的主要原因分析"
      ]
    },
    "keywords": [
      "大语言模型",
      "长文本生成",
      "事实性",
      "响应长度",
      "自动评估",
      "长度偏差"
    ],
    "methods": [
      "自动双层事实性评估框架",
      "受控实验",
      "假设验证（错误传播、长上下文、事实耗尽）"
    ],
    "problems": [
      "长文本生成中响应长度对事实性的影响",
      "长文本生成事实性下降的主要原因分析"
    ]
  },
  "2505.23272": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于多模态大模型（MLMs）对视觉内容的理解能力，提出了感知与认知两级评测框架，核心任务为多模态语义理解与讽刺识别。虽然论文涉及视觉和语言，但主要研究对象是多模态模型的理解能力，且通过问答方式评估模型对讽刺等高级语义的把握。因此，最合适的分类为'多模态学习 → 问答系统'，level3暂无更细致标准任务可选。",
      "keywords": [
        "多模态大模型",
        "视觉理解",
        "讽刺识别",
        "感知与认知评测",
        "视觉房间悖论",
        "语义理解",
        "情感推理"
      ],
      "methods": [
        "两级评测框架（感知与认知）",
        "多模态讽刺数据集构建",
        "多模型对比实验",
        "误差分析"
      ],
      "problems": [
        "多模态大模型是否真正理解视觉内容还是仅仅表面感知？",
        "现有MLMs在讽刺等复杂语义理解上存在哪些局限？",
        "如何系统性评估MLMs的感知与认知能力差距？"
      ]
    },
    "keywords": [
      "多模态大模型",
      "视觉理解",
      "讽刺识别",
      "感知与认知评测",
      "视觉房间悖论",
      "语义理解",
      "情感推理"
    ],
    "methods": [
      "两级评测框架（感知与认知）",
      "多模态讽刺数据集构建",
      "多模型对比实验",
      "误差分析"
    ],
    "problems": [
      "多模态大模型是否真正理解视觉内容还是仅仅表面感知？",
      "现有MLMs在讽刺等复杂语义理解上存在哪些局限？",
      "如何系统性评估MLMs的感知与认知能力差距？"
    ]
  },
  "2505.23297": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于乌克兰语文本的情感检测数据集构建与基线方法评测，属于自然语言处理领域。标准三级领域中未包含'情感分析'或'情感分类'，但'问答系统'是最接近的具体NLP任务，且与文本理解和分类密切相关，因此选择'问答系统'作为最接近的三级领域。四级领域暂无更具体的标准任务可选，设为null。",
      "keywords": [
        "情感检测",
        "乌克兰语",
        "数据集",
        "情感分类",
        "自然语言处理",
        "基准测试"
      ],
      "methods": [
        "数据集构建",
        "众包标注",
        "基线模型评测",
        "大语言模型评估",
        "翻译合成数据"
      ],
      "problems": [
        "乌克兰语情感分类缺乏公开基准数据集",
        "非主流语言情感检测的挑战",
        "现有模型在乌克兰语情感分类上的表现与局限性"
      ]
    },
    "keywords": [
      "情感检测",
      "乌克兰语",
      "数据集",
      "情感分类",
      "自然语言处理",
      "基准测试"
    ],
    "methods": [
      "数据集构建",
      "众包标注",
      "基线模型评测",
      "大语言模型评估",
      "翻译合成数据"
    ],
    "problems": [
      "乌克兰语情感分类缺乏公开基准数据集",
      "非主流语言情感检测的挑战",
      "现有模型在乌克兰语情感分类上的表现与局限性"
    ]
  },
  "2505.23280": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于大规模三维场景重建，提出了一种新的整体优化框架（MixGS），主要解决现有三维重建方法在大规模场景下的全局信息丢失和计算资源消耗高的问题。论文核心任务是三维重建，属于计算机视觉领域下的三维重建分支，未涉及更细致的具体应用，因此level3为null。",
      "keywords": [
        "三维重建",
        "大规模场景",
        "高斯Splatting",
        "整体优化",
        "视图合成",
        "全局一致性",
        "局部保真度"
      ],
      "methods": [
        "混合高斯Splatting（MixGS）",
        "整体场景建模",
        "相机位姿与高斯属性集成",
        "视图感知表示",
        "混合操作（decoded与original Gaussians融合）"
      ],
      "problems": [
        "现有大规模三维重建方法丢失全局场景信息",
        "场景分割与局部优化导致参数调优复杂",
        "高计算资源需求限制大规模场景训练"
      ]
    },
    "keywords": [
      "三维重建",
      "大规模场景",
      "高斯Splatting",
      "整体优化",
      "视图合成",
      "全局一致性",
      "局部保真度"
    ],
    "methods": [
      "混合高斯Splatting（MixGS）",
      "整体场景建模",
      "相机位姿与高斯属性集成",
      "视图感知表示",
      "混合操作（decoded与original Gaussians融合）"
    ],
    "problems": [
      "现有大规模三维重建方法丢失全局场景信息",
      "场景分割与局部优化导致参数调优复杂",
      "高计算资源需求限制大规模场景训练"
    ]
  },
  "2505.23299": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": "小样本学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型和RAG系统中的问答任务，核心贡献是提出数据高效的元模型用于检测幻觉，显著减少标注数据需求。方法涉及高效分类算法与降维技术，属于小样本学习范畴。根据标准领域词表，'自然语言处理'下的'问答系统'最为贴切，具体任务为'小样本学习'，因为论文强调在极少样本下保持高性能。",
      "keywords": [
        "大语言模型",
        "RAG系统",
        "幻觉检测",
        "数据高效",
        "小样本学习",
        "问答系统",
        "元模型",
        "降维"
      ],
      "methods": [
        "高效分类算法",
        "降维技术",
        "Lookback Lens（注意力头动态分析）",
        "探测器方法（内部表示解码）"
      ],
      "problems": [
        "如何在标注数据有限的情况下实现高效的幻觉检测？",
        "如何减少问答系统中幻觉检测模型对大规模标注数据的依赖？",
        "如何在工业应用中提升RAG系统的可靠性和可扩展性？"
      ]
    },
    "keywords": [
      "大语言模型",
      "RAG系统",
      "幻觉检测",
      "数据高效",
      "小样本学习",
      "问答系统",
      "元模型",
      "降维"
    ],
    "methods": [
      "高效分类算法",
      "降维技术",
      "Lookback Lens（注意力头动态分析）",
      "探测器方法（内部表示解码）"
    ],
    "problems": [
      "如何在标注数据有限的情况下实现高效的幻觉检测？",
      "如何减少问答系统中幻觉检测模型对大规模标注数据的依赖？",
      "如何在工业应用中提升RAG系统的可靠性和可扩展性？"
    ]
  },
  "2505.23283": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于遥感图像伪造检测，核心贡献是构建了一个基于扩散模型生成的遥感伪造大规模数据集，并对现有检测方法进行了评测。论文主要涉及计算机视觉领域，具体属于生成模型，且强调扩散模型在遥感图像伪造中的应用与检测，因此选择'计算机科学 → 计算机视觉 → 生成模型 → 扩散模型'作为最合适的分层分类路径。",
      "keywords": [
        "遥感图像",
        "伪造检测",
        "扩散模型",
        "数据集",
        "遥感伪造",
        "通用性",
        "鲁棒性"
      ],
      "methods": [
        "大规模数据集构建（RSFAKE-1M）",
        "多种扩散模型生成伪造图像",
        "基于现有检测器和统一基线的实验评估"
      ],
      "problems": [
        "现有遥感图像伪造检测方法对扩散模型生成的伪造图像效果不佳",
        "缺乏针对扩散模型伪造的遥感图像大规模数据集",
        "如何提升伪造检测方法在遥感领域的泛化能力和鲁棒性"
      ]
    },
    "keywords": [
      "遥感图像",
      "伪造检测",
      "扩散模型",
      "数据集",
      "遥感伪造",
      "通用性",
      "鲁棒性"
    ],
    "methods": [
      "大规模数据集构建（RSFAKE-1M）",
      "多种扩散模型生成伪造图像",
      "基于现有检测器和统一基线的实验评估"
    ],
    "problems": [
      "现有遥感图像伪造检测方法对扩散模型生成的伪造图像效果不佳",
      "缺乏针对扩散模型伪造的遥感图像大规模数据集",
      "如何提升伪造检测方法在遥感领域的泛化能力和鲁棒性"
    ]
  },
  "2505.23304": {
    "classification_path": "计算机科学 → 自然语言处理 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于事件文本中的Generalized Category Discovery（GCD），属于自然语言处理领域。其核心任务是利用部分标注数据对已知和新类别进行分类，涉及小样本学习和类别不平衡问题。虽然论文结合了大语言模型（LLMs）进行模式挖掘，但主要任务仍是自然语言处理中的小样本学习范畴，且标准词表中未有更细致的任务匹配，因此选择'自然语言处理 → 小样本学习'作为最合适的分类路径。",
      "keywords": [
        "Generalized Category Discovery",
        "Event-Centric Contexts",
        "小样本学习",
        "类别不平衡",
        "大语言模型",
        "聚类",
        "文本分类"
      ],
      "methods": [
        "PaMA框架",
        "大语言模型事件模式抽取",
        "聚类-分类对齐",
        "排序-过滤-挖掘流程"
      ],
      "problems": [
        "如何在事件驱动、类别极度不平衡的文本中发现和分类已知及新类别",
        "主观标准导致的聚类与分类分歧问题",
        "少数类别的不公平对齐问题"
      ]
    },
    "keywords": [
      "Generalized Category Discovery",
      "Event-Centric Contexts",
      "小样本学习",
      "类别不平衡",
      "大语言模型",
      "聚类",
      "文本分类"
    ],
    "methods": [
      "PaMA框架",
      "大语言模型事件模式抽取",
      "聚类-分类对齐",
      "排序-过滤-挖掘流程"
    ],
    "problems": [
      "如何在事件驱动、类别极度不平衡的文本中发现和分类已知及新类别",
      "主观标准导致的聚类与分类分歧问题",
      "少数类别的不公平对齐问题"
    ]
  },
  "2505.23287": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 三维CAD模型生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "三维CAD模型生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于从图像自动生成可行的3D CAD模型，属于三维重建领域。其核心贡献是提升生成CAD模型的可行性，采用扩散模型和自修复机制优化生成结果。虽然涉及生成模型和扩散模型，但任务本质是三维CAD模型的生成与修复，因此选择'计算机视觉 → 三维重建 → 三维CAD模型生成'作为最合适的分层分类。",
      "keywords": [
        "3D CAD生成",
        "可行性增强",
        "扩散模型",
        "自修复机制",
        "B-rep",
        "生成式AI",
        "点云",
        "对比学习"
      ],
      "methods": [
        "扩散引导去噪",
        "自修复管道",
        "回归修正机制",
        "对比学习框架",
        "自回归Transformer架构"
      ],
      "problems": [
        "提升自动生成3D CAD模型的可行性",
        "修复生成CAD模型中不可行的B-rep结构",
        "在保证几何精度的同时提高生成模型的可用性"
      ]
    },
    "keywords": [
      "3D CAD生成",
      "可行性增强",
      "扩散模型",
      "自修复机制",
      "B-rep",
      "生成式AI",
      "点云",
      "对比学习"
    ],
    "methods": [
      "扩散引导去噪",
      "自修复管道",
      "回归修正机制",
      "对比学习框架",
      "自回归Transformer架构"
    ],
    "problems": [
      "提升自动生成3D CAD模型的可行性",
      "修复生成CAD模型中不可行的B-rep结构",
      "在保证几何精度的同时提高生成模型的可用性"
    ]
  },
  "2505.23315": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于自动化作文评分（AES）中的置信度建模，属于自然语言处理领域。虽然论文涉及机器学习方法，但其核心任务是对文本（作文）进行自动评分与置信度评估，属于NLP应用。标准领域词表中没有专门的'自动作文评分'或'教育评测'，但'问答系统'作为NLP下的具体任务，最接近自动化文本理解与评分的应用场景，因此选择'自然语言处理 → 问答系统'作为最合适的分类路径。",
      "keywords": [
        "自动作文评分",
        "置信度建模",
        "CEFR分级",
        "序数分类",
        "教育评测",
        "Kernel Weighted Ordinal Categorical Cross Entropy"
      ],
      "methods": [
        "置信度建模",
        "n-ary分类",
        "分数分箱",
        "序数结构损失函数（KWOCCE）"
      ],
      "problems": [
        "如何提升自动作文评分系统的评分置信度与可靠性",
        "如何利用序数结构改进置信度建模",
        "如何确保自动评分结果在教育评测中的可用性和公平性"
      ]
    },
    "keywords": [
      "自动作文评分",
      "置信度建模",
      "CEFR分级",
      "序数分类",
      "教育评测",
      "Kernel Weighted Ordinal Categorical Cross Entropy"
    ],
    "methods": [
      "置信度建模",
      "n-ary分类",
      "分数分箱",
      "序数结构损失函数（KWOCCE）"
    ],
    "problems": [
      "如何提升自动作文评分系统的评分置信度与可靠性",
      "如何利用序数结构改进置信度建模",
      "如何确保自动评分结果在教育评测中的可用性和公平性"
    ]
  },
  "2505.23292": {
    "classification_path": "计算机科学 → 计算机视觉 → 图像分割 → 语义分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "图像分割",
      "level3": "语义分割",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文主要研究在联邦学习框架下实现无监督的语义图像分割任务。其核心贡献在于提出了一个新的联邦无监督语义分割方法（FUSS），并在多个分割任务上进行了实验。根据标准领域词表，'图像分割'是最合适的三级领域，而具体任务为'语义分割'，符合四级领域要求。",
      "keywords": [
        "联邦学习",
        "无监督学习",
        "语义分割",
        "图像分割",
        "特征对齐",
        "聚类",
        "分布式训练"
      ],
      "methods": [
        "联邦无监督语义分割框架（FUSS）",
        "特征和聚类中心对齐",
        "自监督目标优化",
        "局部分割头与全局语义原型联合优化"
      ],
      "problems": [
        "如何在无监督和分布式（联邦）环境下实现高效的语义图像分割",
        "如何在数据异构和无标签条件下对分布式客户端的特征表示和聚类中心进行对齐",
        "如何提升联邦无监督分割在多种数据分布下的性能"
      ]
    },
    "keywords": [
      "联邦学习",
      "无监督学习",
      "语义分割",
      "图像分割",
      "特征对齐",
      "聚类",
      "分布式训练"
    ],
    "methods": [
      "联邦无监督语义分割框架（FUSS）",
      "特征和聚类中心对齐",
      "自监督目标优化",
      "局部分割头与全局语义原型联合优化"
    ],
    "problems": [
      "如何在无监督和分布式（联邦）环境下实现高效的语义图像分割",
      "如何在数据异构和无标签条件下对分布式客户端的特征表示和聚类中心进行对齐",
      "如何提升联邦无监督分割在多种数据分布下的性能"
    ]
  },
  "2505.23316": {
    "classification_path": "计算机科学 → 大语言模型 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于大语言模型（LLMs）的对齐方法，提出了改进的直接偏好优化（DPO）方法以适应多样化反馈类型，并解决了生成模型在对齐过程中的概率下定问题。论文主要内容属于大语言模型领域，具体涉及生成模型的对齐与优化，因此选择“大语言模型→生成模型”作为最合适的分类路径。由于标准词表中未包含更细致的对齐或优化任务，level3设为null。",
      "keywords": [
        "大语言模型",
        "直接偏好优化",
        "对齐",
        "生成模型",
        "多样化反馈",
        "概率下定",
        "正则化"
      ],
      "methods": [
        "直接偏好优化（DPO）",
        "分解损失函数",
        "正则化重构",
        "PRoximalized Preference Optimization (PRO)"
      ],
      "problems": [
        "对齐大语言模型时，现有直接对比方法导致生成概率下定问题",
        "如何扩展对齐方法以适应多样化的反馈类型",
        "如何通过理论分解和正则化改进对齐方法，消除概率下定问题"
      ]
    },
    "keywords": [
      "大语言模型",
      "直接偏好优化",
      "对齐",
      "生成模型",
      "多样化反馈",
      "概率下定",
      "正则化"
    ],
    "methods": [
      "直接偏好优化（DPO）",
      "分解损失函数",
      "正则化重构",
      "PRoximalized Preference Optimization (PRO)"
    ],
    "problems": [
      "对齐大语言模型时，现有直接对比方法导致生成概率下定问题",
      "如何扩展对齐方法以适应多样化的反馈类型",
      "如何通过理论分解和正则化改进对齐方法，消除概率下定问题"
    ]
  },
  "2505.23312": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于text-to-image扩散模型（如Stable Diffusion、FLUX）中的概念擦除问题，提出了一种新的概念擦除方法TRACE，并在多个生成任务（如艺术风格、名人面孔、敏感内容）上进行了实验。论文的核心是针对扩散模型的生成能力与安全性问题，属于计算机视觉领域下的生成模型，具体聚焦于扩散模型的任务与方法，因此选择'计算机科学 → 计算机视觉 → 生成模型 → 扩散模型'作为最合适的分层分类。",
      "keywords": [
        "扩散模型",
        "概念擦除",
        "生成模型",
        "文本到图像生成",
        "隐私保护",
        "内容安全",
        "跨注意力机制",
        "模型微调"
      ],
      "methods": [
        "TRACE（Trajectory-Constrained Attentional Concept Erasure）",
        "跨注意力层的闭式更新",
        "轨迹感知微调目标",
        "理论分析与形式化条件推导",
        "兼容Stable Diffusion与FLUX等模型的微调流程"
      ],
      "problems": [
        "如何在不损害生成质量的前提下，有效从扩散模型中擦除或抑制特定概念（如敏感内容、特定身份、受版权保护的风格）？",
        "如何设计理论上可证实的概念擦除方法，并兼容不同类型的扩散模型？",
        "如何在保持模型对无关内容生成能力的同时，确保目标概念被有效移除？"
      ]
    },
    "keywords": [
      "扩散模型",
      "概念擦除",
      "生成模型",
      "文本到图像生成",
      "隐私保护",
      "内容安全",
      "跨注意力机制",
      "模型微调"
    ],
    "methods": [
      "TRACE（Trajectory-Constrained Attentional Concept Erasure）",
      "跨注意力层的闭式更新",
      "轨迹感知微调目标",
      "理论分析与形式化条件推导",
      "兼容Stable Diffusion与FLUX等模型的微调流程"
    ],
    "problems": [
      "如何在不损害生成质量的前提下，有效从扩散模型中擦除或抑制特定概念（如敏感内容、特定身份、受版权保护的风格）？",
      "如何设计理论上可证实的概念擦除方法，并兼容不同类型的扩散模型？",
      "如何在保持模型对无关内容生成能力的同时，确保目标概念被有效移除？"
    ]
  },
  "2505.23323": {
    "classification_path": "计算机科学 → 大语言模型 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）的能力分析，讨论其推理能力的本质，提出'context-directed extrapolation'机制，属于对大语言模型生成能力的理论探讨。虽然涉及推理和上下文学习，但主要研究对象和分析核心是大语言模型本身及其生成机制，因此选择'大语言模型→生成模型'作为最合适的分类路径。",
      "keywords": [
        "大语言模型",
        "上下文学习",
        "推理能力",
        "生成模型",
        "context-directed extrapolation",
        "训练数据先验"
      ],
      "methods": [
        "理论分析",
        "文献综述",
        "机制假设（context-directed extrapolation）"
      ],
      "problems": [
        "大语言模型的推理能力本质是什么？",
        "大语言模型的能力是否属于简单的随机复述或具备高级推理？",
        "上下文学习如何影响大语言模型对训练数据先验的外推？",
        "大语言模型能力的可控性与可预测性如何？"
      ]
    },
    "keywords": [
      "大语言模型",
      "上下文学习",
      "推理能力",
      "生成模型",
      "context-directed extrapolation",
      "训练数据先验"
    ],
    "methods": [
      "理论分析",
      "文献综述",
      "机制假设（context-directed extrapolation）"
    ],
    "problems": [
      "大语言模型的推理能力本质是什么？",
      "大语言模型的能力是否属于简单的随机复述或具备高级推理？",
      "上下文学习如何影响大语言模型对训练数据先验的外推？",
      "大语言模型能力的可控性与可预测性如何？"
    ]
  },
  "2505.23313": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 行人属性识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "行人属性识别",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于行人属性识别（Pedestrian Attribute Recognition），这是计算机视觉领域中目标检测的细分任务之一。论文提出了针对行人属性识别的对抗攻击与防御框架，属于具体的行人属性识别应用，因此选择'计算机视觉→目标检测→行人属性识别'作为分层分类路径。",
      "keywords": [
        "行人属性识别",
        "对抗攻击",
        "对抗防御",
        "多模态融合",
        "CLIP",
        "语义扰动",
        "标签扰动"
      ],
      "methods": [
        "基于CLIP的多模态Transformer行人属性识别框架",
        "全局与局部（patch-level）对抗攻击",
        "对抗语义与标签扰动（ASL-PAR）",
        "语义偏移防御策略"
      ],
      "problems": [
        "行人属性识别模型在对抗攻击下的脆弱性与抗干扰能力不足",
        "缺乏针对行人属性识别的系统性对抗攻击与防御方法"
      ]
    },
    "keywords": [
      "行人属性识别",
      "对抗攻击",
      "对抗防御",
      "多模态融合",
      "CLIP",
      "语义扰动",
      "标签扰动"
    ],
    "methods": [
      "基于CLIP的多模态Transformer行人属性识别框架",
      "全局与局部（patch-level）对抗攻击",
      "对抗语义与标签扰动（ASL-PAR）",
      "语义偏移防御策略"
    ],
    "problems": [
      "行人属性识别模型在对抗攻击下的脆弱性与抗干扰能力不足",
      "缺乏针对行人属性识别的系统性对抗攻击与防御方法"
    ]
  },
  "2505.23363": {
    "classification_path": "计算机科学 → 强化学习 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "强化学习",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于通过判别式策略优化提升大语言模型在复杂推理任务中的能力，核心方法为将判别式Q函数奖励模型（Q-RM）引入到基于强化学习的生成模型训练流程中。虽然涉及自然语言处理和大语言模型，但论文的主要创新点和实验均围绕强化学习中的奖励建模与策略优化展开，且方法直接作用于生成模型的训练，因此选择'强化学习→生成模型'作为最合适的分类路径。",
      "keywords": [
        "判别式策略优化",
        "Q函数奖励模型",
        "过程奖励模型",
        "令牌级奖励",
        "大语言模型",
        "复杂推理",
        "PPO",
        "REINFORCE"
      ],
      "methods": [
        "判别式Q函数奖励建模（Q-RM）",
        "令牌级奖励分配",
        "与PPO/REINFORCE集成的强化学习训练",
        "理论分析与多基准实验"
      ],
      "problems": [
        "如何在生成模型训练中实现更精细、稳定的令牌级奖励分配",
        "如何解决生成式语言建模与奖励建模之间的冲突导致的训练不稳定和奖励分配不准确问题",
        "如何提升大语言模型在复杂推理任务中的表现和训练效率"
      ]
    },
    "keywords": [
      "判别式策略优化",
      "Q函数奖励模型",
      "过程奖励模型",
      "令牌级奖励",
      "大语言模型",
      "复杂推理",
      "PPO",
      "REINFORCE"
    ],
    "methods": [
      "判别式Q函数奖励建模（Q-RM）",
      "令牌级奖励分配",
      "与PPO/REINFORCE集成的强化学习训练",
      "理论分析与多基准实验"
    ],
    "problems": [
      "如何在生成模型训练中实现更精细、稳定的令牌级奖励分配",
      "如何解决生成式语言建模与奖励建模之间的冲突导致的训练不稳定和奖励分配不准确问题",
      "如何提升大语言模型在复杂推理任务中的表现和训练效率"
    ]
  },
  "2505.23325": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 可控图像生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "可控图像生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要研究如何利用视频生成模型在高维空间的能力，通过知识压缩和任务适配，实现对低维度任务（如可控图像生成）的支持。其核心贡献在于提出了视频到图像的知识迁移范式，并在可控图像生成等任务上取得了优于直接训练图像生成模型的效果。根据标准领域词表，'生成模型'是最合适的三级领域，具体任务为'可控图像生成'，属于生成模型下的细分应用。",
      "keywords": [
        "视频生成模型",
        "知识压缩",
        "任务适配",
        "可控图像生成",
        "长程上下文建模",
        "注意力机制",
        "mixup策略"
      ],
      "methods": [
        "视频到图像知识压缩范式（DRA-Ctrl）",
        "mixup-based过渡策略",
        "重设计的注意力结构与掩码机制"
      ],
      "problems": [
        "如何利用高维视频生成模型支持低维可控图像生成任务",
        "如何实现视频模型到图像生成任务的平滑适配",
        "如何提升图像生成的可控性和多样性"
      ]
    },
    "keywords": [
      "视频生成模型",
      "知识压缩",
      "任务适配",
      "可控图像生成",
      "长程上下文建模",
      "注意力机制",
      "mixup策略"
    ],
    "methods": [
      "视频到图像知识压缩范式（DRA-Ctrl）",
      "mixup-based过渡策略",
      "重设计的注意力结构与掩码机制"
    ],
    "problems": [
      "如何利用高维视频生成模型支持低维可控图像生成任务",
      "如何实现视频模型到图像生成任务的平滑适配",
      "如何提升图像生成的可控性和多样性"
    ]
  },
  "2505.23368": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于利用大语言模型（LLMs）生成链式推理（CoT）解释，以更好地理解和对齐人类标签分布变异性。其核心任务是通过自然语言推理和解释提升模型与人类标签分布的一致性，属于自然语言处理领域。具体方法涉及链式推理解释、标签分布对齐和基于排序的评估框架，最贴近标准领域词表中的‘问答系统’（因其涉及多选答案的推理与解释），但未涉及更细的具体任务，因此level3为null。",
      "keywords": [
        "链式推理（Chain-of-Thought, CoT）",
        "大语言模型（LLM）",
        "人类标签变异性（Human Label Variation, HLV）",
        "解释生成",
        "标签分布对齐",
        "排序评估"
      ],
      "methods": [
        "基于LLM的链式推理解释生成",
        "引入语言学驱动的篇章分割器提取支持/反对语句",
        "基于排序的HLV评估框架"
      ],
      "problems": [
        "如何利用链式推理解释提升模型对人类标签分布变异性的理解与对齐",
        "如何从LLM生成的推理链中准确提取各选项的支持与反对理由",
        "如何更有效地评估模型输出与人类标签分布的一致性"
      ]
    },
    "keywords": [
      "链式推理（Chain-of-Thought, CoT）",
      "大语言模型（LLM）",
      "人类标签变异性（Human Label Variation, HLV）",
      "解释生成",
      "标签分布对齐",
      "排序评估"
    ],
    "methods": [
      "基于LLM的链式推理解释生成",
      "引入语言学驱动的篇章分割器提取支持/反对语句",
      "基于排序的HLV评估框架"
    ],
    "problems": [
      "如何利用链式推理解释提升模型对人类标签分布变异性的理解与对齐",
      "如何从LLM生成的推理链中准确提取各选项的支持与反对理由",
      "如何更有效地评估模型输出与人类标签分布的一致性"
    ]
  },
  "2505.23331": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于视觉自回归生成模型（VAR models）的微调，主要任务是提升图像生成质量和风格控制，属于计算机视觉领域。其核心方法为利用强化学习（Group Relative Policy Optimization）对视觉生成模型进行微调，尽管涉及强化学习，但主要贡献和应用场景在于视觉生成，因此选择'计算机视觉→生成模型'作为分类路径。由于标准词表中未细分到'视觉自回归模型'或'视觉强化学习微调'等更具体任务，level3设为null。",
      "keywords": [
        "视觉自回归模型",
        "生成模型",
        "强化学习微调",
        "Group Relative Policy Optimization",
        "CLIP",
        "图像生成",
        "风格控制"
      ],
      "methods": [
        "Group Relative Policy Optimization (GRPO)",
        "基于CLIP的奖励信号",
        "强化学习驱动的模型微调"
      ],
      "problems": [
        "如何通过强化学习微调提升视觉自回归生成模型的图像质量和风格控制能力",
        "如何使视觉生成模型泛化到训练分布之外的图像风格",
        "如何高效地对视觉生成模型进行在线采样和微调"
      ]
    },
    "keywords": [
      "视觉自回归模型",
      "生成模型",
      "强化学习微调",
      "Group Relative Policy Optimization",
      "CLIP",
      "图像生成",
      "风格控制"
    ],
    "methods": [
      "Group Relative Policy Optimization (GRPO)",
      "基于CLIP的奖励信号",
      "强化学习驱动的模型微调"
    ],
    "problems": [
      "如何通过强化学习微调提升视觉自回归生成模型的图像质量和风格控制能力",
      "如何使视觉生成模型泛化到训练分布之外的图像风格",
      "如何高效地对视觉生成模型进行在线采样和微调"
    ]
  },
  "2505.23404": {
    "classification_path": "计算机科学 → 大语言模型 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）的安全性问题，具体研究了针对不同语义理解能力的LLM的自适应越狱（jailbreaking）攻击策略。虽然涉及安全与攻击，但核心内容是对大语言模型的理解能力分类及其在问答等任务中的安全防护绕过，因此选择'大语言模型'为二级领域。论文主要实验和方法均围绕对LLM的问答能力进行攻击和评估，最贴近的三级领域为'问答系统'。四级领域未涉及更细致的标准任务，故为null。",
      "keywords": [
        "大语言模型",
        "越狱攻击",
        "语义理解",
        "安全性",
        "自适应策略",
        "GPT-4o"
      ],
      "methods": [
        "模型语义理解能力分类",
        "自适应越狱策略设计",
        "针对性攻击实验"
      ],
      "problems": [
        "如何根据大语言模型的语义理解能力分类，设计更有效的越狱攻击策略？",
        "不同类型大语言模型在面对自适应越狱攻击时的脆弱性表现如何？",
        "如何提升越狱攻击对最新大语言模型（如GPT-4o）的成功率？"
      ]
    },
    "keywords": [
      "大语言模型",
      "越狱攻击",
      "语义理解",
      "安全性",
      "自适应策略",
      "GPT-4o"
    ],
    "methods": [
      "模型语义理解能力分类",
      "自适应越狱策略设计",
      "针对性攻击实验"
    ],
    "problems": [
      "如何根据大语言模型的语义理解能力分类，设计更有效的越狱攻击策略？",
      "不同类型大语言模型在面对自适应越狱攻击时的脆弱性表现如何？",
      "如何提升越狱攻击对最新大语言模型（如GPT-4o）的成功率？"
    ]
  },
  "2505.23341": {
    "classification_path": "计算机科学 → 医学图像 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于弱监督下的全切片医学图像（WSI）分类任务，属于医学图像领域。论文提出的DSAGL方法旨在解决医学图像中由于标注稀缺导致的小样本/弱监督学习问题，结合了注意力机制和教师-学生架构，主要创新点在于提升弱监督医学图像分类的性能。标准领域词表中，医学图像下最贴切的三级领域为小样本学习，因其强调弱监督和有限标注的学习场景。论文未涉及医学图像分割等更细任务，因此level3设为null。",
      "keywords": [
        "全切片图像",
        "弱监督学习",
        "注意力机制",
        "教师-学生架构",
        "小样本学习",
        "医学图像分类"
      ],
      "methods": [
        "双流注意力引导学习（DSAGL）",
        "教师-学生架构",
        "多尺度注意力伪标签生成",
        "轻量级编码器（VSSMamba）",
        "融合注意力模块（FASA）",
        "混合损失函数"
      ],
      "problems": [
        "如何在缺乏细粒度标注的情况下对超高分辨率医学全切片图像进行有效分类",
        "如何缓解实例级歧义和包级语义一致性问题",
        "如何提升弱监督医学图像分类的判别性能和鲁棒性"
      ]
    },
    "keywords": [
      "全切片图像",
      "弱监督学习",
      "注意力机制",
      "教师-学生架构",
      "小样本学习",
      "医学图像分类"
    ],
    "methods": [
      "双流注意力引导学习（DSAGL）",
      "教师-学生架构",
      "多尺度注意力伪标签生成",
      "轻量级编码器（VSSMamba）",
      "融合注意力模块（FASA）",
      "混合损失函数"
    ],
    "problems": [
      "如何在缺乏细粒度标注的情况下对超高分辨率医学全切片图像进行有效分类",
      "如何缓解实例级歧义和包级语义一致性问题",
      "如何提升弱监督医学图像分类的判别性能和鲁棒性"
    ]
  },
  "2505.23410": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": "小样本学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）在事实性知识抽取任务中的表现，尤其关注微调数据与推理时prompt（如few-shot learning和Chain of Thought）对事实性gap的影响。虽然论文涉及大语言模型，但其核心问题是知识抽取与问答系统中的事实性提升，并探讨了小样本学习（few-shot learning, ICL）等方法。因此，最合适的分层为‘自然语言处理 → 问答系统 → 小样本学习’。",
      "keywords": [
        "大语言模型",
        "事实性",
        "知识抽取",
        "微调",
        "in-context learning",
        "few-shot learning",
        "Chain of Thought",
        "prompt",
        "知识图谱"
      ],
      "methods": [
        "系统实验分析",
        "in-context learning（ICL）",
        "few-shot learning",
        "Chain of Thought（CoT）",
        "知识图谱理论分析"
      ],
      "problems": [
        "微调数据对大语言模型事实性知识抽取能力的影响机制尚不清楚",
        "微调已知与未知知识时产生的事实性gap如何缓解",
        "推理时prompt（如ICL）能否弥补微调数据的不足",
        "如何更有效地评估微调数据选择方法的有效性"
      ]
    },
    "keywords": [
      "大语言模型",
      "事实性",
      "知识抽取",
      "微调",
      "in-context learning",
      "few-shot learning",
      "Chain of Thought",
      "prompt",
      "知识图谱"
    ],
    "methods": [
      "系统实验分析",
      "in-context learning（ICL）",
      "few-shot learning",
      "Chain of Thought（CoT）",
      "知识图谱理论分析"
    ],
    "problems": [
      "微调数据对大语言模型事实性知识抽取能力的影响机制尚不清楚",
      "微调已知与未知知识时产生的事实性gap如何缓解",
      "推理时prompt（如ICL）能否弥补微调数据的不足",
      "如何更有效地评估微调数据选择方法的有效性"
    ]
  },
  "2505.23343": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "论文聚焦于扩散模型在图像生成中的采样质量提升，提出了一种高效的采样过滤策略（CFG-Rejection），无需模型重训练或外部奖励信号，直接作用于扩散模型的采样过程。论文实验和应用均围绕图像生成展开，属于计算机视觉领域下的生成模型，具体聚焦于扩散模型的采样与质量控制，因此选择'计算机科学 → 计算机视觉 → 生成模型 → 扩散模型'作为分类路径。",
      "keywords": [
        "扩散模型",
        "采样路径",
        "样本过滤",
        "Classifier-Free Guidance",
        "Accumulated Score Differences",
        "图像生成"
      ],
      "methods": [
        "CFG-Rejection（基于采样路径的早期样本过滤）",
        "利用Accumulated Score Differences进行样本质量判别",
        "无外部奖励信号的高效Plug-and-Play策略"
      ],
      "problems": [
        "如何在不增加计算成本和无需模型重训练的前提下提升扩散模型生成样本的质量？",
        "如何利用扩散采样路径中的统计特征实现高效的低质量样本过滤？"
      ]
    },
    "keywords": [
      "扩散模型",
      "采样路径",
      "样本过滤",
      "Classifier-Free Guidance",
      "Accumulated Score Differences",
      "图像生成"
    ],
    "methods": [
      "CFG-Rejection（基于采样路径的早期样本过滤）",
      "利用Accumulated Score Differences进行样本质量判别",
      "无外部奖励信号的高效Plug-and-Play策略"
    ],
    "problems": [
      "如何在不增加计算成本和无需模型重训练的前提下提升扩散模型生成样本的质量？",
      "如何利用扩散采样路径中的统计特征实现高效的低质量样本过滤？"
    ]
  },
  "2505.23420": {
    "classification_path": "计算机科学 → 语音与音频处理 → 语音识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "语音与音频处理",
      "level2": "语音识别",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于语音到文本（Speech-to-Text, S2T）模型的训练收敛性，主要研究学习率策略对大规模语音识别模型（如Conformer、Branchformer等Transformer变体）训练过程的影响。论文的核心任务是语音识别，属于'语音与音频处理'下的'语音识别'。虽然涉及优化方法，但主要应用场景和实验对象均为语音识别任务，因此选择该分类路径。",
      "keywords": [
        "学习率策略",
        "语音到文本",
        "模型收敛",
        "Transformer",
        "Conformer",
        "Branchformer",
        "warmup",
        "大规模训练"
      ],
      "methods": [
        "双线性warmup",
        "学习率warmup调度",
        "子指数warmup",
        "实验对比不同warmup策略"
      ],
      "problems": [
        "大规模语音到文本模型训练中，学习率warmup策略对模型收敛和最终性能的影响",
        "现有warmup方案（如OWSM的双线性warmup）与其他warmup策略的对比及其优劣分析",
        "如何设计更适合大规模S2T模型的学习率warmup方案"
      ]
    },
    "keywords": [
      "学习率策略",
      "语音到文本",
      "模型收敛",
      "Transformer",
      "Conformer",
      "Branchformer",
      "warmup",
      "大规模训练"
    ],
    "methods": [
      "双线性warmup",
      "学习率warmup调度",
      "子指数warmup",
      "实验对比不同warmup策略"
    ],
    "problems": [
      "大规模语音到文本模型训练中，学习率warmup策略对模型收敛和最终性能的影响",
      "现有warmup方案（如OWSM的双线性warmup）与其他warmup策略的对比及其优劣分析",
      "如何设计更适合大规模S2T模型的学习率warmup方案"
    ]
  },
  "2505.23346": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于Flow Matching（FM）框架下的分布间样本迁移，提出了Model-Aligned Coupling（MAC）以提升生成质量和效率。FM和Optimal Transport等方法广泛应用于扩散模型等生成模型领域，且论文强调生成高质量样本和路径优化，属于生成模型中的扩散模型任务。因此，选择'计算机视觉 → 生成模型 → 扩散模型'作为最合适的分层分类。",
      "keywords": [
        "Flow Matching",
        "Optimal Transport",
        "Model-Aligned Coupling",
        "生成模型",
        "扩散模型",
        "路径优化",
        "分布迁移"
      ],
      "methods": [
        "Model-Aligned Coupling (MAC)",
        "Flow Matching (FM)",
        "Optimal Transport-based Coupling",
        "Top-k Coupling Selection"
      ],
      "problems": [
        "如何减少生成模型中样本迁移路径的交叉和非直线性",
        "如何提升Flow Matching框架下生成样本的质量与效率",
        "如何设计与模型预测方向对齐的高效耦合策略以优化生成过程"
      ]
    },
    "keywords": [
      "Flow Matching",
      "Optimal Transport",
      "Model-Aligned Coupling",
      "生成模型",
      "扩散模型",
      "路径优化",
      "分布迁移"
    ],
    "methods": [
      "Model-Aligned Coupling (MAC)",
      "Flow Matching (FM)",
      "Optimal Transport-based Coupling",
      "Top-k Coupling Selection"
    ],
    "problems": [
      "如何减少生成模型中样本迁移路径的交叉和非直线性",
      "如何提升Flow Matching框架下生成样本的质量与效率",
      "如何设计与模型预测方向对齐的高效耦合策略以优化生成过程"
    ]
  },
  "2505.23461": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）在处理不可回答问题（Unanswerable Questions, UAQ）时对事实知识的利用能力评估，核心任务是问答系统中的不可回答问题处理与知识利用。虽然论文涉及大语言模型，但其主要研究内容属于自然语言处理领域下的问答系统，尤其是评测和数据集构建，因此选择'自然语言处理 → 问答系统'作为最合适的分类路径。",
      "keywords": [
        "不可回答问题",
        "大语言模型",
        "事实知识",
        "知识图谱",
        "问答系统",
        "评测数据集",
        "知识利用"
      ],
      "methods": [
        "构建双语不可回答问题数据集（UAQFact）",
        "基于知识图谱生成辅助事实知识",
        "定义内部与外部知识利用评测任务",
        "多模型实验评测"
      ],
      "problems": [
        "如何评估大语言模型在不可回答问题场景下对事实知识的利用能力？",
        "现有不可回答问题数据集缺乏事实知识支持，如何弥补这一不足？",
        "大语言模型在拥有事实知识时，能否有效利用这些知识避免错误回答？",
        "引入外部知识能否提升大语言模型在不可回答问题上的表现？"
      ]
    },
    "keywords": [
      "不可回答问题",
      "大语言模型",
      "事实知识",
      "知识图谱",
      "问答系统",
      "评测数据集",
      "知识利用"
    ],
    "methods": [
      "构建双语不可回答问题数据集（UAQFact）",
      "基于知识图谱生成辅助事实知识",
      "定义内部与外部知识利用评测任务",
      "多模型实验评测"
    ],
    "problems": [
      "如何评估大语言模型在不可回答问题场景下对事实知识的利用能力？",
      "现有不可回答问题数据集缺乏事实知识支持，如何弥补这一不足？",
      "大语言模型在拥有事实知识时，能否有效利用这些知识避免错误回答？",
      "引入外部知识能否提升大语言模型在不可回答问题上的表现？"
    ]
  },
  "2505.23358": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 图像描述生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "图像描述生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于基于视觉-语言模型的知识丰富型图像描述生成（image captioning），属于计算机视觉领域下的生成模型分支。具体任务是图像描述生成（image captioning），该任务在标准领域词表中未单独列出，但作为生成模型的典型应用，最贴切的四级分类应为'图像描述生成'。论文虽涉及多模态，但核心任务是视觉主导的图像描述生成，因此归入计算机视觉-生成模型-图像描述生成最为合适。",
      "keywords": [
        "知识丰富型图像描述",
        "视觉-语言模型",
        "知识回放",
        "beam search",
        "注意力机制"
      ],
      "methods": [
        "知识回放机制",
        "beam search解码",
        "注意力增强的图像编码器",
        "训练调度器"
      ],
      "problems": [
        "现有图像描述模型缺乏知识性和上下文深度",
        "提升生成描述的知识性和多样性",
        "增强模型对未见知识概念的泛化能力"
      ]
    },
    "keywords": [
      "知识丰富型图像描述",
      "视觉-语言模型",
      "知识回放",
      "beam search",
      "注意力机制"
    ],
    "methods": [
      "知识回放机制",
      "beam search解码",
      "注意力增强的图像编码器",
      "训练调度器"
    ],
    "problems": [
      "现有图像描述模型缺乏知识性和上下文深度",
      "提升生成描述的知识性和多样性",
      "增强模型对未见知识概念的泛化能力"
    ]
  },
  "2505.23477": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要评估大语言模型在神经外科自测题（类似医学问答）的表现及其对干扰信息的脆弱性。虽然涉及大语言模型，但研究核心是模型在医学问答任务中的表现和鲁棒性分析，属于自然语言处理领域下的问答系统任务。论文没有聚焦于模型结构创新或多模态等其他方向，因此选择'自然语言处理 → 问答系统'作为最合适的分类路径。",
      "keywords": [
        "大语言模型",
        "问答系统",
        "神经外科",
        "鲁棒性",
        "干扰信息",
        "医学考试"
      ],
      "methods": [
        "大规模模型性能评估",
        "干扰框架设计",
        "医学问答基准测试"
      ],
      "problems": [
        "大语言模型在医学问答任务中的准确性与鲁棒性如何？",
        "干扰性无关信息对大语言模型医学问答表现的影响有多大？",
        "如何提升大语言模型在临床应用中的抗干扰能力？"
      ]
    },
    "keywords": [
      "大语言模型",
      "问答系统",
      "神经外科",
      "鲁棒性",
      "干扰信息",
      "医学考试"
    ],
    "methods": [
      "大规模模型性能评估",
      "干扰框架设计",
      "医学问答基准测试"
    ],
    "problems": [
      "大语言模型在医学问答任务中的准确性与鲁棒性如何？",
      "干扰性无关信息对大语言模型医学问答表现的影响有多大？",
      "如何提升大语言模型在临床应用中的抗干扰能力？"
    ]
  },
  "2505.23359": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解 → 视频推理",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": "视频推理",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文提出了一个用于评估多模态大模型（MLLMs）在复杂视频推理任务上的基准（VideoReasonBench），核心关注点是模型对视频中视觉内容的理解与推理能力。论文主要研究视频内容的多步推理、隐状态推断和超越视频内容的预测，属于计算机视觉领域下的视频理解，并进一步聚焦于视频推理这一具体任务。",
      "keywords": [
        "视频推理",
        "多模态大模型",
        "链式思维",
        "视频理解",
        "基准评测",
        "视觉推理"
      ],
      "methods": [
        "基准数据集构建（VideoReasonBench）",
        "多层次视频推理任务设计",
        "多模态大模型评测",
        "链式思维推理分析"
      ],
      "problems": [
        "现有视频推理基准缺乏对视觉内容的深度推理考察",
        "多模态大模型在复杂视频推理任务上的能力不足",
        "如何设计能有效评估视觉推理能力的基准任务",
        "链式思维推理在视频理解中的作用与效果"
      ]
    },
    "keywords": [
      "视频推理",
      "多模态大模型",
      "链式思维",
      "视频理解",
      "基准评测",
      "视觉推理"
    ],
    "methods": [
      "基准数据集构建（VideoReasonBench）",
      "多层次视频推理任务设计",
      "多模态大模型评测",
      "链式思维推理分析"
    ],
    "problems": [
      "现有视频推理基准缺乏对视觉内容的深度推理考察",
      "多模态大模型在复杂视频推理任务上的能力不足",
      "如何设计能有效评估视觉推理能力的基准任务",
      "链式思维推理在视频理解中的作用与效果"
    ]
  },
  "2505.23480": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型在长链式推理（Long Chain-of-Thought）中的过度思考现象，尤其是在数学推理和缺失前提的数据集上的表现。其核心研究内容为分析和改进大语言模型在推理任务中的表现，属于自然语言处理领域。具体任务为问答系统中的推理能力提升，因此归入'自然语言处理 → 问答系统'。由于标准词表未包含更细的推理任务分类，level3设为null。",
      "keywords": [
        "大语言模型",
        "链式推理",
        "过度思考",
        "自我怀疑",
        "数学推理",
        "问答系统",
        "提示工程"
      ],
      "methods": [
        "定量分析自我怀疑",
        "提示模型质疑输入问题",
        "简洁回答生成",
        "减少推理步骤"
      ],
      "problems": [
        "大语言模型在长链式推理中出现过度思考的问题",
        "自我怀疑导致的无效推理步骤",
        "如何通过提示工程减少模型的自我怀疑和推理冗余"
      ]
    },
    "keywords": [
      "大语言模型",
      "链式推理",
      "过度思考",
      "自我怀疑",
      "数学推理",
      "问答系统",
      "提示工程"
    ],
    "methods": [
      "定量分析自我怀疑",
      "提示模型质疑输入问题",
      "简洁回答生成",
      "减少推理步骤"
    ],
    "problems": [
      "大语言模型在长链式推理中出现过度思考的问题",
      "自我怀疑导致的无效推理步骤",
      "如何通过提示工程减少模型的自我怀疑和推理冗余"
    ]
  },
  "2505.23365": {
    "classification_path": "计算机科学 → 多模态学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": null,
      "level3": null,
      "depth": 2,
      "confidence": 0.95,
      "reasoning": "该论文提出了一种多模态协同融合网络（MCFNet），专注于融合和对齐多种模态（如图像与其他模态）以提升细粒度语义分类性能。论文核心在于多模态特征的融合与协同决策，属于多模态学习领域。虽然涉及图像分类，但其创新点和主要贡献在于多模态信息的协同建模与融合，因此选择'多模态学习'作为二级领域，三级及四级标准领域词表中无更细分任务，故为null。",
      "keywords": [
        "多模态融合",
        "细粒度分类",
        "协同网络",
        "语义对齐",
        "注意力机制"
      ],
      "methods": [
        "正则化集成融合模块",
        "模态特定正则化策略",
        "混合注意力机制",
        "多模态决策分类模块",
        "加权投票范式",
        "多损失函数集成"
      ],
      "problems": [
        "如何有效建模多模态间复杂且隐式的依赖关系以提升细粒度语义分类性能",
        "如何通过融合与对齐多模态特征实现高精度分类",
        "如何联合利用模态间相关性与单模态判别特征提升分类准确率"
      ]
    },
    "keywords": [
      "多模态融合",
      "细粒度分类",
      "协同网络",
      "语义对齐",
      "注意力机制"
    ],
    "methods": [
      "正则化集成融合模块",
      "模态特定正则化策略",
      "混合注意力机制",
      "多模态决策分类模块",
      "加权投票范式",
      "多损失函数集成"
    ],
    "problems": [
      "如何有效建模多模态间复杂且隐式的依赖关系以提升细粒度语义分类性能",
      "如何通过融合与对齐多模态特征实现高精度分类",
      "如何联合利用模态间相关性与单模态判别特征提升分类准确率"
    ]
  },
  "2505.23494": {
    "classification_path": "计算机科学 → 语音与音频处理 → 语音识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "语音与音频处理",
      "level2": "语音识别",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究spoken language models（SLMs），即对口语语音信号进行建模，涉及自监督声学单元的离散化、单位粗糙度与码本大小对性能的影响，以及在不同语言层次（音素、词、句子）上的表现。虽然涉及语言建模，但核心是对语音信号的建模和分析，属于语音与音频处理领域。论文未聚焦于自然语言处理中的文本建模或对话系统，而是关注语音信号的建模，因此选择'语音与音频处理'为二级领域，'语音识别'为最接近的三级领域（尽管论文更偏向于spoken language modeling，但标准词表中三级领域最接近的是'语音识别'）。",
      "keywords": [
        "spoken language modeling",
        "self-supervised units",
        "duration-penalized dynamic programming",
        "codebook size",
        "unit coarseness",
        "acoustic units"
      ],
      "methods": [
        "duration-penalized dynamic programming (DPDP)",
        "self-supervised speech representation discretization",
        "performance analysis across linguistic levels"
      ],
      "problems": [
        "探究自监督声学单元的码本大小与单位粗糙度对spoken language model性能的影响",
        "分析不同语言层次（音素、词、句子）下单位粗糙度的作用",
        "提出并验证DPDP方法在获得粗糙声学单元上的有效性"
      ]
    },
    "keywords": [
      "spoken language modeling",
      "self-supervised units",
      "duration-penalized dynamic programming",
      "codebook size",
      "unit coarseness",
      "acoustic units"
    ],
    "methods": [
      "duration-penalized dynamic programming (DPDP)",
      "self-supervised speech representation discretization",
      "performance analysis across linguistic levels"
    ],
    "problems": [
      "探究自监督声学单元的码本大小与单位粗糙度对spoken language model性能的影响",
      "分析不同语言层次（音素、词、句子）下单位粗糙度的作用",
      "提出并验证DPDP方法在获得粗糙声学单元上的有效性"
    ]
  },
  "2505.23367": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于PAN-sharpening任务，即融合高分辨率全色（PAN）图像与低分辨率多光谱（MS）图像以生成高分辨率多光谱图像。该任务属于遥感图像的超分辨率重建与多模态融合范畴，核心是生成高质量的多光谱图像。虽然涉及多模态对齐，但主要贡献在于提出新的生成框架（PAN-Crafter）和生成机制（MARs、CM3A），属于计算机视觉领域下的生成模型方向。标准词表中没有更细致的“遥感图像融合”或“图像超分辨率”选项，因此选择‘生成模型’作为最贴切的三级领域。",
      "keywords": [
        "PAN-sharpening",
        "多模态对齐",
        "高分辨率多光谱图像",
        "遥感图像融合",
        "生成模型",
        "特征自适应重建",
        "注意力机制"
      ],
      "methods": [
        "Modality-Adaptive Reconstruction (MARs)",
        "Cross-Modality Alignment-Aware Attention (CM3A)",
        "端到端深度学习框架",
        "辅助自监督"
      ],
      "problems": [
        "跨模态（PAN与MS）图像对齐误差导致的融合质量下降",
        "传统方法在存在对齐误差时产生光谱失真、边缘重复和模糊",
        "如何实现高效且鲁棒的PAN-sharpening，提升推理速度与泛化能力"
      ]
    },
    "keywords": [
      "PAN-sharpening",
      "多模态对齐",
      "高分辨率多光谱图像",
      "遥感图像融合",
      "生成模型",
      "特征自适应重建",
      "注意力机制"
    ],
    "methods": [
      "Modality-Adaptive Reconstruction (MARs)",
      "Cross-Modality Alignment-Aware Attention (CM3A)",
      "端到端深度学习框架",
      "辅助自监督"
    ],
    "problems": [
      "跨模态（PAN与MS）图像对齐误差导致的融合质量下降",
      "传统方法在存在对齐误差时产生光谱失真、边缘重复和模糊",
      "如何实现高效且鲁棒的PAN-sharpening，提升推理速度与泛化能力"
    ]
  },
  "2505.23495": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统 → 知识图谱问答",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": "知识图谱问答",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于知识图谱问答（KGQA）数据集的质量诊断与改进，提出了新的基准构建方法，并在KG-RAG（知识检索增强生成）模型上进行评测。其核心任务是提升知识图谱问答系统的评测可靠性，属于自然语言处理领域下的问答系统，具体聚焦于知识图谱问答这一细分任务。",
      "keywords": [
        "知识图谱问答",
        "数据集质量",
        "基准测试",
        "多跳推理",
        "KG-RAG",
        "LLM-in-the-loop",
        "Wikidata"
      ],
      "methods": [
        "手动审查主流KGQA数据集",
        "LLM-in-the-loop数据生成框架（KGQAGen）",
        "结构化知识对齐",
        "大语言模型引导生成",
        "符号化验证",
        "构建大规模新基准（KGQAGen-10k）"
      ],
      "problems": [
        "现有KGQA数据集存在标注不准确、问题设计不佳、知识过时等质量问题",
        "如何系统性诊断并修复KGQA数据集中的常见缺陷",
        "如何构建更具挑战性和可验证性的知识图谱问答基准",
        "现有KG-RAG模型在高质量基准下的性能瓶颈"
      ]
    },
    "keywords": [
      "知识图谱问答",
      "数据集质量",
      "基准测试",
      "多跳推理",
      "KG-RAG",
      "LLM-in-the-loop",
      "Wikidata"
    ],
    "methods": [
      "手动审查主流KGQA数据集",
      "LLM-in-the-loop数据生成框架（KGQAGen）",
      "结构化知识对齐",
      "大语言模型引导生成",
      "符号化验证",
      "构建大规模新基准（KGQAGen-10k）"
    ],
    "problems": [
      "现有KGQA数据集存在标注不准确、问题设计不佳、知识过时等质量问题",
      "如何系统性诊断并修复KGQA数据集中的常见缺陷",
      "如何构建更具挑战性和可验证性的知识图谱问答基准",
      "现有KG-RAG模型在高质量基准下的性能瓶颈"
    ]
  },
  "2505.23380": {
    "classification_path": "计算机科学 → 多模态学习 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于统一多模态大模型（涵盖图像生成与理解），提出了一种自我改进的后训练方法UniRL，结合了监督学习和强化学习。其核心创新在于模型自生成图像并用于自身训练，实现生成与理解任务的互相提升。虽然涉及生成和理解，但主要贡献在于多模态模型的自我改进与生成能力提升，最贴切的标准分类为‘多模态学习 → 生成模型’。",
      "keywords": [
        "多模态大模型",
        "自我改进",
        "图像生成",
        "图像理解",
        "后训练",
        "强化学习",
        "监督微调",
        "无外部数据"
      ],
      "methods": [
        "自我生成训练数据",
        "监督微调（SFT）",
        "Group Relative Policy Optimization（GRPO）",
        "生成-理解互助训练"
      ],
      "problems": [
        "如何在无需外部数据的情况下提升多模态大模型的生成与理解能力",
        "如何实现生成与理解任务的互相促进",
        "如何降低多模态模型后训练的计算与数据需求"
      ]
    },
    "keywords": [
      "多模态大模型",
      "自我改进",
      "图像生成",
      "图像理解",
      "后训练",
      "强化学习",
      "监督微调",
      "无外部数据"
    ],
    "methods": [
      "自我生成训练数据",
      "监督微调（SFT）",
      "Group Relative Policy Optimization（GRPO）",
      "生成-理解互助训练"
    ],
    "problems": [
      "如何在无需外部数据的情况下提升多模态大模型的生成与理解能力",
      "如何实现生成与理解任务的互相促进",
      "如何降低多模态模型后训练的计算与数据需求"
    ]
  },
  "2505.23538": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于企业ESG报告中承诺的自动验证，涉及承诺识别、证据评估、清晰度评价和验证时机等子任务，均属于自然语言理解与信息抽取范畴。论文采用了BERT变体、特征增强、注意力机制和多任务学习等方法，核心任务是对文本中的承诺进行自动化问答式验证，最贴近标准领域词表中的‘自然语言处理 → 问答系统’。虽然涉及多模型架构，但主要任务不是生成、对话或代码生成，因此选择‘问答系统’作为三级领域，四级领域暂无更细致标准任务，设为null。",
      "keywords": [
        "ESG报告",
        "承诺验证",
        "多模型架构",
        "BERT",
        "多任务学习",
        "注意力机制",
        "语言特征提取"
      ],
      "methods": [
        "ESG-BERT与任务特定分类头",
        "语言特征增强",
        "注意力池化",
        "Transformer与文档元数据融合",
        "多目标学习"
      ],
      "problems": [
        "如何自动识别和验证企业ESG报告中的承诺",
        "如何评估承诺的支持证据和清晰度",
        "如何提升在类别不平衡和训练数据有限情况下的验证性能"
      ]
    },
    "keywords": [
      "ESG报告",
      "承诺验证",
      "多模型架构",
      "BERT",
      "多任务学习",
      "注意力机制",
      "语言特征提取"
    ],
    "methods": [
      "ESG-BERT与任务特定分类头",
      "语言特征增强",
      "注意力池化",
      "Transformer与文档元数据融合",
      "多目标学习"
    ],
    "problems": [
      "如何自动识别和验证企业ESG报告中的承诺",
      "如何评估承诺的支持证据和清晰度",
      "如何提升在类别不平衡和训练数据有限情况下的验证性能"
    ]
  },
  "2505.23386": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于NSFW（不适宜工作/未成年人）图像的自动检测与审核，属于图像内容的识别与分类任务。虽然涉及多模态和适应不同规则，但核心任务是对图像内容进行检测和分类，最符合'计算机视觉'下的'目标检测'。论文没有聚焦于分割、三维重建等其他视觉任务，也未涉及自然语言、音频等多模态深度融合，因此选择'目标检测'作为三级领域，四级领域暂无更细分标准任务，设为null。",
      "keywords": [
        "NSFW内容检测",
        "图像审核",
        "自适应框架",
        "复杂语义",
        "内容审核",
        "多类别适应"
      ],
      "methods": [
        "深度学习图像识别",
        "自适应检测框架（VModA）",
        "跨类别与场景适应",
        "基于视觉语言模型（VLM）",
        "数据集重标注与纠错"
      ],
      "problems": [
        "现有NSFW图像检测方法难以识别复杂语义和伪装内容",
        "不同平台和地区审核规则差异导致检测偏差和准确率下降",
        "公开数据集标签不一致和有争议样本影响模型性能",
        "如何设计通用且能适应多种审核规则的NSFW检测框架"
      ]
    },
    "keywords": [
      "NSFW内容检测",
      "图像审核",
      "自适应框架",
      "复杂语义",
      "内容审核",
      "多类别适应"
    ],
    "methods": [
      "深度学习图像识别",
      "自适应检测框架（VModA）",
      "跨类别与场景适应",
      "基于视觉语言模型（VLM）",
      "数据集重标注与纠错"
    ],
    "problems": [
      "现有NSFW图像检测方法难以识别复杂语义和伪装内容",
      "不同平台和地区审核规则差异导致检测偏差和准确率下降",
      "公开数据集标签不一致和有争议样本影响模型性能",
      "如何设计通用且能适应多种审核规则的NSFW检测框架"
    ]
  },
  "2505.23540": {
    "classification_path": "计算机科学 → 大语言模型 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于提升大语言模型（LLM）的数学推理能力，提出了一种新的偏好优化方法（PCPO），主要针对LLM在问答任务中的答案一致性和概率一致性进行优化。虽然涉及偏好优化和概率一致性等方法，但核心应用场景是提升LLM在问答系统中的推理表现，因此选择'大语言模型 → 问答系统'作为最合适的分类路径。由于标准领域词表中未包含更细致的任务（如数学推理），level3设为null。",
      "keywords": [
        "大语言模型",
        "偏好优化",
        "概率一致性",
        "数学推理",
        "问答系统"
      ],
      "methods": [
        "概率一致性偏好优化（PCPO）",
        "双重量化指标（答案正确性与概率一致性）",
        "基于pairwise偏好数据的优化"
      ],
      "problems": [
        "现有偏好优化方法忽略了LLM回答的内部逻辑一致性",
        "如何通过概率一致性提升LLM在数学推理等问答任务中的表现"
      ]
    },
    "keywords": [
      "大语言模型",
      "偏好优化",
      "概率一致性",
      "数学推理",
      "问答系统"
    ],
    "methods": [
      "概率一致性偏好优化（PCPO）",
      "双重量化指标（答案正确性与概率一致性）",
      "基于pairwise偏好数据的优化"
    ],
    "problems": [
      "现有偏好优化方法忽略了LLM回答的内部逻辑一致性",
      "如何通过概率一致性提升LLM在数学推理等问答任务中的表现"
    ]
  },
  "2505.23392": {
    "classification_path": "计算机科学 → 医学图像 → 医学图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "医学图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于压力性溃疡等真实世界伤口图像的自动分割，属于医学图像领域。其核心任务是实现无需像素级标注的伤口分割，直接服务于临床自动化评分（DESIGN-R），并在不同身体部位的伤口上验证泛化能力。论文方法结合了目标检测（YOLOv11n）与医学图像分割（FUSegNet），但最终目标和主要贡献是提升医学图像分割的实用性和泛化性，因此归入'医学图像'→'医学图像分割'最为合适。",
      "keywords": [
        "医学图像分割",
        "伤口分割",
        "压力性溃疡",
        "自动化评分",
        "泛化能力",
        "无标注",
        "YOLOv11n",
        "FUSegNet",
        "DESIGN-R"
      ],
      "methods": [
        "YOLOv11n目标检测器",
        "FUSegNet分割模型",
        "零微调（zero fine-tuning）",
        "少量标注（bounding box）",
        "端到端分割管线"
      ],
      "problems": [
        "现有伤口分割模型在不同身体部位泛化能力差",
        "依赖大量像素级标注，难以扩展到新解剖区域",
        "如何在标注极少的情况下实现稳健的伤口分割",
        "如何实现自动化、客观、一致的DESIGN-R评分"
      ]
    },
    "keywords": [
      "医学图像分割",
      "伤口分割",
      "压力性溃疡",
      "自动化评分",
      "泛化能力",
      "无标注",
      "YOLOv11n",
      "FUSegNet",
      "DESIGN-R"
    ],
    "methods": [
      "YOLOv11n目标检测器",
      "FUSegNet分割模型",
      "零微调（zero fine-tuning）",
      "少量标注（bounding box）",
      "端到端分割管线"
    ],
    "problems": [
      "现有伤口分割模型在不同身体部位泛化能力差",
      "依赖大量像素级标注，难以扩展到新解剖区域",
      "如何在标注极少的情况下实现稳健的伤口分割",
      "如何实现自动化、客观、一致的DESIGN-R评分"
    ]
  },
  "2505.23548": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要探讨大语言模型（LLMs）在翻译任务中的能力来源及其机制，属于自然语言处理领域。虽然论文涉及大语言模型，但其核心问题是翻译能力的机制分析和任务归因，属于NLP范畴。标准词表中没有直接的'机器翻译'或'翻译'任务，因此选择与大语言模型相关的'生成模型'作为三级领域，最贴合论文内容。",
      "keywords": [
        "大语言模型",
        "翻译",
        "生成模型",
        "零样本学习",
        "指令微调",
        "语义对齐"
      ],
      "methods": [
        "文献分析",
        "假设提出（duality hypothesis）",
        "经验反思"
      ],
      "problems": [
        "大语言模型为何具备强大的翻译能力？",
        "翻译能力是否源于训练数据中的偶发双语现象？",
        "指令微调对翻译能力有何影响？",
        "大语言模型能否对齐并利用不同来源的语义相似单语内容？",
        "如何实证检验大语言模型翻译能力的双重来源假设？"
      ]
    },
    "keywords": [
      "大语言模型",
      "翻译",
      "生成模型",
      "零样本学习",
      "指令微调",
      "语义对齐"
    ],
    "methods": [
      "文献分析",
      "假设提出（duality hypothesis）",
      "经验反思"
    ],
    "problems": [
      "大语言模型为何具备强大的翻译能力？",
      "翻译能力是否源于训练数据中的偶发双语现象？",
      "指令微调对翻译能力有何影响？",
      "大语言模型能否对齐并利用不同来源的语义相似单语内容？",
      "如何实证检验大语言模型翻译能力的双重来源假设？"
    ]
  },
  "2505.23395": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "图像分割",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于CAD图纸中的panoptic symbol spotting任务，本质上涉及对可数目标（符号实例）和不可数区域（语义区域）的联合检测与分割。该任务属于计算机视觉领域，具体涉及目标检测（符号实例检测）和图像分割（语义区域分割），而'panoptic'任务正是目标检测与分割的结合。标准领域词表中没有单独的'全景分割'，但'目标检测'和'图像分割'均为相关三级领域，考虑到任务的复合性，level3选择'图像分割'以覆盖panoptic分割的语义分割部分。",
      "keywords": [
        "panoptic symbol spotting",
        "CAD drawings",
        "vector graphics",
        "line-based representation",
        "VecFormer",
        "Branch Fusion Refinement",
        "panoptic segmentation"
      ],
      "methods": [
        "line-based representation of primitives",
        "VecFormer architecture",
        "Branch Fusion Refinement module"
      ],
      "problems": [
        "如何在CAD图纸中同时检测可数符号实例和不可数语义区域（panoptic symbol spotting）",
        "如何避免现有方法在矢量图理解中出现的高计算成本、泛化性差和几何结构信息丢失问题",
        "如何融合实例与语义预测以获得一致且高质量的全景输出"
      ]
    },
    "keywords": [
      "panoptic symbol spotting",
      "CAD drawings",
      "vector graphics",
      "line-based representation",
      "VecFormer",
      "Branch Fusion Refinement",
      "panoptic segmentation"
    ],
    "methods": [
      "line-based representation of primitives",
      "VecFormer architecture",
      "Branch Fusion Refinement module"
    ],
    "problems": [
      "如何在CAD图纸中同时检测可数符号实例和不可数语义区域（panoptic symbol spotting）",
      "如何避免现有方法在矢量图理解中出现的高计算成本、泛化性差和几何结构信息丢失问题",
      "如何融合实例与语义预测以获得一致且高质量的全景输出"
    ]
  },
  "2505.23556": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）在对话场景下的拒绝行为机制分析，采用稀疏自编码器对模型内部激活进行解释和干预。虽然论文涉及大语言模型，但其核心任务是理解和干预对话系统中的安全性（拒绝）行为，最贴切的标准分类为‘自然语言处理 → 对话系统’。由于标准词表中没有更细致的‘安全性’或‘拒绝检测’等四级任务，level3设为null。",
      "keywords": [
        "拒绝行为",
        "大语言模型",
        "稀疏自编码器",
        "安全性",
        "对话系统",
        "指令微调",
        "激活解释",
        "对抗攻击"
      ],
      "methods": [
        "稀疏自编码器分析",
        "激活干预",
        "因果特征提取",
        "线性探测器泛化评估"
      ],
      "problems": [
        "揭示大语言模型中驱动拒绝行为的内部机制",
        "识别和干预与拒绝相关的潜在特征",
        "分析拒绝特征对生成行为的因果影响",
        "理解对抗性越狱技术的机制",
        "提升对抗样本分类任务中的泛化能力"
      ]
    },
    "keywords": [
      "拒绝行为",
      "大语言模型",
      "稀疏自编码器",
      "安全性",
      "对话系统",
      "指令微调",
      "激活解释",
      "对抗攻击"
    ],
    "methods": [
      "稀疏自编码器分析",
      "激活干预",
      "因果特征提取",
      "线性探测器泛化评估"
    ],
    "problems": [
      "揭示大语言模型中驱动拒绝行为的内部机制",
      "识别和干预与拒绝相关的潜在特征",
      "分析拒绝特征对生成行为的因果影响",
      "理解对抗性越狱技术的机制",
      "提升对抗样本分类任务中的泛化能力"
    ]
  },
  "2505.23400": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 单目深度估计",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "单目深度估计",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "论文聚焦于单目深度估计（Monocular Depth Estimation, MDE），这是计算机视觉领域三维重建方向下的一个具体任务。论文提出的方法融合了几何和语义基础模型，旨在提升单目深度估计在复杂场景下的泛化能力和表现，因此最合适的分类路径为‘计算机科学 → 计算机视觉 → 三维重建 → 单目深度估计’。",
      "keywords": [
        "单目深度估计",
        "基础模型",
        "几何信息",
        "语义信息",
        "注意力机制",
        "模型融合"
      ],
      "methods": [
        "Bridging Gate（几何与语义信息融合）",
        "Attention Temperature Scaling（注意力温度缩放）",
        "利用预训练基础模型",
        "只训练融合模块以降低资源消耗"
      ],
      "problems": [
        "如何有效融合几何和语义基础模型以提升单目深度估计的泛化能力",
        "如何防止注意力机制过度关注特定特征导致性能不均衡",
        "如何在降低训练资源和时间的同时保持模型性能"
      ]
    },
    "keywords": [
      "单目深度估计",
      "基础模型",
      "几何信息",
      "语义信息",
      "注意力机制",
      "模型融合"
    ],
    "methods": [
      "Bridging Gate（几何与语义信息融合）",
      "Attention Temperature Scaling（注意力温度缩放）",
      "利用预训练基础模型",
      "只训练融合模块以降低资源消耗"
    ],
    "problems": [
      "如何有效融合几何和语义基础模型以提升单目深度估计的泛化能力",
      "如何防止注意力机制过度关注特定特征导致性能不均衡",
      "如何在降低训练资源和时间的同时保持模型性能"
    ]
  },
  "2505.23570": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要研究利用大语言模型（LLMs）对YouTube上的阴谋论视频进行检测，核心任务是对文本内容进行理解和分类。虽然涉及多模态模型，但主要对比对象和最优结果均为文本模型，且任务本质属于自然语言处理领域下的内容理解与判别。标准词表中没有直接对应'文本分类'或'有害内容检测'的更细分任务，'问答系统'作为内容理解的代表性任务最为接近，因此选择该路径。",
      "keywords": [
        "大语言模型",
        "阴谋论检测",
        "YouTube",
        "多模态模型",
        "文本分类",
        "有害内容检测",
        "RoBERTa",
        "零样本学习"
      ],
      "methods": [
        "零样本大语言模型评估",
        "多模态模型与文本模型对比",
        "有监督基线（RoBERTa）",
        "真实世界数据集测试"
      ],
      "problems": [
        "如何利用大语言模型检测YouTube上的阴谋论视频",
        "多模态模型在有害内容检测中的有效性",
        "当前LLM方法在实际应用中的优势与局限"
      ]
    },
    "keywords": [
      "大语言模型",
      "阴谋论检测",
      "YouTube",
      "多模态模型",
      "文本分类",
      "有害内容检测",
      "RoBERTa",
      "零样本学习"
    ],
    "methods": [
      "零样本大语言模型评估",
      "多模态模型与文本模型对比",
      "有监督基线（RoBERTa）",
      "真实世界数据集测试"
    ],
    "problems": [
      "如何利用大语言模型检测YouTube上的阴谋论视频",
      "多模态模型在有害内容检测中的有效性",
      "当前LLM方法在实际应用中的优势与局限"
    ]
  },
  "2505.23406": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 视频编辑",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "视频编辑",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于视频中人物口型与音频同步的视觉配音问题，提出了一种内容感知的视频编辑方法（EdiDub），以实现更自然的口型同步和身份保持。论文核心在于视频内容的生成式编辑，属于计算机视觉领域下的生成模型，并具体应用于视频编辑任务，因此选择'计算机视觉 → 生成模型 → 视频编辑'作为分类路径。",
      "keywords": [
        "视觉配音",
        "视频编辑",
        "口型同步",
        "内容感知编辑",
        "身份保持",
        "生成模型"
      ],
      "methods": [
        "内容感知编辑框架（EdiDub）",
        "专用条件控制机制",
        "对比传统生成与修复方法"
      ],
      "problems": [
        "如何在视频配音中实现口型与音频的高精度同步",
        "如何在编辑过程中保持原视频的身份和复杂视觉元素",
        "如何克服现有方法在遮挡和光照变化下的表现不足"
      ]
    },
    "keywords": [
      "视觉配音",
      "视频编辑",
      "口型同步",
      "内容感知编辑",
      "身份保持",
      "生成模型"
    ],
    "methods": [
      "内容感知编辑框架（EdiDub）",
      "专用条件控制机制",
      "对比传统生成与修复方法"
    ],
    "problems": [
      "如何在视频配音中实现口型与音频的高精度同步",
      "如何在编辑过程中保持原视频的身份和复杂视觉元素",
      "如何克服现有方法在遮挡和光照变化下的表现不足"
    ]
  },
  "2505.23604": {
    "classification_path": "计算机科学 → 大语言模型 → 代码生成 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "代码生成",
      "level3": "小样本学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于提升中小规模大语言模型在真实软件工程任务（如SWE-Bench代码修复）上的性能，核心方法为进化式测试时扩展（EvoScale），强调在有限样本下高效生成正确代码。论文主要贡献在于大语言模型的代码生成能力提升，且方法属于小样本学习范畴，因此选择“大语言模型 → 代码生成 → 小样本学习”作为最合适的分层分类路径。",
      "keywords": [
        "大语言模型",
        "代码生成",
        "软件工程",
        "进化算法",
        "测试时扩展",
        "小样本学习",
        "强化学习",
        "SWE-Bench"
      ],
      "methods": [
        "进化式测试时扩展（EvoScale）",
        "强化学习自进化训练",
        "样本高效生成",
        "输出分布迭代优化"
      ],
      "problems": [
        "如何提升中小规模大语言模型在真实软件工程任务中的代码生成能力",
        "如何在有限样本下高效找到正确代码解决方案",
        "如何减少依赖外部验证器和高昂的采样成本"
      ]
    },
    "keywords": [
      "大语言模型",
      "代码生成",
      "软件工程",
      "进化算法",
      "测试时扩展",
      "小样本学习",
      "强化学习",
      "SWE-Bench"
    ],
    "methods": [
      "进化式测试时扩展（EvoScale）",
      "强化学习自进化训练",
      "样本高效生成",
      "输出分布迭代优化"
    ],
    "problems": [
      "如何提升中小规模大语言模型在真实软件工程任务中的代码生成能力",
      "如何在有限样本下高效找到正确代码解决方案",
      "如何减少依赖外部验证器和高昂的采样成本"
    ]
  },
  "2505.23434": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 新视角合成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "新视角合成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于城市场景的视角外推（Extrapolated View Synthesis, EVS），属于三维重建领域中的新视角合成任务。其主要贡献是提出了结合语义与几何先验的分层方法以提升新视角合成的泛化能力。虽然涉及生成模型和扩散模型，但核心任务是三维重建中的新视角合成，因此选择该分类路径。",
      "keywords": [
        "城市场景重建",
        "新视角合成",
        "三维重建",
        "语义先验",
        "几何先验",
        "分层表示",
        "扩散模型"
      ],
      "methods": [
        "分层语义-几何先验建模",
        "占用网格粗粒度场景表示",
        "3D包围盒细粒度实例先验",
        "语义-几何引导的变分分数蒸馏（HSG-VSD）"
      ],
      "problems": [
        "提升城市场景在训练视角分布外的新视角合成质量",
        "解决基于扩散的图像生成在大视角外推和语义歧义下的表现不足问题"
      ]
    },
    "keywords": [
      "城市场景重建",
      "新视角合成",
      "三维重建",
      "语义先验",
      "几何先验",
      "分层表示",
      "扩散模型"
    ],
    "methods": [
      "分层语义-几何先验建模",
      "占用网格粗粒度场景表示",
      "3D包围盒细粒度实例先验",
      "语义-几何引导的变分分数蒸馏（HSG-VSD）"
    ],
    "problems": [
      "提升城市场景在训练视角分布外的新视角合成质量",
      "解决基于扩散的图像生成在大视角外推和语义歧义下的表现不足问题"
    ]
  },
  "2505.23621": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于表格推理任务，主要研究如何提升大语言模型在表格问答、事实验证等任务上的推理能力。表格推理属于自然语言处理领域中的问答系统分支，尤其是结构化数据上的问答。论文提出的推理时刻扩展、蒸馏与强化学习方法，均服务于提升表格问答系统的性能，因此选择'自然语言处理→问答系统'作为最合适的分类路径。",
      "keywords": [
        "表格推理",
        "推理时刻扩展",
        "大语言模型",
        "知识蒸馏",
        "强化学习",
        "事实验证",
        "问答系统",
        "泛化能力"
      ],
      "methods": [
        "推理轨迹蒸馏",
        "可验证奖励的强化学习（RLVR）",
        "GRPO算法",
        "指令微调"
      ],
      "problems": [
        "如何在推理阶段扩展大语言模型以提升表格推理任务的性能",
        "如何通过后训练策略（如蒸馏和强化学习）提升小参数模型在表格推理任务上的表现",
        "如何实现模型在表格问答、事实验证等多任务上的泛化能力"
      ]
    },
    "keywords": [
      "表格推理",
      "推理时刻扩展",
      "大语言模型",
      "知识蒸馏",
      "强化学习",
      "事实验证",
      "问答系统",
      "泛化能力"
    ],
    "methods": [
      "推理轨迹蒸馏",
      "可验证奖励的强化学习（RLVR）",
      "GRPO算法",
      "指令微调"
    ],
    "problems": [
      "如何在推理阶段扩展大语言模型以提升表格推理任务的性能",
      "如何通过后训练策略（如蒸馏和强化学习）提升小参数模型在表格推理任务上的表现",
      "如何实现模型在表格问答、事实验证等多任务上的泛化能力"
    ]
  },
  "2505.23438": {
    "classification_path": "计算机科学 → 计算机视觉 → 图像分割 → 半监督语义分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "图像分割",
      "level3": "半监督语义分割",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "论文聚焦于半监督语义分割（Semi-supervised Semantic Segmentation），提出了一种自适应空间增强方法（Adaptive Spatial Augmentation），并在PASCAL VOC 2012、Cityscapes和COCO等标准分割数据集上验证。其核心任务是提升半监督条件下的语义分割性能，属于计算机视觉领域下的图像分割，并具体聚焦于半监督语义分割这一细分任务。",
      "keywords": [
        "半监督学习",
        "语义分割",
        "数据增强",
        "空间增强",
        "自适应增强",
        "一致性正则化"
      ],
      "methods": [
        "自适应空间增强（ASAug）",
        "基于熵的动态增强策略",
        "弱-强一致性正则化框架"
      ],
      "problems": [
        "如何在半监督语义分割中有效利用空间增强方法提升模型泛化能力",
        "如何根据图像实例的特性自适应调整增强策略以提升分割性能",
        "如何解决空间增强导致的弱-强增强掩码不一致问题"
      ]
    },
    "keywords": [
      "半监督学习",
      "语义分割",
      "数据增强",
      "空间增强",
      "自适应增强",
      "一致性正则化"
    ],
    "methods": [
      "自适应空间增强（ASAug）",
      "基于熵的动态增强策略",
      "弱-强一致性正则化框架"
    ],
    "problems": [
      "如何在半监督语义分割中有效利用空间增强方法提升模型泛化能力",
      "如何根据图像实例的特性自适应调整增强策略以提升分割性能",
      "如何解决空间增强导致的弱-强增强掩码不一致问题"
    ]
  },
  "2505.23623": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究Transformer语言模型的表达能力，从理论和实证角度分析其在自然语言处理中的表达极限。虽然涉及理论计算和形式语言，但核心聚焦于自然语言处理领域下的生成模型（即语言模型）的表达性分析，因此选择'自然语言处理'作为二级领域，'生成模型'作为三级领域。论文未聚焦于具体应用任务（如问答、对话等），也未涉及更细粒度的四级任务，因此level3设为null。",
      "keywords": [
        "Transformer",
        "语言模型",
        "表达能力",
        "线性时序逻辑",
        "形式语言理论",
        "软注意力",
        "未来掩码"
      ],
      "methods": [
        "理论表达性分析",
        "线性时序逻辑映射",
        "形式语言与自动机理论关联",
        "实证验证"
      ],
      "problems": [
        "Transformer语言模型在实际实现下的理论表达能力如何刻画？",
        "实际Transformer模型与形式逻辑、自动机理论的表达能力有何对应关系？",
        "Transformer模型在理论表达能力范围内外的泛化能力表现如何？"
      ]
    },
    "keywords": [
      "Transformer",
      "语言模型",
      "表达能力",
      "线性时序逻辑",
      "形式语言理论",
      "软注意力",
      "未来掩码"
    ],
    "methods": [
      "理论表达性分析",
      "线性时序逻辑映射",
      "形式语言与自动机理论关联",
      "实证验证"
    ],
    "problems": [
      "Transformer语言模型在实际实现下的理论表达能力如何刻画？",
      "实际Transformer模型与形式逻辑、自动机理论的表达能力有何对应关系？",
      "Transformer模型在理论表达能力范围内外的泛化能力表现如何？"
    ]
  },
  "2505.23439": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 虚拟试衣",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "虚拟试衣",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于基于图像的虚拟试衣（virtual try-on），属于计算机视觉领域的生成模型应用。其核心任务是将服装图像准确地拟合到人物图像上，属于生成模型在虚拟试衣这一具体应用场景下的研究。论文提出了基于非刚性配准的细节保留方法，强调服装细节的保真和人物姿态的适应性，完全符合‘生成模型’下‘虚拟试衣’这一具体任务。",
      "keywords": [
        "虚拟试衣",
        "非刚性配准",
        "细节保留",
        "图像生成",
        "服装变形",
        "人像合成"
      ],
      "methods": [
        "双金字塔结构特征提取",
        "非刚性配准算法",
        "服装关键点提取",
        "图像合成模块"
      ],
      "problems": [
        "如何在虚拟试衣中准确变形服装以适应不同人体姿态",
        "如何在服装变形过程中最大程度保留服装细节",
        "如何减少服装与人体姿态不匹配导致的不真实伪影"
      ]
    },
    "keywords": [
      "虚拟试衣",
      "非刚性配准",
      "细节保留",
      "图像生成",
      "服装变形",
      "人像合成"
    ],
    "methods": [
      "双金字塔结构特征提取",
      "非刚性配准算法",
      "服装关键点提取",
      "图像合成模块"
    ],
    "problems": [
      "如何在虚拟试衣中准确变形服装以适应不同人体姿态",
      "如何在服装变形过程中最大程度保留服装细节",
      "如何减少服装与人体姿态不匹配导致的不真实伪影"
    ]
  },
  "2505.23628": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于通过大语言模型从大规模文本中自动构建知识图谱，并在多跳问答任务上验证其有效性。虽然涉及知识图谱构建和schema归纳，但主要应用和评测场景为多跳问答系统，因此选择‘自然语言处理 → 问答系统’作为最合适的分类路径。",
      "keywords": [
        "知识图谱",
        "动态schema归纳",
        "大语言模型",
        "多跳问答",
        "自动化信息抽取",
        "语义对齐"
      ],
      "methods": [
        "利用大语言模型进行知识三元组抽取",
        "动态schema自动归纳",
        "实例概念化与语义分类",
        "大规模文本处理",
        "自动化知识图谱构建"
      ],
      "problems": [
        "如何无需预定义schema自动构建大规模知识图谱",
        "如何提升知识图谱在多跳问答和LLM事实性任务中的表现",
        "如何实现schema自动归纳并与人工schema高语义对齐"
      ]
    },
    "keywords": [
      "知识图谱",
      "动态schema归纳",
      "大语言模型",
      "多跳问答",
      "自动化信息抽取",
      "语义对齐"
    ],
    "methods": [
      "利用大语言模型进行知识三元组抽取",
      "动态schema自动归纳",
      "实例概念化与语义分类",
      "大规模文本处理",
      "自动化知识图谱构建"
    ],
    "problems": [
      "如何无需预定义schema自动构建大规模知识图谱",
      "如何提升知识图谱在多跳问答和LLM事实性任务中的表现",
      "如何实现schema自动归纳并与人工schema高语义对齐"
    ]
  },
  "2505.23444": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要聚焦于通过生成模型（尤其是扩散模型）合成高质量的cryo-EM微图像，用于提升下游视觉任务（如粒子识别和三维重建）的性能。论文核心创新点在于结合生物物理建模与条件扩散模型，强调结构多样性和噪声建模，属于计算机视觉领域下的生成模型，具体方法为扩散模型。",
      "keywords": [
        "Cryo-EM",
        "扩散模型",
        "生成模型",
        "生物物理建模",
        "合成数据",
        "噪声建模",
        "条件生成",
        "循环一致性",
        "对比学习"
      ],
      "methods": [
        "条件扩散模型",
        "生物物理建模",
        "循环一致性约束",
        "掩码感知对比学习"
      ],
      "problems": [
        "如何生成结构多样且噪声真实的cryo-EM合成数据",
        "现有合成方法难以同时建模生物结构多样性与空间变化噪声",
        "提升下游任务（如粒子识别和三维重建）在数据稀缺场景下的性能"
      ]
    },
    "keywords": [
      "Cryo-EM",
      "扩散模型",
      "生成模型",
      "生物物理建模",
      "合成数据",
      "噪声建模",
      "条件生成",
      "循环一致性",
      "对比学习"
    ],
    "methods": [
      "条件扩散模型",
      "生物物理建模",
      "循环一致性约束",
      "掩码感知对比学习"
    ],
    "problems": [
      "如何生成结构多样且噪声真实的cryo-EM合成数据",
      "现有合成方法难以同时建模生物结构多样性与空间变化噪声",
      "提升下游任务（如粒子识别和三维重建）在数据稀缺场景下的性能"
    ]
  },
  "2505.23630": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于法语文本的性别中性化重写系统，属于自然语言处理领域。其核心任务是自动将带有性别偏见的文本转换为性别中性的表达，属于文本生成范畴。虽然论文涉及性别偏见消除，但其主要贡献是提出并实现了性别中性化的文本生成系统，因此归入‘自然语言处理 → 生成模型’最为贴切。标准领域词表中没有更细致的任务分类（如‘文本重写’或‘性别中性化’），因此level3设为null。",
      "keywords": [
        "性别中性化",
        "文本重写",
        "法语",
        "性别偏见",
        "自然语言处理",
        "生成模型",
        "集体名词"
      ],
      "methods": [
        "基于规则的系统（RBS）",
        "微调语言模型",
        "instruct-based模型",
        "字典结合方法"
      ],
      "problems": [
        "如何自动将法语中带有性别偏见的文本重写为性别中性表达？",
        "如何利用集体名词实现法语的性别中性化？",
        "如何提升法语性别中性化重写系统的性能？"
      ]
    },
    "keywords": [
      "性别中性化",
      "文本重写",
      "法语",
      "性别偏见",
      "自然语言处理",
      "生成模型",
      "集体名词"
    ],
    "methods": [
      "基于规则的系统（RBS）",
      "微调语言模型",
      "instruct-based模型",
      "字典结合方法"
    ],
    "problems": [
      "如何自动将法语中带有性别偏见的文本重写为性别中性表达？",
      "如何利用集体名词实现法语的性别中性化？",
      "如何提升法语性别中性化重写系统的性能？"
    ]
  },
  "2505.23451": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 场景图生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "场景图生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于场景图生成（Scene Graph Generation, SGG），这是计算机视觉领域中基于目标检测的高级视觉理解任务。论文主要研究如何通过逆向因果结构缓解SGG中的偏差问题，属于目标检测的下游任务。根据标准领域词表，'目标检测'是最贴切的三级领域，'场景图生成'是具体任务，符合四级分类要求。",
      "keywords": [
        "场景图生成",
        "逆向因果框架",
        "去偏置",
        "虚假相关性",
        "主动逆向估计",
        "最大信息采样"
      ],
      "methods": [
        "逆向因果框架（RcSGG）",
        "主动逆向估计（ARE）",
        "最大信息采样（MIS）"
      ],
      "problems": [
        "现有场景图生成框架中检测器输入与最终预测之间存在虚假相关性，导致偏差",
        "尾部关系被预测为头部关系，前景关系被预测为背景关系",
        "如何通过重构因果结构缓解上述偏差，提高场景图生成的公平性和准确性"
      ]
    },
    "keywords": [
      "场景图生成",
      "逆向因果框架",
      "去偏置",
      "虚假相关性",
      "主动逆向估计",
      "最大信息采样"
    ],
    "methods": [
      "逆向因果框架（RcSGG）",
      "主动逆向估计（ARE）",
      "最大信息采样（MIS）"
    ],
    "problems": [
      "现有场景图生成框架中检测器输入与最终预测之间存在虚假相关性，导致偏差",
      "尾部关系被预测为头部关系，前景关系被预测为背景关系",
      "如何通过重构因果结构缓解上述偏差，提高场景图生成的公平性和准确性"
    ]
  },
  "2505.23646": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注大规模推理模型（LRMs）在事实性问答任务中的幻觉现象，分析其后训练流程对幻觉的影响，并从模型行为和不确定性角度探讨幻觉机制。虽然涉及大语言模型，但研究核心是模型在问答任务中的表现及其幻觉问题，因此归入‘自然语言处理 → 问答系统’最为贴切。",
      "keywords": [
        "大规模推理模型",
        "幻觉",
        "事实性问答",
        "链式思维",
        "后训练",
        "模型不确定性"
      ],
      "methods": [
        "全流程幻觉评估",
        "行为分析（Flaw Repetition与Think-Answer Mismatch）",
        "模型不确定性与事实准确性关联分析"
      ],
      "problems": [
        "大规模推理模型是否更易产生幻觉？",
        "不同后训练流程如何影响模型幻觉表现？",
        "哪些模型行为导致事实性问答中的幻觉？",
        "模型不确定性与幻觉之间的关系是什么？"
      ]
    },
    "keywords": [
      "大规模推理模型",
      "幻觉",
      "事实性问答",
      "链式思维",
      "后训练",
      "模型不确定性"
    ],
    "methods": [
      "全流程幻觉评估",
      "行为分析（Flaw Repetition与Think-Answer Mismatch）",
      "模型不确定性与事实准确性关联分析"
    ],
    "problems": [
      "大规模推理模型是否更易产生幻觉？",
      "不同后训练流程如何影响模型幻觉表现？",
      "哪些模型行为导致事实性问答中的幻觉？",
      "模型不确定性与幻觉之间的关系是什么？"
    ]
  },
  "2505.23462": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于基于扩散模型的盲人脸修复任务，提出了一种高效的潜在空间对齐适配器（LAFR），用于提升低质量人脸图像的重建质量和身份保持能力。论文核心方法为扩散模型的改进与适配，属于计算机视觉领域下的生成模型，具体聚焦于扩散模型在图像修复中的应用。因此，最合适的分类路径为‘计算机科学 → 计算机视觉 → 生成模型 → 扩散模型’。",
      "keywords": [
        "盲人脸修复",
        "扩散模型",
        "潜在空间对齐",
        "身份保持",
        "高效训练"
      ],
      "methods": [
        "基于潜在代码本的对齐适配器（LAFR）",
        "多层次修复损失（结合身份嵌入与结构先验）",
        "轻量级扩散先验微调"
      ],
      "problems": [
        "如何在不重新训练VAE编码器的情况下，实现低质量人脸图像与高质量图像潜在空间的语义对齐",
        "如何在盲人脸修复中同时提升重建质量与身份保持能力",
        "如何降低训练成本并提升修复效率"
      ]
    },
    "keywords": [
      "盲人脸修复",
      "扩散模型",
      "潜在空间对齐",
      "身份保持",
      "高效训练"
    ],
    "methods": [
      "基于潜在代码本的对齐适配器（LAFR）",
      "多层次修复损失（结合身份嵌入与结构先验）",
      "轻量级扩散先验微调"
    ],
    "problems": [
      "如何在不重新训练VAE编码器的情况下，实现低质量人脸图像与高质量图像潜在空间的语义对齐",
      "如何在盲人脸修复中同时提升重建质量与身份保持能力",
      "如何降低训练成本并提升修复效率"
    ]
  },
  "2505.23654": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型 → 长文档摘要",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": "长文档摘要",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于长文档的自动摘要，尤其关注大语言模型在零样本条件下生成摘要时对论证结构（argument roles）的保留情况，并提出了新的评估框架ARC。论文属于自然语言处理领域，具体任务为生成模型下的长文档摘要，且与大语言模型的指令跟随能力密切相关。标准领域词表中，'生成模型'涵盖了摘要生成任务，'长文档摘要'为具体应用任务，因此选择该分类路径。",
      "keywords": [
        "长文档摘要",
        "大语言模型",
        "指令跟随",
        "论证结构",
        "摘要生成",
        "结构化信息",
        "法律文本",
        "科学文献"
      ],
      "methods": [
        "Argument Representation Coverage (ARC) 框架",
        "基于结构化论证角色的摘要评估",
        "对比不同开源大语言模型的摘要表现",
        "分析上下文窗口位置偏置与角色偏好"
      ],
      "problems": [
        "大语言模型在零样本长文档摘要任务中能否充分保留和覆盖关键论证角色信息",
        "现有大语言模型生成的摘要在高风险领域（如法律、科学）中是否遗漏关键信息",
        "如何有效评估和分析大语言模型生成摘要时对结构化论证信息的覆盖情况"
      ]
    },
    "keywords": [
      "长文档摘要",
      "大语言模型",
      "指令跟随",
      "论证结构",
      "摘要生成",
      "结构化信息",
      "法律文本",
      "科学文献"
    ],
    "methods": [
      "Argument Representation Coverage (ARC) 框架",
      "基于结构化论证角色的摘要评估",
      "对比不同开源大语言模型的摘要表现",
      "分析上下文窗口位置偏置与角色偏好"
    ],
    "problems": [
      "大语言模型在零样本长文档摘要任务中能否充分保留和覆盖关键论证角色信息",
      "现有大语言模型生成的摘要在高风险领域（如法律、科学）中是否遗漏关键信息",
      "如何有效评估和分析大语言模型生成摘要时对结构化论证信息的覆盖情况"
    ]
  },
  "2505.23463": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注深度学习中的加权风险函数（如focal loss、inverse focal loss、AURC）与模型校准（calibration）之间的关系，提出了正则化AURC的可微分优化方法，并在多个数据集和模型上验证了其校准性能。虽然论文被归为cs.CV，但其核心贡献在于提出和分析新的损失函数及其对模型校准的影响，属于机器学习领域下的模型校准与选择性分类问题。标准领域词表中没有专门的'模型校准'或'选择性分类'，但这些内容与'小样本学习'下的泛化与不确定性建模密切相关，因此选择'小样本学习'作为最接近的三级领域。",
      "keywords": [
        "模型校准",
        "加权风险函数",
        "AURC",
        "focal loss",
        "inverse focal loss",
        "选择性分类",
        "SoftRank"
      ],
      "methods": [
        "正则化AURC优化",
        "SoftRank可微分排序",
        "加权风险最小化"
      ],
      "problems": [
        "不同加权风险函数对模型校准性能的影响",
        "如何通过优化AURC提升模型校准",
        "如何实现AURC的可微分优化以适应深度学习训练"
      ]
    },
    "keywords": [
      "模型校准",
      "加权风险函数",
      "AURC",
      "focal loss",
      "inverse focal loss",
      "选择性分类",
      "SoftRank"
    ],
    "methods": [
      "正则化AURC优化",
      "SoftRank可微分排序",
      "加权风险最小化"
    ],
    "problems": [
      "不同加权风险函数对模型校准性能的影响",
      "如何通过优化AURC提升模型校准",
      "如何实现AURC的可微分优化以适应深度学习训练"
    ]
  },
  "2505.23657": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注大语言模型（LLMs）在文本生成过程中的幻觉（hallucination）问题，提出了一种新的解码策略（Active Layer-Contrastive Decoding）以提升生成文本的事实性。虽然论文涉及强化学习和大语言模型，但其核心任务是改进自然语言生成的解码方法，属于自然语言处理领域下的生成模型方向。标准词表中没有更细的任务（如'文本生成'），因此选择'生成模型'作为第三级分类，第四级为null。",
      "keywords": [
        "大语言模型",
        "幻觉",
        "解码策略",
        "对比学习",
        "强化学习",
        "事实性",
        "文本生成"
      ],
      "methods": [
        "Active Layer-Contrastive Decoding (ActLCD)",
        "强化学习策略",
        "奖励感知分类器",
        "层级对比解码"
      ],
      "problems": [
        "如何减少大语言模型生成中的幻觉现象",
        "如何提升生成文本的事实性",
        "如何在生成过程中动态决定对比层的应用时机"
      ]
    },
    "keywords": [
      "大语言模型",
      "幻觉",
      "解码策略",
      "对比学习",
      "强化学习",
      "事实性",
      "文本生成"
    ],
    "methods": [
      "Active Layer-Contrastive Decoding (ActLCD)",
      "强化学习策略",
      "奖励感知分类器",
      "层级对比解码"
    ],
    "problems": [
      "如何减少大语言模型生成中的幻觉现象",
      "如何提升生成文本的事实性",
      "如何在生成过程中动态决定对比层的应用时机"
    ]
  },
  "2505.23469": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究点云的全局定向问题，属于三维场景的几何处理范畴。其核心任务是对大规模、非闭合（非watertight）的场景级点云进行全局法向定向，这直接服务于三维重建、分割和分析等下游任务。论文提出的Divide-and-Conquer Point Orientation (DACPO) 框架，属于三维重建领域中的点云处理与定向问题。虽然涉及优化方法，但其主要贡献和应用场景均属于三维重建，因此选择'计算机视觉 → 三维重建'作为分类路径，level3暂无更细分标准任务可选，设为null。",
      "keywords": [
        "点云定向",
        "三维重建",
        "非闭合场景",
        "分而治之",
        "0-1整数优化",
        "法向估计",
        "可见连通区域"
      ],
      "methods": [
        "分而治之策略",
        "随机贪心法向初始估计",
        "迭代式泊松表面重建",
        "基于可见连通区域的块间一致性建模",
        "0-1整数优化全局集成"
      ],
      "problems": [
        "如何对大规模、非闭合的场景级点云进行全局法向定向",
        "如何提升点云定向在非watertight场景下的鲁棒性和可扩展性",
        "如何高效整合局部块的定向结果以获得全局一致的点云定向"
      ]
    },
    "keywords": [
      "点云定向",
      "三维重建",
      "非闭合场景",
      "分而治之",
      "0-1整数优化",
      "法向估计",
      "可见连通区域"
    ],
    "methods": [
      "分而治之策略",
      "随机贪心法向初始估计",
      "迭代式泊松表面重建",
      "基于可见连通区域的块间一致性建模",
      "0-1整数优化全局集成"
    ],
    "problems": [
      "如何对大规模、非闭合的场景级点云进行全局法向定向",
      "如何提升点云定向在非watertight场景下的鲁棒性和可扩展性",
      "如何高效整合局部块的定向结果以获得全局一致的点云定向"
    ]
  },
  "2505.23662": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于评估大语言模型在长时对话中的工具使用能力，提出了ToolHaystack基准，主要关注模型在多轮、长时、带噪声的对话场景下的表现。虽然涉及大语言模型，但研究核心是对话系统中的工具增强与长期交互鲁棒性，因此选择'自然语言处理'为二级领域，'对话系统'为三级领域，四级领域暂无更细任务可选。",
      "keywords": [
        "大语言模型",
        "工具增强",
        "长时对话",
        "基准测试",
        "鲁棒性",
        "多轮交互"
      ],
      "methods": [
        "基准设计（ToolHaystack）",
        "多任务执行上下文",
        "噪声注入对话",
        "模型对比评测"
      ],
      "problems": [
        "现有工具增强大语言模型评测多局限于短上下文，无法反映真实长期交互表现",
        "如何系统性评估模型在长时、多任务、带噪声对话中的工具使用能力与鲁棒性"
      ]
    },
    "keywords": [
      "大语言模型",
      "工具增强",
      "长时对话",
      "基准测试",
      "鲁棒性",
      "多轮交互"
    ],
    "methods": [
      "基准设计（ToolHaystack）",
      "多任务执行上下文",
      "噪声注入对话",
      "模型对比评测"
    ],
    "problems": [
      "现有工具增强大语言模型评测多局限于短上下文，无法反映真实长期交互表现",
      "如何系统性评估模型在长时、多任务、带噪声对话中的工具使用能力与鲁棒性"
    ]
  },
  "2505.23475": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了一种自监督方法，通过从合成数据中学习关键点和描述符来加速和提升时间序列对齐的准确性。虽然论文借鉴了计算机视觉中的关键点检测思想，但其核心贡献在于时间序列数据的高效对齐与泛化能力，属于机器学习领域。论文强调模型在仅用合成数据训练时对真实数据的强泛化能力，属于小样本学习的典型应用场景。标准领域词表中没有更细致的时间序列分析或对齐任务，因此选择'小样本学习'作为最贴切的三级领域。",
      "keywords": [
        "时间序列对齐",
        "自监督学习",
        "关键点检测",
        "描述符学习",
        "动态时间规整（DTW）",
        "合成数据",
        "泛化能力"
      ],
      "methods": [
        "自监督关键点与描述符学习",
        "1D仿射变换生成合成训练数据",
        "全卷积与小波卷积网络架构",
        "稀疏表示下的DTW加速"
      ],
      "problems": [
        "如何在保证对齐精度的同时显著加速时间序列对齐过程",
        "如何利用自监督方法从合成数据中学习对齐所需的关键点和描述符",
        "如何提升模型在真实世界时间序列上的泛化能力"
      ]
    },
    "keywords": [
      "时间序列对齐",
      "自监督学习",
      "关键点检测",
      "描述符学习",
      "动态时间规整（DTW）",
      "合成数据",
      "泛化能力"
    ],
    "methods": [
      "自监督关键点与描述符学习",
      "1D仿射变换生成合成训练数据",
      "全卷积与小波卷积网络架构",
      "稀疏表示下的DTW加速"
    ],
    "problems": [
      "如何在保证对齐精度的同时显著加速时间序列对齐过程",
      "如何利用自监督方法从合成数据中学习对齐所需的关键点和描述符",
      "如何提升模型在真实世界时间序列上的泛化能力"
    ]
  },
  "2505.23666": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于提升Transformer类大语言模型在长文本推理和问答任务中的推理效率和准确性，提出了一种新的低秩线性注意力机制（LoLA），并在长文本needle-in-a-haystack问答任务和零样本常识推理任务上进行了实验。虽然涉及底层注意力机制优化，但其主要应用场景和实验均为自然语言处理中的问答系统，因此归入'自然语言处理 → 问答系统'最为合适。",
      "keywords": [
        "Transformer",
        "低秩线性注意力",
        "稀疏缓存",
        "长文本推理",
        "问答系统",
        "大语言模型",
        "滑动窗口注意力",
        "记忆冲突"
      ],
      "methods": [
        "低秩线性注意力机制（LoLA）",
        "稀疏缓存存储关键值对",
        "多级记忆分布（滑动窗口、本地缓存、递归隐藏状态）",
        "推理时仅用的高效注意力策略"
      ],
      "problems": [
        "如何在长文本推理任务中降低Transformer模型的推理复杂度",
        "如何提升线性注意力方法对softmax注意力的近似精度",
        "如何缓解长文本推理中的记忆冲突问题",
        "如何在有限硬件资源下提升大语言模型的长文本问答能力"
      ]
    },
    "keywords": [
      "Transformer",
      "低秩线性注意力",
      "稀疏缓存",
      "长文本推理",
      "问答系统",
      "大语言模型",
      "滑动窗口注意力",
      "记忆冲突"
    ],
    "methods": [
      "低秩线性注意力机制（LoLA）",
      "稀疏缓存存储关键值对",
      "多级记忆分布（滑动窗口、本地缓存、递归隐藏状态）",
      "推理时仅用的高效注意力策略"
    ],
    "problems": [
      "如何在长文本推理任务中降低Transformer模型的推理复杂度",
      "如何提升线性注意力方法对softmax注意力的近似精度",
      "如何缓解长文本推理中的记忆冲突问题",
      "如何在有限硬件资源下提升大语言模型的长文本问答能力"
    ]
  },
  "2505.23481": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了PhysicsNeRF，一种基于物理约束的稀疏视角三维重建方法，属于计算机视觉领域。其核心任务是从稀疏视角进行三维重建，直接对应标准领域词表中的'三维重建'。论文未聚焦于人体、医学等特定应用，因此选择通用的'三维重建'作为第三级分类，第四级无更细分任务，设为null。",
      "keywords": [
        "PhysicsNeRF",
        "三维重建",
        "稀疏视角",
        "Neural Radiance Fields",
        "物理约束",
        "深度排序",
        "一致性约束",
        "稀疏先验",
        "跨视角对齐"
      ],
      "methods": [
        "物理约束的NeRF扩展",
        "深度排序约束",
        "RegNeRF一致性",
        "稀疏先验",
        "跨视角对齐",
        "紧凑神经网络结构"
      ],
      "problems": [
        "如何在稀疏视角下实现高质量三维重建",
        "NeRF在稀疏监督下性能下降的根本原因",
        "提升三维重建模型的物理一致性与泛化能力"
      ]
    },
    "keywords": [
      "PhysicsNeRF",
      "三维重建",
      "稀疏视角",
      "Neural Radiance Fields",
      "物理约束",
      "深度排序",
      "一致性约束",
      "稀疏先验",
      "跨视角对齐"
    ],
    "methods": [
      "物理约束的NeRF扩展",
      "深度排序约束",
      "RegNeRF一致性",
      "稀疏先验",
      "跨视角对齐",
      "紧凑神经网络结构"
    ],
    "problems": [
      "如何在稀疏视角下实现高质量三维重建",
      "NeRF在稀疏监督下性能下降的根本原因",
      "提升三维重建模型的物理一致性与泛化能力"
    ]
  },
  "2505.23688": {
    "classification_path": "计算机科学 → 语音与音频处理 → 语音识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "语音与音频处理",
      "level2": "语音识别",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究自动化语音数据注释，具体为利用wav2vec2.0模型对语音中的塞音爆破实现进行自动分类。虽然涉及到语音中的细粒度音系现象，但核心任务属于语音信号的自动分析与识别，最接近标准领域词表中的'语音识别'。论文未涉及更细的标准任务如小样本学习或三维重建，因此level3设为null。",
      "keywords": [
        "自动语音注释",
        "wav2vec2.0",
        "塞音爆破",
        "语音分类",
        "自监督学习",
        "语音识别",
        "语音变异",
        "语音语料库"
      ],
      "methods": [
        "预训练自监督模型（wav2vec2.0）",
        "自动分类",
        "语音数据注释",
        "跨语言实验（英语和日语）"
      ],
      "problems": [
        "如何利用自监督预训练模型自动识别和分类语音中的塞音爆破现象",
        "自动注释工具在多变语音现象上的适用性与准确性",
        "提升语音语料库注释的效率和规模"
      ]
    },
    "keywords": [
      "自动语音注释",
      "wav2vec2.0",
      "塞音爆破",
      "语音分类",
      "自监督学习",
      "语音识别",
      "语音变异",
      "语音语料库"
    ],
    "methods": [
      "预训练自监督模型（wav2vec2.0）",
      "自动分类",
      "语音数据注释",
      "跨语言实验（英语和日语）"
    ],
    "problems": [
      "如何利用自监督预训练模型自动识别和分类语音中的塞音爆破现象",
      "自动注释工具在多变语音现象上的适用性与准确性",
      "提升语音语料库注释的效率和规模"
    ]
  },
  "2505.23484": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解 → 视频描述",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": "视频描述",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于视频字幕（caption）的质量评估，属于视频内容的理解与描述任务。虽然涉及多模态和大语言模型，但核心贡献是为视频描述（Video Captioning）任务提供细粒度评测基准和自动化评测方法，因此最合适的分类路径为‘计算机科学 → 计算机视觉 → 视频理解 → 视频描述’。",
      "keywords": [
        "视频字幕",
        "视频描述",
        "质量评估",
        "基准数据集",
        "细粒度评测",
        "大语言模型",
        "自动化评测"
      ],
      "methods": [
        "细粒度多维度标注",
        "基于问答对的评测",
        "自动化评测流程",
        "对比式问答分析",
        "大语言模型辅助评测",
        "新评测指标（AR, IR, CR）"
      ],
      "problems": [
        "现有视频字幕评测基准无法细致捕捉影响视频生成的空间-时间细节",
        "缺乏大规模、细粒度的视频字幕质量评测数据集",
        "如何自动化、系统性地评估视频字幕的多维度质量"
      ]
    },
    "keywords": [
      "视频字幕",
      "视频描述",
      "质量评估",
      "基准数据集",
      "细粒度评测",
      "大语言模型",
      "自动化评测"
    ],
    "methods": [
      "细粒度多维度标注",
      "基于问答对的评测",
      "自动化评测流程",
      "对比式问答分析",
      "大语言模型辅助评测",
      "新评测指标（AR, IR, CR）"
    ],
    "problems": [
      "现有视频字幕评测基准无法细致捕捉影响视频生成的空间-时间细节",
      "缺乏大规模、细粒度的视频字幕质量评测数据集",
      "如何自动化、系统性地评估视频字幕的多维度质量"
    ]
  },
  "2505.23689": {
    "classification_path": "计算机科学 → 自然语言处理 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究语言模型（LMs）在不同语料（儿童导向语言与维基百科）上的语法学习能力，涉及多语言、不同训练目标（masked和causal），以及对语法泛化能力的评估。论文聚焦于语言模型的训练数据选择及其对语法学习的影响，属于自然语言处理领域。由于论文核心是对语言模型（属于生成模型范畴）在语法学习任务上的表现分析，最合适的三级分类为'生成模型'。四级分类未涉及具体下游任务（如问答、对话等），因此level3为null。",
      "keywords": [
        "语言模型",
        "儿童导向语言",
        "语法学习",
        "多语言",
        "训练语料",
        "频率控制",
        "最小对测试",
        "FIT-CLAMS"
      ],
      "methods": [
        "对比实验（CDL与Wikipedia语料）",
        "多语言训练（英语、法语、德语）",
        "两种语言模型目标（masked, causal）",
        "最小对语法基准测试",
        "频率控制测试方法（FIT-CLAMS）",
        "回归分析"
      ],
      "problems": [
        "儿童导向语言是否能提升语言模型的语法学习能力",
        "不同语料、模型类型和评测设置下儿童导向语言的泛化能力",
        "现有语法评测基准的局限性及频率效应的影响"
      ]
    },
    "keywords": [
      "语言模型",
      "儿童导向语言",
      "语法学习",
      "多语言",
      "训练语料",
      "频率控制",
      "最小对测试",
      "FIT-CLAMS"
    ],
    "methods": [
      "对比实验（CDL与Wikipedia语料）",
      "多语言训练（英语、法语、德语）",
      "两种语言模型目标（masked, causal）",
      "最小对语法基准测试",
      "频率控制测试方法（FIT-CLAMS）",
      "回归分析"
    ],
    "problems": [
      "儿童导向语言是否能提升语言模型的语法学习能力",
      "不同语料、模型类型和评测设置下儿童导向语言的泛化能力",
      "现有语法评测基准的局限性及频率效应的影响"
    ]
  },
  "2505.23493": {
    "classification_path": "计算机科学 → 多模态学习 → 生成模型 → 文本到图像生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "生成模型",
      "level3": "文本到图像生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于文本到图像生成（Text-to-Image Generation）任务，核心贡献是提出了一个针对推理能力的基准（R2I-Bench）和评测指标（R2IScore），用于评估现有生成模型在多种推理场景下的表现。论文涉及文本与图像的跨模态理解与生成，属于多模态学习范畴；具体任务为生成模型下的文本到图像生成，因此选择‘多模态学习 → 生成模型 → 文本到图像生成’作为最合适的分层分类路径。",
      "keywords": [
        "文本到图像生成",
        "推理能力",
        "多模态学习",
        "基准评测",
        "R2I-Bench",
        "R2IScore",
        "生成模型"
      ],
      "methods": [
        "基准数据集构建",
        "推理类别覆盖（常识、数学、逻辑、组合、数值、因果、概念混合）",
        "QA式评测指标设计",
        "模型性能对比实验",
        "推理与生成解耦的流水线框架"
      ],
      "problems": [
        "现有文本到图像生成模型推理能力不足且缺乏系统性评测",
        "如何系统性评估和量化T2I模型在多种推理场景下的表现",
        "推动更具推理能力的文本到图像生成模型的研究"
      ]
    },
    "keywords": [
      "文本到图像生成",
      "推理能力",
      "多模态学习",
      "基准评测",
      "R2I-Bench",
      "R2IScore",
      "生成模型"
    ],
    "methods": [
      "基准数据集构建",
      "推理类别覆盖（常识、数学、逻辑、组合、数值、因果、概念混合）",
      "QA式评测指标设计",
      "模型性能对比实验",
      "推理与生成解耦的流水线框架"
    ],
    "problems": [
      "现有文本到图像生成模型推理能力不足且缺乏系统性评测",
      "如何系统性评估和量化T2I模型在多种推理场景下的表现",
      "推动更具推理能力的文本到图像生成模型的研究"
    ]
  },
  "2505.23701": {
    "classification_path": "计算机科学 → 大语言模型 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（如Llama-3和Qwen2.5）在数学文字题上的推理能力评估，特别是区分抽象表述与算术计算两个子技能。该研究属于大语言模型在问答系统中的能力分析与评测，因此选择'大语言模型'为二级领域，'问答系统'为三级领域。论文未涉及更细致的具体任务或应用，四级领域设为null。",
      "keywords": [
        "大语言模型",
        "数学文字题",
        "抽象表述",
        "算术计算",
        "推理能力",
        "链式思维(CoT)",
        "评测方法",
        "GSM8K",
        "SVAMP"
      ],
      "methods": [
        "分离式评测",
        "因果修补(causal patching)",
        "行为分析",
        "机制分析"
      ],
      "problems": [
        "大语言模型在数学文字题推理中，抽象表述与算术计算能力如何区分？",
        "链式思维(CoT)对抽象表述与算术计算的影响分别如何？",
        "现有评测方法是否准确反映了大语言模型的推理能力？"
      ]
    },
    "keywords": [
      "大语言模型",
      "数学文字题",
      "抽象表述",
      "算术计算",
      "推理能力",
      "链式思维(CoT)",
      "评测方法",
      "GSM8K",
      "SVAMP"
    ],
    "methods": [
      "分离式评测",
      "因果修补(causal patching)",
      "行为分析",
      "机制分析"
    ],
    "problems": [
      "大语言模型在数学文字题推理中，抽象表述与算术计算能力如何区分？",
      "链式思维(CoT)对抽象表述与算术计算的影响分别如何？",
      "现有评测方法是否准确反映了大语言模型的推理能力？"
    ]
  },
  "2505.23503": {
    "classification_path": "计算机科学 → 医学图像 → 医学图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "医学图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注医学诊断图像的分类与分析，比较了CNN与大语言模型（LLM）在医学图像分析中的表现。虽然涉及多模态和大语言模型，但核心任务是医学图像的自动诊断与分类，最贴切的标准领域为'医学图像'。在三级领域中，'医学图像分割'最接近医学图像分析的具体任务，虽然论文更偏向分类，但标准词表中没有更合适的分类，因此选择'医学图像分割'作为最接近的三级领域，四级领域暂无更细分任务，设为null。",
      "keywords": [
        "医学图像分析",
        "多模态AI",
        "卷积神经网络",
        "大语言模型",
        "模型比较",
        "诊断性能",
        "能耗",
        "CO2排放"
      ],
      "methods": [
        "多模态AI框架",
        "卷积神经网络（CNN）",
        "大语言模型（LLM）",
        "性能评估（准确率、F1分数、执行时间、能耗、CO2排放）",
        "后处理过滤"
      ],
      "problems": [
        "CNN与大语言模型在医学图像诊断中的性能差异",
        "多模态AI系统在医学诊断中的可靠性与效率提升",
        "医学图像分析模型的能耗与环境影响"
      ]
    },
    "keywords": [
      "医学图像分析",
      "多模态AI",
      "卷积神经网络",
      "大语言模型",
      "模型比较",
      "诊断性能",
      "能耗",
      "CO2排放"
    ],
    "methods": [
      "多模态AI框架",
      "卷积神经网络（CNN）",
      "大语言模型（LLM）",
      "性能评估（准确率、F1分数、执行时间、能耗、CO2排放）",
      "后处理过滤"
    ],
    "problems": [
      "CNN与大语言模型在医学图像诊断中的性能差异",
      "多模态AI系统在医学诊断中的可靠性与效率提升",
      "医学图像分析模型的能耗与环境影响"
    ]
  },
  "2505.23713": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于大语言模型在社会推理任务中的能力评估，提出了一个新的基准SocialMaze，涵盖了社交推理游戏、日常互动和数字社区等多种场景。论文核心在于评测和分析大语言模型在复杂社会语境下的推理与问答能力，属于自然语言处理领域。具体任务为对模型社会推理能力的系统性问答评测，最贴近标准词表中的‘问答系统’。虽然涉及大语言模型，但‘大语言模型’在标准词表中为二级领域，且论文重心为评测与任务设计，因此归入‘自然语言处理’下的‘问答系统’最为合适。",
      "keywords": [
        "社会推理",
        "大语言模型",
        "基准评测",
        "动态交互",
        "信息不确定性",
        "链式思考",
        "社会语境"
      ],
      "methods": [
        "基准数据集设计",
        "多场景任务构建",
        "自动与人工验证",
        "链式思考推理分析",
        "针对性微调"
      ],
      "problems": [
        "如何系统性评估大语言模型的社会推理能力",
        "现有评测任务过于简单，无法反映真实社交场景下的推理需求",
        "模型在动态交互和信息不确定性下推理能力的不足",
        "如何通过数据集和任务设计推动模型在复杂社会语境下的推理能力提升"
      ]
    },
    "keywords": [
      "社会推理",
      "大语言模型",
      "基准评测",
      "动态交互",
      "信息不确定性",
      "链式思考",
      "社会语境"
    ],
    "methods": [
      "基准数据集设计",
      "多场景任务构建",
      "自动与人工验证",
      "链式思考推理分析",
      "针对性微调"
    ],
    "problems": [
      "如何系统性评估大语言模型的社会推理能力",
      "现有评测任务过于简单，无法反映真实社交场景下的推理需求",
      "模型在动态交互和信息不确定性下推理能力的不足",
      "如何通过数据集和任务设计推动模型在复杂社会语境下的推理能力提升"
    ]
  },
  "2505.23504": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解 → 异常事件检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": "异常事件检测",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于视频异常理解（Video Anomaly Understanding），属于计算机视觉领域下的视频理解方向。论文提出了基于多模态大语言模型和强化微调的视频异常推理方法，并构建了专门用于异常推理的基准（VAU-Bench），核心任务是提升视频中异常事件的检测与推理能力。因此，最合适的四级分类为‘异常事件检测’。",
      "keywords": [
        "视频异常理解",
        "异常事件检测",
        "多模态大语言模型",
        "强化微调",
        "因果推理",
        "时空感知",
        "链式思考",
        "基准测试"
      ],
      "methods": [
        "多模态大语言模型（MLLM）",
        "强化微调（Reinforcement Fine-Tuning, RFT）",
        "链式思考（Chain-of-Thought）推理",
        "基准构建（VAU-Bench）"
      ],
      "problems": [
        "现有视频异常检测方法缺乏可解释性和因果、上下文推理能力",
        "缺乏用于评估异常推理能力的综合性基准",
        "如何提升视频异常事件的推理、定位和问答准确性"
      ]
    },
    "keywords": [
      "视频异常理解",
      "异常事件检测",
      "多模态大语言模型",
      "强化微调",
      "因果推理",
      "时空感知",
      "链式思考",
      "基准测试"
    ],
    "methods": [
      "多模态大语言模型（MLLM）",
      "强化微调（Reinforcement Fine-Tuning, RFT）",
      "链式思考（Chain-of-Thought）推理",
      "基准构建（VAU-Bench）"
    ],
    "problems": [
      "现有视频异常检测方法缺乏可解释性和因果、上下文推理能力",
      "缺乏用于评估异常推理能力的综合性基准",
      "如何提升视频异常事件的推理、定位和问答准确性"
    ]
  },
  "2505.23714": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于低资源语言的语义消歧任务，核心贡献是构建和标注多语言的多义词语境数据集，并通过Word-in-Context (WiC) 格式进行实验。WiC任务本质上属于自然语言处理领域下的问答系统（判断同一词在不同语境下是否语义一致），而不是生成模型、对话系统等其他细分方向。因此选择'自然语言处理→问答系统'作为最合适的分类路径。",
      "keywords": [
        "低资源语言",
        "语义消歧",
        "多义词",
        "数据集构建",
        "跨语言迁移",
        "Word-in-Context",
        "半自动标注"
      ],
      "methods": [
        "半自动标注方法",
        "多语言数据集构建",
        "WiC格式实验"
      ],
      "problems": [
        "如何为低资源语言构建高质量的语义消歧评测数据集",
        "如何提升跨语言迁移在低资源语言上的有效性",
        "如何通过半自动方法高效标注多义词语境数据"
      ]
    },
    "keywords": [
      "低资源语言",
      "语义消歧",
      "多义词",
      "数据集构建",
      "跨语言迁移",
      "Word-in-Context",
      "半自动标注"
    ],
    "methods": [
      "半自动标注方法",
      "多语言数据集构建",
      "WiC格式实验"
    ],
    "problems": [
      "如何为低资源语言构建高质量的语义消歧评测数据集",
      "如何提升跨语言迁移在低资源语言上的有效性",
      "如何通过半自动方法高效标注多义词语境数据"
    ]
  },
  "2505.23522": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了一个面向地球科学六大圈层及其交互的多模态基准（OmniEarth-Bench），涵盖了多种模态（卫星遥感、原位观测等）和多层次推理任务（感知、一般推理、科学知识推理、链式推理），并对多模态大模型（MLLMs）进行系统评测。论文核心在于多模态数据的理解与推理，且主要任务为基于多模态数据的问答与推理评测，因此选择'多模态学习'为二级领域，'问答系统'为三级领域。论文未聚焦于具体视觉任务（如目标检测、分割等），也非单一自然语言处理或机器学习范畴，最合适的细分为多模态问答系统。",
      "keywords": [
        "多模态学习",
        "地球科学",
        "基准数据集",
        "六大圈层",
        "跨圈层交互",
        "问答系统",
        "推理",
        "卫星遥感",
        "环境监测"
      ],
      "methods": [
        "多模态基准构建",
        "专家与众包标注",
        "多层次推理任务设计",
        "多模态大模型评测",
        "混合专家-众包验证流程"
      ],
      "problems": [
        "现有地球科学多模态学习基准覆盖不全、交互性不足",
        "缺乏系统性评测地球六大圈层及其交互的多模态基准",
        "多模态大模型在复杂地球科学推理任务中的能力有限",
        "如何权威、系统地评估多模态模型在地球科学领域的表现"
      ]
    },
    "keywords": [
      "多模态学习",
      "地球科学",
      "基准数据集",
      "六大圈层",
      "跨圈层交互",
      "问答系统",
      "推理",
      "卫星遥感",
      "环境监测"
    ],
    "methods": [
      "多模态基准构建",
      "专家与众包标注",
      "多层次推理任务设计",
      "多模态大模型评测",
      "混合专家-众包验证流程"
    ],
    "problems": [
      "现有地球科学多模态学习基准覆盖不全、交互性不足",
      "缺乏系统性评测地球六大圈层及其交互的多模态基准",
      "多模态大模型在复杂地球科学推理任务中的能力有限",
      "如何权威、系统地评估多模态模型在地球科学领域的表现"
    ]
  },
  "2505.23715": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于大语言模型在面对有缺陷前提时的批判能力评估，属于自然语言理解范畴。论文设计了针对前提批判能力的评测基准，并系统评估了多种大语言模型在问答场景下对前提错误的识别与批判能力。虽然涉及大语言模型，但主要研究内容是其在问答任务中的表现与评测，因此选择'自然语言处理'为二级领域，'问答系统'为三级领域，四级领域暂无更细分标准任务，设为null。",
      "keywords": [
        "大语言模型",
        "前提批判能力",
        "问答系统",
        "错误检测",
        "评测基准"
      ],
      "methods": [
        "Premise Critique Bench (PCBench)基准设计",
        "多类型错误与多难度分级",
        "多维度评测指标",
        "系统性模型评估"
      ],
      "problems": [
        "大语言模型在面对有缺陷或矛盾前提时缺乏主动批判能力",
        "现有评测忽视了模型对错误前提的识别与批判",
        "前提批判能力与推理能力之间的关系不明确",
        "不同类型错误和问题难度对模型批判能力的影响"
      ]
    },
    "keywords": [
      "大语言模型",
      "前提批判能力",
      "问答系统",
      "错误检测",
      "评测基准"
    ],
    "methods": [
      "Premise Critique Bench (PCBench)基准设计",
      "多类型错误与多难度分级",
      "多维度评测指标",
      "系统性模型评估"
    ],
    "problems": [
      "大语言模型在面对有缺陷或矛盾前提时缺乏主动批判能力",
      "现有评测忽视了模型对错误前提的识别与批判",
      "前提批判能力与推理能力之间的关系不明确",
      "不同类型错误和问题难度对模型批判能力的影响"
    ]
  },
  "2505.23524": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解 → 时序动作定位",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": "时序动作定位",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要研究无监督的时序动作定位（UTAL），属于视频理解领域中的具体任务。虽然方法涉及多模态（视觉+音频）和CLIP等跨模态技术，但核心任务是视频中的动作定位，因此选择'计算机视觉 → 视频理解 → 时序动作定位'作为最合适的分层分类路径。",
      "keywords": [
        "无监督时序动作定位",
        "多模态学习",
        "音视频增强",
        "CLIP",
        "视觉语言预训练",
        "自监督学习"
      ],
      "methods": [
        "CLIP辅助的跨视角音视频增强",
        "视觉语言预训练与分类预训练协同增强",
        "音频感知边界信息融合",
        "自监督跨视角学习范式"
      ],
      "problems": [
        "现有方法过度依赖有标签的时序边界和动作类别，标注成本高",
        "分类预训练特征过于关注高判别性区域，忽略上下文",
        "仅依赖视觉模态难以准确确定动作边界"
      ]
    },
    "keywords": [
      "无监督时序动作定位",
      "多模态学习",
      "音视频增强",
      "CLIP",
      "视觉语言预训练",
      "自监督学习"
    ],
    "methods": [
      "CLIP辅助的跨视角音视频增强",
      "视觉语言预训练与分类预训练协同增强",
      "音频感知边界信息融合",
      "自监督跨视角学习范式"
    ],
    "problems": [
      "现有方法过度依赖有标签的时序边界和动作类别，标注成本高",
      "分类预训练特征过于关注高判别性区域，忽略上下文",
      "仅依赖视觉模态难以准确确定动作边界"
    ]
  },
  "2505.23722": {
    "classification_path": "计算机科学 → 自然语言处理 → 小样本学习 → 命名实体识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "小样本学习",
      "level3": "命名实体识别",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于命名实体识别（NER）任务，提出了一种基于标签引导的in-context learning方法（DEER），旨在提升大语言模型在小样本场景下的NER性能。论文核心创新点在于结合标签统计信息进行示例选择和纠错，属于自然语言处理领域下的小样本学习范畴，具体任务为命名实体识别。",
      "keywords": [
        "命名实体识别",
        "in-context learning",
        "大语言模型",
        "小样本学习",
        "标签引导",
        "示例选择",
        "纠错"
      ],
      "methods": [
        "标签引导的token级示例检索",
        "基于标签统计的错误纠正",
        "DEER方法"
      ],
      "problems": [
        "如何提升大语言模型在小样本命名实体识别任务中的表现",
        "如何利用标签信息优化in-context learning的示例选择",
        "如何针对易错token进行有效纠错"
      ]
    },
    "keywords": [
      "命名实体识别",
      "in-context learning",
      "大语言模型",
      "小样本学习",
      "标签引导",
      "示例选择",
      "纠错"
    ],
    "methods": [
      "标签引导的token级示例检索",
      "基于标签统计的错误纠正",
      "DEER方法"
    ],
    "problems": [
      "如何提升大语言模型在小样本命名实体识别任务中的表现",
      "如何利用标签信息优化in-context learning的示例选择",
      "如何针对易错token进行有效纠错"
    ]
  },
  "2505.23525": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于高保真动态人像动画的生成，核心方法为基于扩散模型的生成框架，并提出了直接偏好优化和时序运动调制两项创新。论文属于计算机视觉领域，具体聚焦于生成模型，且方法基于扩散模型，因此选择'计算机视觉 → 生成模型 → 扩散模型'作为最合适的分层分类路径。",
      "keywords": [
        "高保真动态人像动画",
        "扩散模型",
        "直接偏好优化",
        "时序运动调制",
        "人类偏好对齐",
        "唇音同步",
        "表情自然度",
        "身体动作一致性"
      ],
      "methods": [
        "基于人类偏好的直接偏好优化",
        "时序运动调制（Temporal Motion Modulation）",
        "扩散模型生成框架",
        "UNet与DiT结构兼容"
      ],
      "problems": [
        "如何生成高动态、写实的人像动画",
        "如何实现精确的唇音同步与自然表情",
        "如何提升身体动作的高保真度与时序一致性",
        "如何通过人类偏好优化提升生成动画的感知质量"
      ]
    },
    "keywords": [
      "高保真动态人像动画",
      "扩散模型",
      "直接偏好优化",
      "时序运动调制",
      "人类偏好对齐",
      "唇音同步",
      "表情自然度",
      "身体动作一致性"
    ],
    "methods": [
      "基于人类偏好的直接偏好优化",
      "时序运动调制（Temporal Motion Modulation）",
      "扩散模型生成框架",
      "UNet与DiT结构兼容"
    ],
    "problems": [
      "如何生成高动态、写实的人像动画",
      "如何实现精确的唇音同步与自然表情",
      "如何提升身体动作的高保真度与时序一致性",
      "如何通过人类偏好优化提升生成动画的感知质量"
    ]
  },
  "2505.23723": {
    "classification_path": "计算机科学 → 强化学习 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "强化学习",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究基于大语言模型（LLM）的智能体在自动化机器学习任务中的自主学习与优化，核心方法为在线强化学习，且提出了探索性微调、逐步强化学习和奖励模块等创新。虽然涉及大语言模型，但论文的创新点和主要技术路线是将强化学习与生成模型（LLM）结合，提升智能体在机器学习工程任务中的自主能力，因此归入‘强化学习→生成模型’最为贴切。",
      "keywords": [
        "大语言模型",
        "强化学习",
        "智能体",
        "自动化机器学习",
        "探索性微调",
        "奖励模块",
        "跨任务泛化"
      ],
      "methods": [
        "探索性微调",
        "逐步强化学习",
        "奖励统一模块",
        "基于Qwen-2.5 LLM的智能体训练"
      ],
      "problems": [
        "现有LLM智能体依赖人工提示工程，缺乏基于实验经验的自适应优化能力",
        "如何让LLM智能体通过交互式实验和在线强化学习自主提升机器学习工程能力",
        "如何统一多样化的机器学习反馈信号以优化强化学习过程"
      ]
    },
    "keywords": [
      "大语言模型",
      "强化学习",
      "智能体",
      "自动化机器学习",
      "探索性微调",
      "奖励模块",
      "跨任务泛化"
    ],
    "methods": [
      "探索性微调",
      "逐步强化学习",
      "奖励统一模块",
      "基于Qwen-2.5 LLM的智能体训练"
    ],
    "problems": [
      "现有LLM智能体依赖人工提示工程，缺乏基于实验经验的自适应优化能力",
      "如何让LLM智能体通过交互式实验和在线强化学习自主提升机器学习工程能力",
      "如何统一多样化的机器学习反馈信号以优化强化学习过程"
    ]
  },
  "2505.23543": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要聚焦于通过神经网络（如YOLOv1、Detectron2）和知识图谱结合的方法，对文化遗产数字化图像中的结构化特征进行自动检测和元数据丰富。其核心创新是多层视觉机制（MVM），用于嵌套特征（如印章内文字、图章内图像）的动态检测，属于典型的目标检测任务。虽然涉及知识图谱和语义互操作，但主要贡献和方法集中在视觉特征的自动检测与元数据提取，因此选择‘计算机视觉 → 目标检测’作为最合适的分类路径。",
      "keywords": [
        "元数据丰富",
        "神经网络",
        "知识图谱",
        "文化遗产",
        "目标检测",
        "多层视觉机制",
        "语义互操作"
      ],
      "methods": [
        "多层视觉机制（MVM）",
        "神经网络模型（YOLOv1, Detectron2）",
        "大语言模型（LLMs）",
        "知识图谱集成",
        "手工标注数据集"
      ],
      "problems": [
        "如何自动化提取和丰富文化遗产数字化图像的结构化元数据",
        "如何实现神经网络与语义知识图谱的有效集成以提升元数据互操作性",
        "如何解决领域特定的特征检测与语义标准对接的实际挑战"
      ]
    },
    "keywords": [
      "元数据丰富",
      "神经网络",
      "知识图谱",
      "文化遗产",
      "目标检测",
      "多层视觉机制",
      "语义互操作"
    ],
    "methods": [
      "多层视觉机制（MVM）",
      "神经网络模型（YOLOv1, Detectron2）",
      "大语言模型（LLMs）",
      "知识图谱集成",
      "手工标注数据集"
    ],
    "problems": [
      "如何自动化提取和丰富文化遗产数字化图像的结构化元数据",
      "如何实现神经网络与语义知识图谱的有效集成以提升元数据互操作性",
      "如何解决领域特定的特征检测与语义标准对接的实际挑战"
    ]
  },
  "2505.23729": {
    "classification_path": "计算机科学 → 大语言模型 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）的推理时对齐问题，提出了SITAlign方法以实现多目标约束下的满意对齐。虽然涉及多目标优化和人类决策建模，但核心贡献在于大语言模型推理阶段的生成控制，因此选择'大语言模型'为二级领域，'生成模型'为三级领域。四级领域暂无更细致标准任务可选，故为null。",
      "keywords": [
        "大语言模型",
        "对齐",
        "满意化",
        "多目标优化",
        "推理控制",
        "SITAlign"
      ],
      "methods": [
        "SITAlign推理框架",
        "满意化对齐策略",
        "阈值约束多目标优化",
        "理论子最优性界分析",
        "多基准实验验证"
      ],
      "problems": [
        "如何在大语言模型推理阶段实现多目标下的满意化对齐",
        "如何将人类决策中的满意化策略应用于大语言模型的对齐问题",
        "如何在保证主目标最优的同时满足次要目标的阈值约束"
      ]
    },
    "keywords": [
      "大语言模型",
      "对齐",
      "满意化",
      "多目标优化",
      "推理控制",
      "SITAlign"
    ],
    "methods": [
      "SITAlign推理框架",
      "满意化对齐策略",
      "阈值约束多目标优化",
      "理论子最优性界分析",
      "多基准实验验证"
    ],
    "problems": [
      "如何在大语言模型推理阶段实现多目标下的满意化对齐",
      "如何将人类决策中的满意化策略应用于大语言模型的对齐问题",
      "如何在保证主目标最优的同时满足次要目标的阈值约束"
    ]
  },
  "2505.23558": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 视觉问答",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "视觉问答",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于视觉-语言推理模型（VLRMs），提出了Qwen-LookAgain方法以提升视觉信息在推理过程中的关注度，并减少幻觉现象。论文的主要任务是多模态（视觉+语言）下的问答系统，尤其关注视觉问答（Visual Question Answering, VQA）任务。虽然涉及强化学习方法（BRPO），但核心贡献和实验均围绕多模态视觉问答展开，因此选择'多模态学习→问答系统→视觉问答'作为最合适的分层分类路径。",
      "keywords": [
        "视觉-语言推理模型",
        "视觉问答",
        "幻觉抑制",
        "反思机制",
        "视觉注意力",
        "多模态学习"
      ],
      "methods": [
        "Qwen-LookAgain模型",
        "Balanced Reflective Policy Optimization (BRPO)",
        "视觉-文本反思机制",
        "Visual Token COPY",
        "Visual Token ROUTE"
      ],
      "problems": [
        "视觉-语言推理模型在长推理过程中视觉信息关注度下降，导致幻觉现象",
        "文本反思机制不足以抑制多模态模型中的幻觉",
        "如何在推理过程中有效引导模型重新关注视觉信息以提升问答准确性"
      ]
    },
    "keywords": [
      "视觉-语言推理模型",
      "视觉问答",
      "幻觉抑制",
      "反思机制",
      "视觉注意力",
      "多模态学习"
    ],
    "methods": [
      "Qwen-LookAgain模型",
      "Balanced Reflective Policy Optimization (BRPO)",
      "视觉-文本反思机制",
      "Visual Token COPY",
      "Visual Token ROUTE"
    ],
    "problems": [
      "视觉-语言推理模型在长推理过程中视觉信息关注度下降，导致幻觉现象",
      "文本反思机制不足以抑制多模态模型中的幻觉",
      "如何在推理过程中有效引导模型重新关注视觉信息以提升问答准确性"
    ]
  },
  "2505.23735": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注于提升序列建模和长上下文理解能力，提出了新的长时记忆模块ATLAS，并在语言建模、常识推理、长上下文理解等任务上进行了实验。虽然涉及模型结构创新，但核心任务是提升自然语言处理中的长文本理解与记忆能力，最贴近的标准领域为‘自然语言处理’。在三级领域中，‘问答系统’最贴合长上下文理解与信息检索相关任务，且论文实验涵盖了常识推理和回忆密集型任务，因此选择‘问答系统’。四级领域暂无更细分标准，设为null。",
      "keywords": [
        "长上下文理解",
        "序列建模",
        "长时记忆模块",
        "ATLAS",
        "Transformer",
        "DeepTransformers",
        "语言建模",
        "常识推理"
      ],
      "methods": [
        "长时记忆模块设计（ATLAS）",
        "基于当前与历史输入的记忆优化",
        "Transformer结构泛化（DeepTransformers）",
        "与现有Transformer和线性循环模型的对比实验"
      ],
      "problems": [
        "如何提升模型对长序列的上下文记忆与理解能力",
        "如何突破现有Transformer和循环神经网络在长序列建模中的内存与表达瓶颈",
        "如何优化长时记忆模块以支持更高效的上下文检索与推理"
      ]
    },
    "keywords": [
      "长上下文理解",
      "序列建模",
      "长时记忆模块",
      "ATLAS",
      "Transformer",
      "DeepTransformers",
      "语言建模",
      "常识推理"
    ],
    "methods": [
      "长时记忆模块设计（ATLAS）",
      "基于当前与历史输入的记忆优化",
      "Transformer结构泛化（DeepTransformers）",
      "与现有Transformer和线性循环模型的对比实验"
    ],
    "problems": [
      "如何提升模型对长序列的上下文记忆与理解能力",
      "如何突破现有Transformer和循环神经网络在长序列建模中的内存与表达瓶颈",
      "如何优化长时记忆模块以支持更高效的上下文检索与推理"
    ]
  },
  "2505.23566": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 光学字符识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "光学字符识别",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于手写数学表达式识别（HMER），属于光学字符识别（OCR）任务的一个细分方向。虽然方法涉及视觉-语言模型和多任务学习，但核心任务是对图像中的手写数学符号进行结构化识别，最贴近'计算机视觉 → 目标检测 → 光学字符识别'这一分层路径。标准词表中未直接包含'HMER'，但OCR是其最合适的具体任务归属。",
      "keywords": [
        "手写数学表达式识别",
        "光学字符识别",
        "视觉-语言模型",
        "多任务学习",
        "结构化推理"
      ],
      "methods": [
        "视觉-语言模型微调",
        "Tree-Aware Chain-of-Thought (Tree-CoT)",
        "Error-Driven Learning (EDL)",
        "Symbol Counting (SC)"
      ],
      "problems": [
        "手写数学表达式中符号布局自由和书写风格多样导致的识别难题",
        "现有方法难以统一集成多种改进策略",
        "提升视觉-语言模型在HMER任务上的泛化能力和准确率"
      ]
    },
    "keywords": [
      "手写数学表达式识别",
      "光学字符识别",
      "视觉-语言模型",
      "多任务学习",
      "结构化推理"
    ],
    "methods": [
      "视觉-语言模型微调",
      "Tree-Aware Chain-of-Thought (Tree-CoT)",
      "Error-Driven Learning (EDL)",
      "Symbol Counting (SC)"
    ],
    "problems": [
      "手写数学表达式中符号布局自由和书写风格多样导致的识别难题",
      "现有方法难以统一集成多种改进策略",
      "提升视觉-语言模型在HMER任务上的泛化能力和准确率"
    ]
  },
  "2505.23754": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统 → null",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": "null",
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注利用大语言模型（LLM）进行非正式数学定理证明，核心在于自然语言推理与理解，并通过强化学习提升推理能力。虽然涉及强化学习和大语言模型，但其主要任务是自然语言下的数学问答与推理，最贴近标准词表中的‘自然语言处理→问答系统’。论文并未聚焦于代码生成、对话系统等其他细分任务，因此选择该分类路径。",
      "keywords": [
        "大语言模型",
        "定理证明",
        "自然语言推理",
        "强化学习",
        "数学推理",
        "数据集",
        "评测指标"
      ],
      "methods": [
        "自然语言定理证明框架",
        "RL-Zero强化学习策略",
        "大规模数据集构建",
        "过程与结果评测指标"
      ],
      "problems": [
        "如何提升大语言模型在非正式数学定理证明中的推理能力",
        "如何利用自然语言和强化学习促进自动定理证明",
        "如何系统评估LLM在数学推理任务中的表现"
      ]
    },
    "keywords": [
      "大语言模型",
      "定理证明",
      "自然语言推理",
      "强化学习",
      "数学推理",
      "数据集",
      "评测指标"
    ],
    "methods": [
      "自然语言定理证明框架",
      "RL-Zero强化学习策略",
      "大规模数据集构建",
      "过程与结果评测指标"
    ],
    "problems": [
      "如何提升大语言模型在非正式数学定理证明中的推理能力",
      "如何利用自然语言和强化学习促进自动定理证明",
      "如何系统评估LLM在数学推理任务中的表现"
    ]
  },
  "2505.23586": {
    "classification_path": "计算机科学 → 计算机视觉 → 图像分割 → 篡改区域定位",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "图像分割",
      "level3": "篡改区域定位",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要关注于在缺乏像素级标注的情况下，通过弱监督方法对图像中被篡改区域进行定位。该任务属于计算机视觉领域下的图像分割分支，具体聚焦于图像篡改区域的分割与定位，因此选择'计算机视觉 → 图像分割 → 篡改区域定位'作为最合适的分层分类路径。",
      "keywords": [
        "弱监督学习",
        "图像篡改检测",
        "区域定位",
        "多分辨率特征",
        "分割模型",
        "Bayesian推断"
      ],
      "methods": [
        "融合图像级篡改检测网络的激活图与预训练分割模型的分割图",
        "基于WCBnet生成多视角特征图并融合用于粗定位",
        "利用DeepLab、SegmentAnything、PSPnet等分割模型细化区域",
        "采用Bayesian推断提升定位精度"
      ],
      "problems": [
        "如何在缺乏像素级标注的情况下实现对图像篡改区域的有效定位",
        "提升现有深度学习篡改检测方法的可解释性和区域定位能力"
      ]
    },
    "keywords": [
      "弱监督学习",
      "图像篡改检测",
      "区域定位",
      "多分辨率特征",
      "分割模型",
      "Bayesian推断"
    ],
    "methods": [
      "融合图像级篡改检测网络的激活图与预训练分割模型的分割图",
      "基于WCBnet生成多视角特征图并融合用于粗定位",
      "利用DeepLab、SegmentAnything、PSPnet等分割模型细化区域",
      "采用Bayesian推断提升定位精度"
    ],
    "problems": [
      "如何在缺乏像素级标注的情况下实现对图像篡改区域的有效定位",
      "提升现有深度学习篡改检测方法的可解释性和区域定位能力"
    ]
  },
  "2505.23759": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究视觉-语言模型（VLMs）在解决Rebus谜题（视觉与语言结合的谜题）上的能力，涉及视觉与语言的深度融合与推理，属于典型的多模态学习范畴。论文通过构建Rebus谜题基准，分析VLMs在多模态抽象、符号推理和隐喻理解等方面的表现，核心任务为多模态问答，因此选择'多模态学习→问答系统'作为最合适的分类路径。",
      "keywords": [
        "视觉-语言模型",
        "Rebus谜题",
        "多模态推理",
        "符号推理",
        "视觉隐喻",
        "基准数据集"
      ],
      "methods": [
        "手工构建并注释Rebus谜题基准",
        "多模态模型性能评估",
        "定量与定性分析"
      ],
      "problems": [
        "当前视觉-语言模型在Rebus谜题等多模态抽象与符号推理任务上的能力与局限性",
        "VLMs在处理抽象推理、侧向思维和视觉隐喻时的表现不足"
      ]
    },
    "keywords": [
      "视觉-语言模型",
      "Rebus谜题",
      "多模态推理",
      "符号推理",
      "视觉隐喻",
      "基准数据集"
    ],
    "methods": [
      "手工构建并注释Rebus谜题基准",
      "多模态模型性能评估",
      "定量与定性分析"
    ],
    "problems": [
      "当前视觉-语言模型在Rebus谜题等多模态抽象与符号推理任务上的能力与局限性",
      "VLMs在处理抽象推理、侧向思维和视觉隐喻时的表现不足"
    ]
  },
  "2505.23587": {
    "classification_path": "计算机科学 → 医学图像 → 医学图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "医学图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于乳腺超声肿瘤分割任务，属于医学图像领域。其核心贡献在于提升医学图像分割模型在跨数据集场景下的泛化能力，主要方法为PCA预处理与U-Net分割模型结合。虽然涉及计算机视觉和机器学习方法，但论文的主要应用场景和任务是医学图像分割，因此选择'医学图像'作为二级领域，'医学图像分割'为三级领域，四级领域无更细分标准词，设为null。",
      "keywords": [
        "PCA",
        "跨数据集泛化",
        "乳腺超声",
        "肿瘤分割",
        "医学图像分割",
        "U-Net",
        "外部验证"
      ],
      "methods": [
        "主成分分析（PCA）预处理",
        "U-Net分割模型训练与评估",
        "跨数据集实验设计",
        "统计显著性分析"
      ],
      "problems": [
        "医学图像分割模型在未见数据集上的泛化能力有限",
        "现有领域自适应和风格迁移方法在医学小样本多样性场景下效果不佳",
        "如何通过特征降维与重构提升分割模型的跨数据集性能"
      ]
    },
    "keywords": [
      "PCA",
      "跨数据集泛化",
      "乳腺超声",
      "肿瘤分割",
      "医学图像分割",
      "U-Net",
      "外部验证"
    ],
    "methods": [
      "主成分分析（PCA）预处理",
      "U-Net分割模型训练与评估",
      "跨数据集实验设计",
      "统计显著性分析"
    ],
    "problems": [
      "医学图像分割模型在未见数据集上的泛化能力有限",
      "现有领域自适应和风格迁移方法在医学小样本多样性场景下效果不佳",
      "如何通过特征降维与重构提升分割模型的跨数据集性能"
    ]
  },
  "2505.23765": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统 → 聚合式问答",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": "聚合式问答",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于从大规模对话日志中通过聚合推理回答集合性问题，属于自然语言处理领域下的问答系统。其创新点在于提出了聚合式问答（Aggregative Question Answering）任务，要求模型跨越大量对话进行推理和信息整合，因此最合适的四级分类为‘聚合式问答’。",
      "keywords": [
        "聚合式问答",
        "对话日志",
        "大语言模型",
        "集体洞察",
        "WildChat-AQA",
        "用户-聊天机器人交互"
      ],
      "methods": [
        "大规模对话数据聚合",
        "跨会话推理",
        "基准数据集构建",
        "现有方法实验评估"
      ],
      "problems": [
        "如何从大规模用户-聊天机器人对话日志中提取集体洞察？",
        "现有方法在聚合式问答任务中推理能力和计算效率的不足如何解决？",
        "如何构建和评估能够处理聚合式问答任务的基准数据集？"
      ]
    },
    "keywords": [
      "聚合式问答",
      "对话日志",
      "大语言模型",
      "集体洞察",
      "WildChat-AQA",
      "用户-聊天机器人交互"
    ],
    "methods": [
      "大规模对话数据聚合",
      "跨会话推理",
      "基准数据集构建",
      "现有方法实验评估"
    ],
    "problems": [
      "如何从大规模用户-聊天机器人对话日志中提取集体洞察？",
      "现有方法在聚合式问答任务中推理能力和计算效率的不足如何解决？",
      "如何构建和评估能够处理聚合式问答任务的基准数据集？"
    ]
  },
  "2505.23590": {
    "classification_path": "计算机科学 → 多模态学习 → 规则驱动视觉强化学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "强化学习",
      "level3": "规则驱动视觉强化学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要研究多模态大模型（MLLMs）在视觉任务（拼图）上的规则驱动强化学习，涉及视觉与语言的结合，属于多模态学习。核心方法为强化学习，具体聚焦于规则驱动的视觉强化学习任务，因此选择'多模态学习→强化学习→规则驱动视觉强化学习'作为最贴切的分层分类。",
      "keywords": [
        "多模态大模型",
        "视觉强化学习",
        "规则驱动",
        "拼图任务",
        "泛化能力",
        "推理能力"
      ],
      "methods": [
        "规则驱动强化学习（Rule-based RL）",
        "多模态大模型微调",
        "拼图任务实验框架",
        "对比监督微调与强化学习"
      ],
      "problems": [
        "多模态大模型在视觉强化学习任务中的泛化能力如何？",
        "规则驱动强化学习在视觉任务中的表现与机制是什么？",
        "拼图任务训练能否促进模型对其他视觉任务的泛化？",
        "多模态大模型是否需要显式推理才能泛化？",
        "监督微调与强化学习在多模态视觉任务中的优劣对比"
      ]
    },
    "keywords": [
      "多模态大模型",
      "视觉强化学习",
      "规则驱动",
      "拼图任务",
      "泛化能力",
      "推理能力"
    ],
    "methods": [
      "规则驱动强化学习（Rule-based RL）",
      "多模态大模型微调",
      "拼图任务实验框架",
      "对比监督微调与强化学习"
    ],
    "problems": [
      "多模态大模型在视觉强化学习任务中的泛化能力如何？",
      "规则驱动强化学习在视觉任务中的表现与机制是什么？",
      "拼图任务训练能否促进模型对其他视觉任务的泛化？",
      "多模态大模型是否需要显式推理才能泛化？",
      "监督微调与强化学习在多模态视觉任务中的优劣对比"
    ]
  },
  "2505.22654": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于大规模视觉-语言模型（LVLMs）的高效推理，核心内容是通过视觉token的高效压缩与剪枝提升多模态模型的推理速度和资源利用率。论文主要涉及视觉与语言的联合建模与推理优化，属于多模态学习范畴。由于论文的主要实验和应用场景集中在多模态问答系统（如LLaVA-NeXT-7B等），最贴切的三级领域为问答系统。四级领域暂无更细致标准任务，故为null。",
      "keywords": [
        "视觉-语言模型",
        "视觉token压缩",
        "多模态推理",
        "高效推理",
        "token剪枝",
        "VScan"
      ],
      "methods": [
        "两阶段视觉token压缩框架",
        "全局与局部扫描结合的token合并",
        "语言模型中间层token剪枝",
        "综合实证分析"
      ],
      "problems": [
        "如何减少大规模视觉-语言模型中的视觉token冗余以提升推理效率",
        "如何在保证模型性能的前提下大幅降低计算资源消耗",
        "现有视觉token剪枝策略在不同阶段的有效性与局限性"
      ]
    },
    "keywords": [
      "视觉-语言模型",
      "视觉token压缩",
      "多模态推理",
      "高效推理",
      "token剪枝",
      "VScan"
    ],
    "methods": [
      "两阶段视觉token压缩框架",
      "全局与局部扫描结合的token合并",
      "语言模型中间层token剪枝",
      "综合实证分析"
    ],
    "problems": [
      "如何减少大规模视觉-语言模型中的视觉token冗余以提升推理效率",
      "如何在保证模型性能的前提下大幅降低计算资源消耗",
      "现有视觉token剪枝策略在不同阶段的有效性与局限性"
    ]
  },
  "2505.23595": {
    "classification_path": "计算机科学 → 医学图像 → 医学图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "医学图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于胸部X光片（CXR）的多标签分类任务，属于医学图像分析领域。虽然论文核心是多任务学习中的任务权重分配方法，但其主要应用场景和实验均在医学影像（胸部X光片）分类任务上。标准领域词表中医学图像下只有'医学图像分割'，但没有更细致的'医学图像分类'，因此选择最接近的'医学图像分割'作为三级领域。由于没有更具体的四级任务，level3设为null。",
      "keywords": [
        "多任务学习",
        "胸部X光片",
        "医学图像分类",
        "动态任务权重",
        "无梯度方法",
        "负迁移",
        "深度学习"
      ],
      "methods": [
        "动态无梯度任务加权机制",
        "基于任务损失趋势的权重调整",
        "模型无关的任务权重分配",
        "ResNet18架构应用"
      ],
      "problems": [
        "如何在多任务学习中有效平衡各任务的贡献",
        "如何降低多任务学习中任务权重分配的计算和内存开销",
        "如何提升医学图像多标签分类的准确率与泛化能力",
        "如何缓解多任务学习中的负迁移现象"
      ]
    },
    "keywords": [
      "多任务学习",
      "胸部X光片",
      "医学图像分类",
      "动态任务权重",
      "无梯度方法",
      "负迁移",
      "深度学习"
    ],
    "methods": [
      "动态无梯度任务加权机制",
      "基于任务损失趋势的权重调整",
      "模型无关的任务权重分配",
      "ResNet18架构应用"
    ],
    "problems": [
      "如何在多任务学习中有效平衡各任务的贡献",
      "如何降低多任务学习中任务权重分配的计算和内存开销",
      "如何提升医学图像多标签分类的准确率与泛化能力",
      "如何缓解多任务学习中的负迁移现象"
    ]
  },
  "2505.22756": {
    "classification_path": "计算机科学 → 强化学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "强化学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要研究强化学习（RL）方法对大语言模型（LLM）在数学推理任务中的能力提升，尤其关注RL对问题求解能力的细粒度影响。虽然涉及大语言模型和自然语言处理，但核心贡献在于分析和分解RL对模型推理能力（如计划、执行、验证）的作用，并通过合成任务验证RL在问答类推理任务中的表现。因此，最合适的分类路径为‘计算机科学 → 强化学习 → 问答系统’。",
      "keywords": [
        "强化学习",
        "大语言模型",
        "数学推理",
        "问题求解",
        "能力分解",
        "GRPO",
        "执行鲁棒性",
        "coverage wall"
      ],
      "methods": [
        "能力分解（计划、执行、验证）",
        "GRPO强化学习训练",
        "合成解题树导航任务",
        "经验分析"
      ],
      "problems": [
        "RL方法提升LLM数学推理能力的具体机制是什么？",
        "RL训练是否提升了模型的计划、执行和验证等细粒度能力？",
        "RL模型在遇到新类型问题时为何会遇到‘coverage wall’？",
        "如何通过改进RL探索和泛化能力突破coverage wall？"
      ]
    },
    "keywords": [
      "强化学习",
      "大语言模型",
      "数学推理",
      "问题求解",
      "能力分解",
      "GRPO",
      "执行鲁棒性",
      "coverage wall"
    ],
    "methods": [
      "能力分解（计划、执行、验证）",
      "GRPO强化学习训练",
      "合成解题树导航任务",
      "经验分析"
    ],
    "problems": [
      "RL方法提升LLM数学推理能力的具体机制是什么？",
      "RL训练是否提升了模型的计划、执行和验证等细粒度能力？",
      "RL模型在遇到新类型问题时为何会遇到‘coverage wall’？",
      "如何通过改进RL探索和泛化能力突破coverage wall？"
    ]
  },
  "2505.23597": {
    "classification_path": "计算机科学 → 计算机视觉 → 图像分割 → 语义分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "图像分割",
      "level3": "语义分割",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于遥感数据中树冠的精确语义分割任务，提出了新型深度学习模型PerceptiveNet，并在树冠和航拍场景数据集上进行了实验。其核心任务是对图像中的树冠进行像素级别的分类，属于计算机视觉领域下的图像分割，具体为语义分割任务。",
      "keywords": [
        "语义分割",
        "树冠分割",
        "遥感",
        "PerceptiveNet",
        "Log-Gabor卷积",
        "深度学习",
        "CNN-Transformer混合模型"
      ],
      "methods": [
        "Logarithmic Gabor参数化卷积层",
        "可训练滤波器参数",
        "宽感受野特征提取主干网络",
        "消融实验",
        "CNN-Transformer混合模型"
      ],
      "problems": [
        "如何在遥感图像中实现复杂森林冠层的精确语义分割",
        "如何提升模型对阴影、复杂背景、尺度变化和树种光谱差异的鲁棒性",
        "如何通过新型卷积层和混合架构提升分割性能并实现跨域泛化"
      ]
    },
    "keywords": [
      "语义分割",
      "树冠分割",
      "遥感",
      "PerceptiveNet",
      "Log-Gabor卷积",
      "深度学习",
      "CNN-Transformer混合模型"
    ],
    "methods": [
      "Logarithmic Gabor参数化卷积层",
      "可训练滤波器参数",
      "宽感受野特征提取主干网络",
      "消融实验",
      "CNN-Transformer混合模型"
    ],
    "problems": [
      "如何在遥感图像中实现复杂森林冠层的精确语义分割",
      "如何提升模型对阴影、复杂背景、尺度变化和树种光谱差异的鲁棒性",
      "如何通过新型卷积层和混合架构提升分割性能并实现跨域泛化"
    ]
  },
  "2505.22758": {
    "classification_path": "计算机科学 → 大语言模型 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于提升Transformer类大语言模型在低批量推理场景下的效率，提出了专门的内核（kernel）优化方法。虽然涉及底层系统优化，但核心贡献是面向大语言模型（如Transformer）的推理加速，属于大语言模型领域。由于标准词表下未有更细致的推理加速或内核优化选项，且论文未聚焦于具体下游任务（如问答、对话等），因此选择'大语言模型 → 生成模型'作为最合适的分类路径。",
      "keywords": [
        "低批量推理",
        "大语言模型",
        "Transformer",
        "高效内核",
        "推理加速",
        "模型量化"
      ],
      "methods": [
        "专用推理内核设计",
        "全模型内核优化",
        "量化支持",
        "内存带宽优化"
      ],
      "problems": [
        "如何提升大语言模型在低批量推理场景下的效率",
        "如何减少内存带宽和内核启动开销对推理速度的影响"
      ]
    },
    "keywords": [
      "低批量推理",
      "大语言模型",
      "Transformer",
      "高效内核",
      "推理加速",
      "模型量化"
    ],
    "methods": [
      "专用推理内核设计",
      "全模型内核优化",
      "量化支持",
      "内存带宽优化"
    ],
    "problems": [
      "如何提升大语言模型在低批量推理场景下的效率",
      "如何减少内存带宽和内核启动开销对推理速度的影响"
    ]
  },
  "2505.23601": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 医学视觉问答",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "医学视觉问答",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于多模态大语言模型（MLLMs）在内镜分析中的综合评测，涉及视觉与语言的结合，属于多模态学习。论文核心任务是基于视觉问答（VQA）对医学内镜场景进行评估，且所有实验和基准均围绕医学视觉问答展开，因此选择'多模态学习 → 问答系统 → 医学视觉问答'作为最贴切的分层分类路径。",
      "keywords": [
        "多模态大语言模型",
        "内镜分析",
        "视觉问答",
        "医学人工智能",
        "基准评测",
        "EndoBench"
      ],
      "methods": [
        "多维度评测框架",
        "EndoBench基准设计",
        "跨场景视觉问答任务",
        "模型性能对比分析",
        "人类专家基准对照"
      ],
      "problems": [
        "现有内镜多模态模型评测基准覆盖有限，无法反映真实临床多样性和任务复杂性",
        "如何全面评估多模态大语言模型在内镜分析中的感知与诊断能力",
        "不同类型MLLMs（通用、医学专用、专有）在医学视觉问答任务中的性能差异与不足"
      ]
    },
    "keywords": [
      "多模态大语言模型",
      "内镜分析",
      "视觉问答",
      "医学人工智能",
      "基准评测",
      "EndoBench"
    ],
    "methods": [
      "多维度评测框架",
      "EndoBench基准设计",
      "跨场景视觉问答任务",
      "模型性能对比分析",
      "人类专家基准对照"
    ],
    "problems": [
      "现有内镜多模态模型评测基准覆盖有限，无法反映真实临床多样性和任务复杂性",
      "如何全面评估多模态大语言模型在内镜分析中的感知与诊断能力",
      "不同类型MLLMs（通用、医学专用、专有）在医学视觉问答任务中的性能差异与不足"
    ]
  },
  "2505.22857": {
    "classification_path": "计算机科学 → 语音与音频处理 → 语音识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "语音与音频处理",
      "level2": "语音识别",
      "level3": null,
      "depth": 3,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于自动语音识别（ASR）中的上下文偏置问题，提出了一种基于GPU加速的n-gram语言模型（NGPU-LM），用于提升ASR系统在贪婪解码过程中的效率和准确性。论文的主要贡献在于提升语音识别系统的推理速度和上下文适应能力，属于语音与音频处理领域下的语音识别任务。虽然涉及语言模型和并行计算，但核心任务是提升ASR系统的解码性能，因此选择'语音与音频处理 → 语音识别'作为最合适的分类路径。",
      "keywords": [
        "n-gram语言模型",
        "GPU加速",
        "上下文偏置",
        "自动语音识别",
        "贪婪解码",
        "并行计算"
      ],
      "methods": [
        "GPU优化的数据结构设计",
        "定制化贪婪解码算法",
        "n-gram语言模型并行推理"
      ],
      "problems": [
        "现有n-gram语言模型在ASR上下文偏置中的并行化和计算效率不足",
        "如何在不显著增加计算开销的情况下提升贪婪解码的准确性",
        "如何缩小贪婪解码与beam search在ASR中的准确率差距"
      ]
    },
    "keywords": [
      "n-gram语言模型",
      "GPU加速",
      "上下文偏置",
      "自动语音识别",
      "贪婪解码",
      "并行计算"
    ],
    "methods": [
      "GPU优化的数据结构设计",
      "定制化贪婪解码算法",
      "n-gram语言模型并行推理"
    ],
    "problems": [
      "现有n-gram语言模型在ASR上下文偏置中的并行化和计算效率不足",
      "如何在不显著增加计算开销的情况下提升贪婪解码的准确性",
      "如何缩小贪婪解码与beam search在ASR中的准确率差距"
    ]
  },
  "2505.23629": {
    "classification_path": "计算机科学 → 计算机视觉 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注彩色图像集的识别问题，属于计算机视觉领域。论文提出了一种基于四元数Grassmann流形的新方法，用于对彩色图像集进行建模和分类，并在ETH-80数据集上进行了实验。虽然方法涉及流形学习和距离度量，但核心任务是图像集识别，这属于小样本学习范畴，因为图像集识别通常涉及有限样本的分类问题。标准领域词表中没有更细的'图像集识别'或'图像分类'，因此选择最接近的'小样本学习'作为三级领域。",
      "keywords": [
        "彩色图像集识别",
        "四元数Grassmann流形",
        "距离度量",
        "图像分类",
        "ETH-80数据集"
      ],
      "methods": [
        "基于四元数Grassmann流形的图像集建模",
        "最短距离度量公式",
        "新型分类框架"
      ],
      "problems": [
        "如何有效利用彩色信息进行图像集识别",
        "如何在Grassmann流形上度量图像集之间的距离",
        "提升彩色图像集识别的准确率和稳定性"
      ]
    },
    "keywords": [
      "彩色图像集识别",
      "四元数Grassmann流形",
      "距离度量",
      "图像分类",
      "ETH-80数据集"
    ],
    "methods": [
      "基于四元数Grassmann流形的图像集建模",
      "最短距离度量公式",
      "新型分类框架"
    ],
    "problems": [
      "如何有效利用彩色信息进行图像集识别",
      "如何在Grassmann流形上度量图像集之间的距离",
      "提升彩色图像集识别的准确率和稳定性"
    ]
  },
  "2505.22863": {
    "classification_path": "计算机科学 → 多模态学习 → 对话系统 → null",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "对话系统",
      "level3": "null",
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究利用大语言模型（LLM）结合语音（音频）和文本信息进行抑郁症识别，属于典型的多模态学习任务。虽然涉及语音和文本，但核心创新点在于多模态信息融合与心理学知识注入，且应用于对话场景（DAIC-WOZ数据集为对话型抑郁检测）。标准领域词表中‘多模态学习’最为贴切，三级领域选择‘对话系统’，因其任务场景为对话式抑郁检测。四级领域暂无更细分标准词，设为null。",
      "keywords": [
        "大语言模型",
        "多模态学习",
        "抑郁症识别",
        "心理学知识注入",
        "语音特征提取",
        "对话系统"
      ],
      "methods": [
        "Wav2Vec音频特征提取",
        "文本与音频特征融合",
        "大语言模型微调",
        "心理学知识问答注入"
      ],
      "problems": [
        "如何提升大语言模型在多模态抑郁症识别中的表现",
        "如何有效融合语音与文本信息进行抑郁症检测",
        "如何将心理学领域知识注入大语言模型以提升诊断准确性"
      ]
    },
    "keywords": [
      "大语言模型",
      "多模态学习",
      "抑郁症识别",
      "心理学知识注入",
      "语音特征提取",
      "对话系统"
    ],
    "methods": [
      "Wav2Vec音频特征提取",
      "文本与音频特征融合",
      "大语言模型微调",
      "心理学知识问答注入"
    ],
    "problems": [
      "如何提升大语言模型在多模态抑郁症识别中的表现",
      "如何有效融合语音与文本信息进行抑郁症检测",
      "如何将心理学领域知识注入大语言模型以提升诊断准确性"
    ]
  },
  "2505.23637": {
    "classification_path": "计算机科学 → 医学图像 → 医学图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "医学图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于医学影像数据的特征工程方法比较，尤其是利用拓扑数据分析（TDA）中的持久同调（PH）对医学影像进行特征提取，并比较不同特征向量构建方式对分类性能的影响。虽然论文未直接涉及分割任务，但医学影像分类与分割在实际应用和特征工程方法上高度相关，且标准词表下医学图像领域的下一级仅有'医学图像分割'，因此选择该路径最为贴切。",
      "keywords": [
        "医学影像分析",
        "持久同调",
        "拓扑数据分析",
        "特征工程",
        "持久条形码",
        "特征聚合",
        "特征拼接",
        "分类"
      ],
      "methods": [
        "持久同调特征提取",
        "持久条形码聚合",
        "特征拼接",
        "机器学习分类模型"
      ],
      "problems": [
        "比较持久条形码聚合与特征拼接两种特征工程方法对医学影像分类性能的影响",
        "评估不同特征向量构建方式在医学影像数据上的表现"
      ]
    },
    "keywords": [
      "医学影像分析",
      "持久同调",
      "拓扑数据分析",
      "特征工程",
      "持久条形码",
      "特征聚合",
      "特征拼接",
      "分类"
    ],
    "methods": [
      "持久同调特征提取",
      "持久条形码聚合",
      "特征拼接",
      "机器学习分类模型"
    ],
    "problems": [
      "比较持久条形码聚合与特征拼接两种特征工程方法对医学影像分类性能的影响",
      "评估不同特征向量构建方式在医学影像数据上的表现"
    ]
  },
  "2505.22907": {
    "classification_path": "计算机科学 → 自然语言处理 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注人工智能对话体系统与人类交流规范的对齐问题，提出了CONTEXT-ALIGN框架用于评估AI对话系统的设计与人类沟通实践的一致性。虽然涉及大语言模型，但核心研究内容是对话系统的对齐与评估，因此选择‘自然语言处理 → 对话系统’作为最合适的分类路径。",
      "keywords": [
        "对话系统",
        "对齐",
        "大语言模型",
        "语用学",
        "人机交互",
        "语境",
        "共识建立"
      ],
      "methods": [
        "CONTEXT-ALIGN框架",
        "哲学与语言学理论分析",
        "对话语用学分析"
      ],
      "problems": [
        "如何使AI对话系统在语境和共识处理上与人类交流规范对齐",
        "当前大语言模型架构在实现完全对齐方面的局限性",
        "如何评估开发者在AI对话系统设计中的选择与人类交流实践的一致性"
      ]
    },
    "keywords": [
      "对话系统",
      "对齐",
      "大语言模型",
      "语用学",
      "人机交互",
      "语境",
      "共识建立"
    ],
    "methods": [
      "CONTEXT-ALIGN框架",
      "哲学与语言学理论分析",
      "对话语用学分析"
    ],
    "problems": [
      "如何使AI对话系统在语境和共识处理上与人类交流规范对齐",
      "当前大语言模型架构在实现完全对齐方面的局限性",
      "如何评估开发者在AI对话系统设计中的选择与人类交流实践的一致性"
    ]
  },
  "2505.23642": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "三维重建",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文提出了一种基于三角形集合（triangle soup）和软连接力的三维场景重建与新视角合成方法，核心任务是三维重建，并在此基础上实现新视角合成。论文主要关注三维场景的几何与外观建模，属于计算机视觉领域下的三维重建任务。",
      "keywords": [
        "三维重建",
        "三角形集合",
        "软连接力",
        "新视角合成",
        "场景优化",
        "三维场景表示"
      ],
      "methods": [
        "基于三角形的场景优化算法",
        "软连接力约束",
        "三角形集合（triangle soup）表示",
        "推理时优化框架"
      ],
      "problems": [
        "如何利用三角形集合高效表达和重建三维场景的几何与外观",
        "如何在三角形集合中实现表面连续性",
        "如何提升三维重建和新视角合成的表现"
      ]
    },
    "keywords": [
      "三维重建",
      "三角形集合",
      "软连接力",
      "新视角合成",
      "场景优化",
      "三维场景表示"
    ],
    "methods": [
      "基于三角形的场景优化算法",
      "软连接力约束",
      "三角形集合（triangle soup）表示",
      "推理时优化框架"
    ],
    "problems": [
      "如何利用三角形集合高效表达和重建三维场景的几何与外观",
      "如何在三角形集合中实现表面连续性",
      "如何提升三维重建和新视角合成的表现"
    ]
  },
  "2505.22928": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于从医学临床试验论文中自动抽取数值证据并推断研究结论，属于自然语言处理领域。其核心任务是对文本进行结构化信息抽取和推理，属于问答系统的范畴（即针对特定问题自动从文本中推断答案），而不是通用的生成模型、对话系统等。虽然论文采用了强化学习方法，但主要任务是NLP中的信息抽取与推理，因此归入'自然语言处理 → 问答系统'最为贴切。",
      "keywords": [
        "数值推理",
        "信息抽取",
        "系统综述自动化",
        "临床试验",
        "强化学习",
        "医学文本",
        "结构化证据"
      ],
      "methods": [
        "数值数据抽取模型",
        "强化学习训练（RL）",
        "监督微调（SFT）",
        "基于价值奖励模型的训练",
        "效果估计组件"
      ],
      "problems": [
        "如何自动从临床试验论文中抽取结构化数值证据",
        "如何基于数值证据推断研究结论以辅助医学系统综述",
        "如何提升自动化系统在医学证据推理中的准确性和可解释性"
      ]
    },
    "keywords": [
      "数值推理",
      "信息抽取",
      "系统综述自动化",
      "临床试验",
      "强化学习",
      "医学文本",
      "结构化证据"
    ],
    "methods": [
      "数值数据抽取模型",
      "强化学习训练（RL）",
      "监督微调（SFT）",
      "基于价值奖励模型的训练",
      "效果估计组件"
    ],
    "problems": [
      "如何自动从临床试验论文中抽取结构化数值证据",
      "如何基于数值证据推断研究结论以辅助医学系统综述",
      "如何提升自动化系统在医学证据推理中的准确性和可解释性"
    ]
  },
  "2505.23656": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于提升文本到视频（T2V）扩散模型的物理合理性，通过与视频理解基础模型的关系对齐实现物理知识注入。其主要创新点在于提出了针对T2V扩散模型的物理知识蒸馏方法，属于计算机视觉领域下的生成模型，具体任务为扩散模型在视频生成中的应用。",
      "keywords": [
        "文本到视频生成",
        "扩散模型",
        "物理知识蒸馏",
        "关系对齐",
        "视频生成",
        "基础模型"
      ],
      "methods": [
        "Token Relation Distillation (TRD) 损失",
        "关系对齐蒸馏",
        "视频理解基础模型知识迁移",
        "T2V模型微调"
      ],
      "problems": [
        "现有文本到视频扩散模型缺乏物理合理性",
        "如何将物理知识有效注入T2V生成模型",
        "提升生成视频的物理常识与一致性"
      ]
    },
    "keywords": [
      "文本到视频生成",
      "扩散模型",
      "物理知识蒸馏",
      "关系对齐",
      "视频生成",
      "基础模型"
    ],
    "methods": [
      "Token Relation Distillation (TRD) 损失",
      "关系对齐蒸馏",
      "视频理解基础模型知识迁移",
      "T2V模型微调"
    ],
    "problems": [
      "现有文本到视频扩散模型缺乏物理合理性",
      "如何将物理知识有效注入T2V生成模型",
      "提升生成视频的物理常识与一致性"
    ]
  },
  "2505.23660": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文提出了一种将图像扩散过程重构为自回归模型的范式，核心内容是将扩散模型与自回归建模结合，用于图像生成任务。论文主要关注视觉内容的生成，属于计算机视觉领域下的生成模型，具体聚焦于扩散模型的创新方法，因此选择'计算机视觉 → 生成模型 → 扩散模型'作为分类路径。",
      "keywords": [
        "扩散模型",
        "自回归模型",
        "图像生成",
        "离散token",
        "图像合成",
        "大语言模型",
        "ImageNet",
        "零样本布局控制"
      ],
      "methods": [
        "将图像扩散过程重构为标准自回归的next-token预测",
        "设计图像tokenizer，将图像转为离散token序列",
        "利用token的粗到细顺序进行自回归建模",
        "直接用自回归模型生成token并解码为扩散去噪步骤"
      ],
      "problems": [
        "如何将扩散模型与自回归模型结合，实现高效的图像生成？",
        "如何设计tokenizer，使得图像扩散过程可用自回归方式建模？",
        "能否在不修改自回归模型结构的前提下实现扩散式图像生成？"
      ]
    },
    "keywords": [
      "扩散模型",
      "自回归模型",
      "图像生成",
      "离散token",
      "图像合成",
      "大语言模型",
      "ImageNet",
      "零样本布局控制"
    ],
    "methods": [
      "将图像扩散过程重构为标准自回归的next-token预测",
      "设计图像tokenizer，将图像转为离散token序列",
      "利用token的粗到细顺序进行自回归建模",
      "直接用自回归模型生成token并解码为扩散去噪步骤"
    ],
    "problems": [
      "如何将扩散模型与自回归模型结合，实现高效的图像生成？",
      "如何设计tokenizer，使得图像扩散过程可用自回归方式建模？",
      "能否在不修改自回归模型结构的前提下实现扩散式图像生成？"
    ]
  },
  "2505.23020": {
    "classification_path": "计算机科学 → 大语言模型 → 对话系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "对话系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）从信息提供者向具备代理能力（agentic capabilities）的转变，核心贡献是提出AgentAlign框架以提升LLM代理行为的安全性对齐。虽然涉及安全性和多步行为，但主要研究对象和方法均围绕大语言模型的安全对齐与行为生成，且实验和评测均基于对话/指令执行场景，因此选择“大语言模型→对话系统”作为最贴切的分类路径。标准领域词表下未有更细致的安全对齐或代理任务选项，故level3设为null。",
      "keywords": [
        "大语言模型",
        "安全对齐",
        "代理能力",
        "行为链",
        "指令生成",
        "AgentAlign",
        "多步推理"
      ],
      "methods": [
        "行为链抽象与实例化",
        "安全对齐数据合成",
        "模拟环境生成多样化工具实例",
        "比例合成良性与恶意指令",
        "模型微调"
      ],
      "problems": [
        "如何提升具备代理能力的大语言模型在执行任务时的安全对齐水平",
        "如何在不损害模型有用性的前提下，防止LLM代理被用于恶意用途",
        "如何自动化生成高真实性、可执行的安全对齐训练数据"
      ]
    },
    "keywords": [
      "大语言模型",
      "安全对齐",
      "代理能力",
      "行为链",
      "指令生成",
      "AgentAlign",
      "多步推理"
    ],
    "methods": [
      "行为链抽象与实例化",
      "安全对齐数据合成",
      "模拟环境生成多样化工具实例",
      "比例合成良性与恶意指令",
      "模型微调"
    ],
    "problems": [
      "如何提升具备代理能力的大语言模型在执行任务时的安全对齐水平",
      "如何在不损害模型有用性的前提下，防止LLM代理被用于恶意用途",
      "如何自动化生成高真实性、可执行的安全对齐训练数据"
    ]
  },
  "2505.23661": {
    "classification_path": "计算机科学 → 多模态学习 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了一个统一的多模态理解与生成基线模型OpenUni，核心在于通过轻量级的transformer连接器将多模态大语言模型与扩散模型结合，实现了图像生成和多模态理解任务。论文强调模型的多模态统一能力和生成能力，属于多模态学习领域下的生成模型方向。由于标准词表中没有更细的多模态生成任务选项，level3设为null。",
      "keywords": [
        "多模态学习",
        "生成模型",
        "图像生成",
        "大语言模型",
        "扩散模型",
        "轻量级模型",
        "统一模型",
        "开源"
      ],
      "methods": [
        "轻量级transformer连接器",
        "可学习查询机制",
        "多模态大语言模型与扩散模型结合",
        "高效训练策略"
      ],
      "problems": [
        "如何统一多模态理解与生成任务",
        "如何降低多模态模型的训练复杂度与开销",
        "如何在参数量有限的情况下实现高质量生成与理解"
      ]
    },
    "keywords": [
      "多模态学习",
      "生成模型",
      "图像生成",
      "大语言模型",
      "扩散模型",
      "轻量级模型",
      "统一模型",
      "开源"
    ],
    "methods": [
      "轻量级transformer连接器",
      "可学习查询机制",
      "多模态大语言模型与扩散模型结合",
      "高效训练策略"
    ],
    "problems": [
      "如何统一多模态理解与生成任务",
      "如何降低多模态模型的训练复杂度与开销",
      "如何在参数量有限的情况下实现高质量生成与理解"
    ]
  },
  "2505.23039": {
    "classification_path": "计算机科学 → 自然语言处理 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "自然语言处理",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究自然语言到SQL（NL2SQL）的自动转换系统，属于自然语言处理领域。其核心任务是将自然语言问题转化为结构化查询语言（SQL），以便非技术用户访问数据库，这属于问答系统的范畴。虽然涉及数据库，但主要创新点和技术路线集中在自然语言理解与问答系统的实现，因此选择‘自然语言处理 → 问答系统’作为最合适的分类路径。",
      "keywords": [
        "NL2SQL",
        "自然语言到SQL",
        "数据库查询",
        "问答系统",
        "查询工作负载",
        "大语言模型",
        "SQL生成"
      ],
      "methods": [
        "利用历史查询工作负载信息",
        "数据库模式检索",
        "大语言模型驱动的SQL生成",
        "工作负载定制化NL2SQL系统"
      ],
      "problems": [
        "如何利用历史SQL查询工作负载提升NL2SQL系统的准确性和效率",
        "如何将数据库特定的隐含知识（如常见连接路径、表/列语义）融入NL2SQL系统",
        "提升自然语言到SQL转换在实际数据库环境下的执行准确率和响应速度"
      ]
    },
    "keywords": [
      "NL2SQL",
      "自然语言到SQL",
      "数据库查询",
      "问答系统",
      "查询工作负载",
      "大语言模型",
      "SQL生成"
    ],
    "methods": [
      "利用历史查询工作负载信息",
      "数据库模式检索",
      "大语言模型驱动的SQL生成",
      "工作负载定制化NL2SQL系统"
    ],
    "problems": [
      "如何利用历史SQL查询工作负载提升NL2SQL系统的准确性和效率",
      "如何将数据库特定的隐含知识（如常见连接路径、表/列语义）融入NL2SQL系统",
      "提升自然语言到SQL转换在实际数据库环境下的执行准确率和响应速度"
    ]
  },
  "2505.23675": {
    "classification_path": "计算机科学 → 医学图像 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要聚焦于非小细胞肺癌(NSCLC)免疫治疗反应预测，核心方法为基于CT医学影像的扩散生成模型（ImmunoDiff），并结合解剖结构先验和多模态临床数据。虽然涉及多模态学习，但主任务是医学影像生成与预测，因此归入'医学图像'。具体方法为扩散模型，属于'生成模型'下的'扩散模型'。",
      "keywords": [
        "免疫治疗反应预测",
        "非小细胞肺癌",
        "扩散模型",
        "医学影像生成",
        "CT合成",
        "解剖结构先验",
        "多模态融合",
        "cbi-Adapter"
      ],
      "methods": [
        "解剖结构感知的扩散模型（ImmunoDiff）",
        "cbi-Adapter多模态条件模块",
        "临床变量条件机制",
        "基于CT的后治疗影像合成"
      ],
      "problems": [
        "如何准确预测非小细胞肺癌患者对免疫治疗的反应",
        "如何利用基线CT影像和临床数据生成高保真度的后治疗CT影像",
        "如何提升医学影像生成模型对解剖结构和多模态信息的建模能力"
      ]
    },
    "keywords": [
      "免疫治疗反应预测",
      "非小细胞肺癌",
      "扩散模型",
      "医学影像生成",
      "CT合成",
      "解剖结构先验",
      "多模态融合",
      "cbi-Adapter"
    ],
    "methods": [
      "解剖结构感知的扩散模型（ImmunoDiff）",
      "cbi-Adapter多模态条件模块",
      "临床变量条件机制",
      "基于CT的后治疗影像合成"
    ],
    "problems": [
      "如何准确预测非小细胞肺癌患者对免疫治疗的反应",
      "如何利用基线CT影像和临床数据生成高保真度的后治疗CT影像",
      "如何提升医学影像生成模型对解剖结构和多模态信息的建模能力"
    ]
  },
  "2505.23049": {
    "classification_path": "计算机科学 → 大语言模型 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于大语言模型（LLMs）的剪枝鲁棒性提升，属于大语言模型领域。其核心方法为通过参数重要性重分布和正交变换提升模型在稀疏化（剪枝）下的性能，主要应用于LLaMA3、Qwen2.5、Mistral等主流生成式大语言模型。虽然涉及模型压缩与稀疏性，但论文的主要贡献和实验均围绕大语言模型的生成能力与鲁棒性展开，因此选择“大语言模型→生成模型”作为最合适的分类路径。",
      "keywords": [
        "大语言模型",
        "剪枝",
        "稀疏性",
        "重要性重分布",
        "正交变换",
        "模型压缩",
        "鲁棒性"
      ],
      "methods": [
        "DenoiseRotator",
        "重要性分布熵最小化",
        "可学习正交变换",
        "与现有剪枝方法集成（如Magnitude, SparseGPT, Wanda）"
      ],
      "problems": [
        "如何提升大语言模型在半结构化稀疏剪枝下的鲁棒性",
        "如何通过参数重要性重分布减少剪枝带来的性能损失"
      ]
    },
    "keywords": [
      "大语言模型",
      "剪枝",
      "稀疏性",
      "重要性重分布",
      "正交变换",
      "模型压缩",
      "鲁棒性"
    ],
    "methods": [
      "DenoiseRotator",
      "重要性分布熵最小化",
      "可学习正交变换",
      "与现有剪枝方法集成（如Magnitude, SparseGPT, Wanda）"
    ],
    "problems": [
      "如何提升大语言模型在半结构化稀疏剪枝下的鲁棒性",
      "如何通过参数重要性重分布减少剪枝带来的性能损失"
    ]
  },
  "2505.23678": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 小目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "小目标检测",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要研究视觉推理任务，核心创新在于通过强化学习实现视觉注意力的空间定位和推理步骤的可视化锚定，尤其强调在视觉界面中对小目标（如GUI元素、局部区域）的定位与探索。虽然方法融合了多模态和强化学习，但主要任务是视觉场景中小目标的定位与推理，因此归入‘计算机视觉 → 目标检测 → 小目标检测’最为贴切。",
      "keywords": [
        "视觉推理",
        "强化学习",
        "视觉注意力",
        "空间锚定",
        "小目标检测",
        "多模态模型",
        "人类决策启发",
        "视觉-语言模型"
      ],
      "methods": [
        "视觉锚定强化学习（ViGoRL）",
        "多轮强化学习框架",
        "空间注意力机制",
        "视觉反馈动态缩放"
      ],
      "problems": [
        "如何将强化学习应用于视觉推理任务，实现推理步骤与具体视觉区域的空间锚定？",
        "如何提升模型在复杂视觉界面中对小目标或局部区域的定位与推理能力？",
        "如何通过多轮强化学习和视觉反馈机制提升视觉推理的可解释性和准确性？"
      ]
    },
    "keywords": [
      "视觉推理",
      "强化学习",
      "视觉注意力",
      "空间锚定",
      "小目标检测",
      "多模态模型",
      "人类决策启发",
      "视觉-语言模型"
    ],
    "methods": [
      "视觉锚定强化学习（ViGoRL）",
      "多轮强化学习框架",
      "空间注意力机制",
      "视觉反馈动态缩放"
    ],
    "problems": [
      "如何将强化学习应用于视觉推理任务，实现推理步骤与具体视觉区域的空间锚定？",
      "如何提升模型在复杂视觉界面中对小目标或局部区域的定位与推理能力？",
      "如何通过多轮强化学习和视觉反馈机制提升视觉推理的可解释性和准确性？"
    ]
  },
  "2505.23058": {
    "classification_path": "计算机科学 → 大语言模型 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了Be.FM，一种基于开源大语言模型并针对人类行为数据微调的基础模型，主要用于理解和预测人类行为。论文核心在于大语言模型的构建与行为建模的结合，属于大语言模型领域下的生成模型应用。虽然涉及行为预测和推理，但从标准词表来看，最贴切的路径是‘大语言模型 → 生成模型’。",
      "keywords": [
        "基础模型",
        "大语言模型",
        "人类行为建模",
        "行为预测",
        "行为科学",
        "开源",
        "微调",
        "基准任务"
      ],
      "methods": [
        "基于大语言模型的微调",
        "多行为数据集训练",
        "基准任务评测"
      ],
      "problems": [
        "如何利用大语言模型理解和预测人类行为",
        "如何构建适用于人类行为建模的开源基础模型",
        "如何评估行为基础模型在行为预测、个体特征推断和情境洞察等任务上的能力"
      ]
    },
    "keywords": [
      "基础模型",
      "大语言模型",
      "人类行为建模",
      "行为预测",
      "行为科学",
      "开源",
      "微调",
      "基准任务"
    ],
    "methods": [
      "基于大语言模型的微调",
      "多行为数据集训练",
      "基准任务评测"
    ],
    "problems": [
      "如何利用大语言模型理解和预测人类行为",
      "如何构建适用于人类行为建模的开源基础模型",
      "如何评估行为基础模型在行为预测、个体特征推断和情境洞察等任务上的能力"
    ]
  },
  "2505.23693": {
    "classification_path": "计算机科学 → 多模态学习 → 视频理解 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "视频理解",
      "level3": "问答系统",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要关注多模态大模型（MLLMs）在AI生成内容（AIGC）视频上的理解与反馈生成能力评测，属于多模态学习范畴。具体任务为对AIGC视频进行多维度评测，包括问答、推理、错误检测等，核心属于视频理解下的问答系统应用，因此选择'多模态学习 → 视频理解 → 问答系统'作为最合适的分层分类路径。",
      "keywords": [
        "多模态大模型",
        "AIGC视频",
        "视频理解",
        "问答系统",
        "模型评测",
        "反馈生成",
        "基准测试"
      ],
      "methods": [
        "VF-Eval基准测试",
        "多任务评测（连贯性验证、错误感知、错误类型检测、推理评估）",
        "模型对比实验",
        "RePrompt人类反馈对齐实验"
      ],
      "problems": [
        "现有多模态大模型在AI生成视频内容理解与反馈生成方面能力不足",
        "缺乏针对AIGC视频的系统性评测基准",
        "如何提升多模态大模型对AIGC视频的解释和反馈能力"
      ]
    },
    "keywords": [
      "多模态大模型",
      "AIGC视频",
      "视频理解",
      "问答系统",
      "模型评测",
      "反馈生成",
      "基准测试"
    ],
    "methods": [
      "VF-Eval基准测试",
      "多任务评测（连贯性验证、错误感知、错误类型检测、推理评估）",
      "模型对比实验",
      "RePrompt人类反馈对齐实验"
    ],
    "problems": [
      "现有多模态大模型在AI生成视频内容理解与反馈生成方面能力不足",
      "缺乏针对AIGC视频的系统性评测基准",
      "如何提升多模态大模型对AIGC视频的解释和反馈能力"
    ]
  },
  "2505.23091": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 多模态推理",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "多模态推理",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于提升多模态小语言模型（MSLMs）的推理能力，提出了基于课程学习和分阶段强化学习的Infi-MMR框架，主要解决多模态推理任务中的能力提升问题。论文核心在于多模态信息（文本+视觉）的推理能力解锁与提升，属于多模态学习范畴。具体任务为多模态推理，且论文在多模态数学推理和一般推理能力上进行了评测，最贴近'多模态学习 → 问答系统 → 多模态推理'这一分类路径。",
      "keywords": [
        "多模态小语言模型",
        "推理能力",
        "课程学习",
        "分阶段强化学习",
        "多模态推理",
        "Infi-MMR"
      ],
      "methods": [
        "课程式三阶段训练框架",
        "分阶段强化学习",
        "高质量文本推理数据激活",
        "跨模态适应",
        "无caption多模态数据增强"
      ],
      "problems": [
        "多模态小语言模型推理能力弱",
        "高质量多模态推理数据稀缺",
        "视觉处理集成导致推理能力下降",
        "直接强化学习导致推理过程复杂且错误"
      ]
    },
    "keywords": [
      "多模态小语言模型",
      "推理能力",
      "课程学习",
      "分阶段强化学习",
      "多模态推理",
      "Infi-MMR"
    ],
    "methods": [
      "课程式三阶段训练框架",
      "分阶段强化学习",
      "高质量文本推理数据激活",
      "跨模态适应",
      "无caption多模态数据增强"
    ],
    "problems": [
      "多模态小语言模型推理能力弱",
      "高质量多模态推理数据稀缺",
      "视觉处理集成导致推理能力下降",
      "直接强化学习导致推理过程复杂且错误"
    ]
  },
  "2505.23694": {
    "classification_path": "计算机科学 → 计算机视觉 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于视觉Transformer模型的参数高效微调（PEFT），提出了一种基于分布感知和语义引导的视觉提示调优方法（DA-VPT），主要提升在有限参数调整下的下游视觉任务表现。虽然论文在图像识别和分割任务上做了实验，但核心创新点在于提升小样本或参数受限场景下的模型适应能力，属于小样本学习范畴。‘小样本学习’是标准三级领域词表中最贴切的分类。",
      "keywords": [
        "视觉提示调优",
        "参数高效微调",
        "Vision Transformer",
        "分布感知",
        "语义引导",
        "度量学习",
        "图像识别",
        "图像分割"
      ],
      "methods": [
        "分布感知视觉提示调优（DA-VPT）",
        "度量学习引导提示分布",
        "语义信息桥接图像patch与类别token",
        "冻结主干参数，仅微调提示token"
      ],
      "problems": [
        "提示token与图像token之间的分布关系对微调性能的影响",
        "如何利用语义信息优化视觉Transformer的参数高效微调",
        "提升ViT模型在有限参数调整下的下游视觉任务表现"
      ]
    },
    "keywords": [
      "视觉提示调优",
      "参数高效微调",
      "Vision Transformer",
      "分布感知",
      "语义引导",
      "度量学习",
      "图像识别",
      "图像分割"
    ],
    "methods": [
      "分布感知视觉提示调优（DA-VPT）",
      "度量学习引导提示分布",
      "语义信息桥接图像patch与类别token",
      "冻结主干参数，仅微调提示token"
    ],
    "problems": [
      "提示token与图像token之间的分布关系对微调性能的影响",
      "如何利用语义信息优化视觉Transformer的参数高效微调",
      "提升ViT模型在有限参数调整下的下游视觉任务表现"
    ]
  },
  "2505.23094": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注大语言模型的参数高效微调（PEFT），提出了一种新的权重分解方法（MAP），以提升在有限参数更新下的适应能力。虽然论文应用于自然语言处理，但核心贡献在于机器学习领域的模型高效适应与小样本学习方法，因此选择'机器学习'为二级领域，'小样本学习'为三级领域。四级领域暂无更具体标准任务可选，设为null。",
      "keywords": [
        "参数高效微调",
        "低秩适应",
        "权重分解",
        "大语言模型",
        "方向与幅值分离",
        "MAP方法"
      ],
      "methods": [
        "MAP权重分解框架",
        "方向与幅值独立更新",
        "权重归一化",
        "标量系数调节"
      ],
      "problems": [
        "如何在大语言模型中实现高效的参数微调",
        "如何以更有解释性和灵活性的方式分解权重更新",
        "现有方向分解方法缺乏几何基础，如何改进"
      ]
    },
    "keywords": [
      "参数高效微调",
      "低秩适应",
      "权重分解",
      "大语言模型",
      "方向与幅值分离",
      "MAP方法"
    ],
    "methods": [
      "MAP权重分解框架",
      "方向与幅值独立更新",
      "权重归一化",
      "标量系数调节"
    ],
    "problems": [
      "如何在大语言模型中实现高效的参数微调",
      "如何以更有解释性和灵活性的方式分解权重更新",
      "现有方向分解方法缺乏几何基础，如何改进"
    ]
  },
  "2505.23704": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 视觉目标跟踪",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "视觉目标跟踪",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于视觉目标跟踪（VOT）任务，提出了结合视觉与语言信息的跟踪框架。虽然方法涉及多模态学习和大语言模型，但核心任务是提升视觉目标跟踪的鲁棒性和性能，因此归入计算机视觉下的目标检测-视觉目标跟踪最为贴切。",
      "keywords": [
        "视觉目标跟踪",
        "视觉语言模型",
        "多模态融合",
        "文本描述",
        "CLIP",
        "GPT-4V"
      ],
      "methods": [
        "双分支架构（视觉分支与文本分支）",
        "基于VLMs的丰富文本描述生成",
        "视觉与文本特征融合",
        "时序自适应语言建模"
      ],
      "problems": [
        "传统视觉跟踪器在动态外观变化、遮挡和背景干扰下表现不佳",
        "现有视觉语言模型在跟踪任务中缺乏丰富的目标语义文本描述",
        "视觉与文本特征融合机制低效，难以实现目标的整体理解",
        "缺乏对目标外观时序变化的语言建模，导致初始描述与后续视觉变化脱节"
      ]
    },
    "keywords": [
      "视觉目标跟踪",
      "视觉语言模型",
      "多模态融合",
      "文本描述",
      "CLIP",
      "GPT-4V"
    ],
    "methods": [
      "双分支架构（视觉分支与文本分支）",
      "基于VLMs的丰富文本描述生成",
      "视觉与文本特征融合",
      "时序自适应语言建模"
    ],
    "problems": [
      "传统视觉跟踪器在动态外观变化、遮挡和背景干扰下表现不佳",
      "现有视觉语言模型在跟踪任务中缺乏丰富的目标语义文本描述",
      "视觉与文本特征融合机制低效，难以实现目标的整体理解",
      "缺乏对目标外观时序变化的语言建模，导致初始描述与后续视觉变化脱节"
    ]
  },
  "2505.23270": {
    "classification_path": "计算机科学 → 大语言模型 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于大语言模型（LLMs）的知识移除（machine unlearning）及其审计方法，属于大语言模型领域。论文主要研究如何评估和审计生成式大语言模型中的unlearning效果，涉及生成模型的评估与安全性，因此选择'大语言模型'为二级领域，'生成模型'为三级领域。论文未聚焦于问答、对话等具体应用任务，四级领域设为null。",
      "keywords": [
        "大语言模型",
        "机器遗忘",
        "模型审计",
        "生成模型",
        "隐私保护",
        "GDPR",
        "激活扰动"
      ],
      "methods": [
        "基于prompt的审计方法",
        "中间激活扰动技术",
        "多种unlearning算法评估",
        "基准数据集构建"
      ],
      "problems": [
        "如何有效评估大语言模型中的machine unlearning效果",
        "现有unlearning算法在生成式模型中的有效性与鲁棒性",
        "如何设计新的审计方法以克服仅依赖输入输出的局限"
      ]
    },
    "keywords": [
      "大语言模型",
      "机器遗忘",
      "模型审计",
      "生成模型",
      "隐私保护",
      "GDPR",
      "激活扰动"
    ],
    "methods": [
      "基于prompt的审计方法",
      "中间激活扰动技术",
      "多种unlearning算法评估",
      "基准数据集构建"
    ],
    "problems": [
      "如何有效评估大语言模型中的machine unlearning效果",
      "现有unlearning算法在生成式模型中的有效性与鲁棒性",
      "如何设计新的审计方法以克服仅依赖输入输出的局限"
    ]
  },
  "2505.23709": {
    "classification_path": "计算机科学 → 医学图像 → 医学图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "医学图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于皮肤病变的表型分析和分类，核心任务是通过多模态对比学习提升皮肤病变的表征能力，主要应用于皮肤病变的分类和检测。虽然涉及多模态学习，但其主要应用场景和任务属于医学图像领域，且与医学图像分割/分类密切相关。标准领域词表中医学图像下的医学图像分割最为贴切，尽管论文更偏向分类，但医学图像分割已涵盖医学图像分析的主要任务，因此选择该路径。",
      "keywords": [
        "皮肤病变",
        "多模态对比学习",
        "表型分析",
        "预训练",
        "医学图像",
        "元数据",
        "皮肤病变分类"
      ],
      "methods": [
        "嵌套多模态对比学习",
        "图像-元数据联合预训练",
        "SLIMP框架"
      ],
      "problems": [
        "如何结合皮肤病变图像与患者元数据提升皮肤病变分类的准确性",
        "如何通过多模态对比学习捕捉复杂的图像与临床信息关系",
        "如何缓解仅依赖图像时因成像条件变化和缺乏临床上下文导致的分类困难"
      ]
    },
    "keywords": [
      "皮肤病变",
      "多模态对比学习",
      "表型分析",
      "预训练",
      "医学图像",
      "元数据",
      "皮肤病变分类"
    ],
    "methods": [
      "嵌套多模态对比学习",
      "图像-元数据联合预训练",
      "SLIMP框架"
    ],
    "problems": [
      "如何结合皮肤病变图像与患者元数据提升皮肤病变分类的准确性",
      "如何通过多模态对比学习捕捉复杂的图像与临床信息关系",
      "如何缓解仅依赖图像时因成像条件变化和缺乏临床上下文导致的分类困难"
    ]
  },
  "2505.23339": {
    "classification_path": "计算机科学 → 语音与音频处理 → 语音识别",
    "raw_result": {
      "root": "计算机科学",
      "level1": "语音与音频处理",
      "level2": "语音识别",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要介绍了一种用于声学鼻音度（nasalance）测量的开源硬件系统Nosey，属于语音信号的采集与分析范畴。虽然论文没有直接涉及自动语音识别，但其核心任务是对语音信号中的鼻音成分进行定量分析，这与语音识别领域中的语音信号处理和特征提取密切相关。标准领域词表中，'语音与音频处理'下最贴近的三级领域为'语音识别'，因此选择此路径。",
      "keywords": [
        "nasalance",
        "开源硬件",
        "语音信号处理",
        "3D打印",
        "声学测量",
        "Nosey",
        "nasometry"
      ],
      "methods": [
        "开源硬件设计",
        "3D打印定制",
        "声学信号采集",
        "设备对比实验",
        "硬件可定制性测试"
      ],
      "problems": [
        "如何设计一种低成本、可定制的开源硬件系统用于声学鼻音度测量？",
        "Nosey与商业鼻音度设备在测量结果和可用性上有何异同？",
        "如何通过硬件定制优化语音信号采集的准确性和适用性？"
      ]
    },
    "keywords": [
      "nasalance",
      "开源硬件",
      "语音信号处理",
      "3D打印",
      "声学测量",
      "Nosey",
      "nasometry"
    ],
    "methods": [
      "开源硬件设计",
      "3D打印定制",
      "声学信号采集",
      "设备对比实验",
      "硬件可定制性测试"
    ],
    "problems": [
      "如何设计一种低成本、可定制的开源硬件系统用于声学鼻音度测量？",
      "Nosey与商业鼻音度设备在测量结果和可用性上有何异同？",
      "如何通过硬件定制优化语音信号采集的准确性和适用性？"
    ]
  },
  "2505.23716": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 新视角合成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "新视角合成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要关注于从无标定图像集合进行新视角合成，提出了一种前馈网络AnySplat用于3D高斯点云生成和相机参数估计。该任务属于计算机视觉领域中的三维重建，具体聚焦于新视角合成（novel view synthesis），而非传统的三维建模或点云重建，因此选择'三维重建'作为三级领域，'新视角合成'作为四级具体任务。",
      "keywords": [
        "新视角合成",
        "3D高斯点云",
        "前馈网络",
        "无标定视图",
        "神经渲染",
        "相机参数估计"
      ],
      "methods": [
        "前馈神经网络",
        "3D高斯点云生成",
        "端到端相机参数预测",
        "零样本评估"
      ],
      "problems": [
        "如何在无已知相机位姿和无场景优化的情况下实现高质量新视角合成",
        "如何提升无标定多视图数据下的三维重建与渲染效率",
        "如何减少基于神经场的渲染延迟以实现实时新视角合成"
      ]
    },
    "keywords": [
      "新视角合成",
      "3D高斯点云",
      "前馈网络",
      "无标定视图",
      "神经渲染",
      "相机参数估计"
    ],
    "methods": [
      "前馈神经网络",
      "3D高斯点云生成",
      "端到端相机参数预测",
      "零样本评估"
    ],
    "problems": [
      "如何在无已知相机位姿和无场景优化的情况下实现高质量新视角合成",
      "如何提升无标定多视图数据下的三维重建与渲染效率",
      "如何减少基于神经场的渲染延迟以实现实时新视角合成"
    ]
  },
  "2505.23419": {
    "classification_path": "计算机科学 → 大语言模型 → 代码生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "代码生成",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于基于大语言模型（LLMs）自动修复真实世界软件缺陷的基准评测，核心任务是让模型生成代码补丁（patches）以解决GitHub上的实际issue。论文提出了SWE-bench-Live这一新型、可持续更新的代码修复基准，并对多种LLM和agent框架在该任务上的表现进行了系统评测。虽然涉及自然语言处理，但主要任务是代码生成与自动修复，因此选择“大语言模型→代码生成”作为最合适的分类路径。",
      "keywords": [
        "SWE-bench-Live",
        "大语言模型",
        "代码修复",
        "基准评测",
        "自动化数据集构建",
        "GitHub issue",
        "可复现环境",
        "数据污染防控"
      ],
      "methods": [
        "自动化实例构建与环境配置流水线（curation pipeline）",
        "基于Docker的可复现任务环境",
        "多模型基准评测",
        "任务难度与数据新鲜度分析"
      ],
      "problems": [
        "现有代码修复基准数据集覆盖面窄、更新不及时、依赖大量人工，导致可扩展性差和过拟合风险高",
        "如何构建可持续、自动化、覆盖广泛且抗污染的代码修复基准",
        "评估大语言模型在动态、真实世界软件开发环境中的代码修复能力"
      ]
    },
    "keywords": [
      "SWE-bench-Live",
      "大语言模型",
      "代码修复",
      "基准评测",
      "自动化数据集构建",
      "GitHub issue",
      "可复现环境",
      "数据污染防控"
    ],
    "methods": [
      "自动化实例构建与环境配置流水线（curation pipeline）",
      "基于Docker的可复现任务环境",
      "多模型基准评测",
      "任务难度与数据新鲜度分析"
    ],
    "problems": [
      "现有代码修复基准数据集覆盖面窄、更新不及时、依赖大量人工，导致可扩展性差和过拟合风险高",
      "如何构建可持续、自动化、覆盖广泛且抗污染的代码修复基准",
      "评估大语言模型在动态、真实世界软件开发环境中的代码修复能力"
    ]
  },
  "2505.23726": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "小样本学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要关注于在带有噪声标注的数据上提升目标检测的鲁棒性，尤其强调在小样本（few-shot）场景下的表现。其核心贡献是提出了一种结合基础模型（foundation model）和多实例学习（MIL）的方法，用于提升目标检测任务的性能。因此，最合适的分层路径为‘计算机科学 → 计算机视觉 → 目标检测 → 小样本学习’。",
      "keywords": [
        "目标检测",
        "小样本学习",
        "基础模型",
        "多实例学习",
        "噪声标注",
        "鲁棒性"
      ],
      "methods": [
        "多实例学习框架",
        "基础模型引导的标签预处理",
        "检测头结构改进"
      ],
      "problems": [
        "如何在存在噪声标注的情况下提升目标检测模型的鲁棒性",
        "如何在小样本场景下缓解噪声标注对检测性能的影响"
      ]
    },
    "keywords": [
      "目标检测",
      "小样本学习",
      "基础模型",
      "多实例学习",
      "噪声标注",
      "鲁棒性"
    ],
    "methods": [
      "多实例学习框架",
      "基础模型引导的标签预处理",
      "检测头结构改进"
    ],
    "problems": [
      "如何在存在噪声标注的情况下提升目标检测模型的鲁棒性",
      "如何在小样本场景下缓解噪声标注对检测性能的影响"
    ]
  },
  "2505.23442": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要研究知识图谱补全（KGC）中的正则化方法，属于机器学习领域。虽然KGC与自然语言处理相关，但论文核心聚焦于正则化技术对模型泛化能力和性能上限的提升，属于机器学习方法论。论文提出了稀疏正则化（SPR）方法，旨在提升模型在数据稀疏、噪声较多情况下的表现，这与小样本学习中的泛化与鲁棒性问题高度相关。标准领域词表中没有更细致的'知识图谱补全'或'正则化'选项，'小样本学习'最贴合论文关注的泛化与稀疏性问题，因此选择该路径。",
      "keywords": [
        "知识图谱补全",
        "正则化",
        "稀疏正则化",
        "泛化能力",
        "模型性能",
        "选择性稀疏",
        "嵌入向量"
      ],
      "methods": [
        "稀疏正则化方法（SPR）",
        "嵌入向量选择性惩罚",
        "对比实验",
        "经验研究"
      ],
      "problems": [
        "如何通过更有效的正则化方法提升知识图谱补全模型的泛化能力和性能上限？",
        "如何设计正则化方法以减少噪声影响并突出有意义的特征？",
        "现有KGC模型正则化方法的局限性及其改进途径"
      ]
    },
    "keywords": [
      "知识图谱补全",
      "正则化",
      "稀疏正则化",
      "泛化能力",
      "模型性能",
      "选择性稀疏",
      "嵌入向量"
    ],
    "methods": [
      "稀疏正则化方法（SPR）",
      "嵌入向量选择性惩罚",
      "对比实验",
      "经验研究"
    ],
    "problems": [
      "如何通过更有效的正则化方法提升知识图谱补全模型的泛化能力和性能上限？",
      "如何设计正则化方法以减少噪声影响并突出有意义的特征？",
      "现有KGC模型正则化方法的局限性及其改进途径"
    ]
  },
  "2505.23727": {
    "classification_path": "计算机科学 → 计算机视觉 → 图像分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "图像分割",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注于提升图像分割任务中的推理效率和泛化能力，提出了PixelThink方法以调节推理链长度，并引入了新的评测基准ReasonSeg-Diff。虽然涉及多模态和强化学习，但核心任务是图像分割，因此选择'计算机视觉 → 图像分割'作为最合适的分类路径。",
      "keywords": [
        "图像分割",
        "多模态大语言模型",
        "推理链",
        "强化学习",
        "任务难度估计",
        "模型不确定性",
        "ReasonSeg-Diff",
        "推理效率"
      ],
      "methods": [
        "基于任务难度和模型不确定性的推理链调节",
        "强化学习范式",
        "Group-Relative Policy Optimization (GRPO)",
        "ReasonSeg-Diff基准与多维评测指标"
      ],
      "problems": [
        "提升图像分割中的推理效率与泛化能力",
        "解决推理链冗长导致的计算成本高和推理质量不可控问题",
        "实现推理长度与场景复杂度和模型信心的自适应调节"
      ]
    },
    "keywords": [
      "图像分割",
      "多模态大语言模型",
      "推理链",
      "强化学习",
      "任务难度估计",
      "模型不确定性",
      "ReasonSeg-Diff",
      "推理效率"
    ],
    "methods": [
      "基于任务难度和模型不确定性的推理链调节",
      "强化学习范式",
      "Group-Relative Policy Optimization (GRPO)",
      "ReasonSeg-Diff基准与多维评测指标"
    ],
    "problems": [
      "提升图像分割中的推理效率与泛化能力",
      "解决推理链冗长导致的计算成本高和推理质量不可控问题",
      "实现推理长度与场景复杂度和模型信心的自适应调节"
    ]
  },
  "2505.23474": {
    "classification_path": "计算机科学 → 大语言模型 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于Process Reward Models（PRMs）在复杂推理任务中的评测，尤其是针对大语言模型（LLMs）在多步推理和决策过程中的表现。论文提出了一个新的基准（Socratic-PRMBench），系统性地评估PRMs在六种推理模式下的能力。虽然涉及推理和奖励建模，但核心任务是对大语言模型在推理和问答场景下的中间步骤进行系统性评测，最贴近标准领域词表中的“大语言模型→问答系统”。",
      "keywords": [
        "Process Reward Models",
        "Socratic-PRMBench",
        "推理模式",
        "大语言模型",
        "系统性评测",
        "中间步骤验证"
      ],
      "methods": [
        "基准数据集构建",
        "多推理模式覆盖",
        "PRM与LLM评测",
        "错误识别分析"
      ],
      "problems": [
        "现有PRM评测忽略多样推理模式下的系统性评估",
        "PRM在不同推理模式下识别错误能力不足",
        "缺乏覆盖多推理模式的标准化评测基准"
      ]
    },
    "keywords": [
      "Process Reward Models",
      "Socratic-PRMBench",
      "推理模式",
      "大语言模型",
      "系统性评测",
      "中间步骤验证"
    ],
    "methods": [
      "基准数据集构建",
      "多推理模式覆盖",
      "PRM与LLM评测",
      "错误识别分析"
    ],
    "problems": [
      "现有PRM评测忽略多样推理模式下的系统性评估",
      "PRM在不同推理模式下识别错误能力不足",
      "缺乏覆盖多推理模式的标准化评测基准"
    ]
  },
  "2505.23734": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 新视角合成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "新视角合成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于基于3D Gaussian Splatting的前馈式新视角合成方法的可扩展性问题，提出了ZPressor模块以提升多视角输入下的效率和性能。该工作属于计算机视觉领域，具体聚焦于三维重建中的新视角合成任务，因此选择'计算机科学 → 计算机视觉 → 三维重建 → 新视角合成'作为分类路径。",
      "keywords": [
        "3D Gaussian Splatting",
        "新视角合成",
        "信息瓶颈",
        "多视角压缩",
        "前馈模型",
        "三维重建"
      ],
      "methods": [
        "信息瓶颈分析",
        "ZPressor模块",
        "跨注意力机制",
        "多视角输入压缩",
        "锚点-支持集划分"
      ],
      "problems": [
        "如何提升前馈式3DGS模型在多视角输入下的可扩展性",
        "如何在不损失关键信息的前提下高效压缩多视角输入",
        "如何缓解编码器容量受限导致的性能下降或内存消耗过高问题"
      ]
    },
    "keywords": [
      "3D Gaussian Splatting",
      "新视角合成",
      "信息瓶颈",
      "多视角压缩",
      "前馈模型",
      "三维重建"
    ],
    "methods": [
      "信息瓶颈分析",
      "ZPressor模块",
      "跨注意力机制",
      "多视角输入压缩",
      "锚点-支持集划分"
    ],
    "problems": [
      "如何提升前馈式3DGS模型在多视角输入下的可扩展性",
      "如何在不损失关键信息的前提下高效压缩多视角输入",
      "如何缓解编码器容量受限导致的性能下降或内存消耗过高问题"
    ]
  },
  "2505.23500": {
    "classification_path": "计算机科学 → 大语言模型 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文核心在于利用指令微调的大语言模型（LLMs）进行软件元数据的身份解析（identity resolution），属于大语言模型在实际任务中的应用。虽然涉及自然语言处理，但更侧重于大语言模型的实际能力评估和应用。论文任务本质上是对结构化元数据的语义判断与匹配，最贴近标准领域词表中的'问答系统'，因其涉及模型对复杂查询的理解与决策。其他三级领域如'代码生成'、'生成模型'等不符合论文任务，因此选择'大语言模型 → 问答系统'作为最合适的分类路径。",
      "keywords": [
        "大语言模型",
        "软件元数据",
        "身份解析",
        "FAIR原则",
        "生物信息学",
        "OpenEBench",
        "自动化语义判断"
      ],
      "methods": [
        "指令微调大语言模型评估",
        "人工标注金标准对比",
        "高置信度代理机制",
        "多模型基准测试"
      ],
      "problems": [
        "如何利用大语言模型实现跨平台软件元数据的身份解析",
        "如何提升自动化语义判断在FAIR软件元数据整合中的准确性与鲁棒性",
        "如何评估和改进大语言模型在处理结构化元数据时的表现"
      ]
    },
    "keywords": [
      "大语言模型",
      "软件元数据",
      "身份解析",
      "FAIR原则",
      "生物信息学",
      "OpenEBench",
      "自动化语义判断"
    ],
    "methods": [
      "指令微调大语言模型评估",
      "人工标注金标准对比",
      "高置信度代理机制",
      "多模型基准测试"
    ],
    "problems": [
      "如何利用大语言模型实现跨平台软件元数据的身份解析",
      "如何提升自动化语义判断在FAIR软件元数据整合中的准确性与鲁棒性",
      "如何评估和改进大语言模型在处理结构化元数据时的表现"
    ]
  },
  "2505.23537": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于高维数据的张量网络结构搜索（TN-SS），提出了一种结合领域知识和大语言模型（LLM）推理能力的新方法，以减少函数评估次数并提升结构解释性。虽然涉及大语言模型，但其核心任务是优化机器学习中的结构搜索问题，属于机器学习领域。论文强调在有限评估（即小样本）下高效搜索最优结构，因此归入'小样本学习'最为贴切。",
      "keywords": [
        "张量网络",
        "结构搜索",
        "领域知识",
        "大语言模型",
        "高维数据",
        "函数评估",
        "解释性"
      ],
      "methods": [
        "领域感知提示管道",
        "大语言模型推理",
        "结构初始化优化",
        "迭代优化"
      ],
      "problems": [
        "如何高效地在高维数据中搜索最优张量网络结构",
        "如何利用领域知识和大语言模型提升结构搜索效率与解释性",
        "如何减少结构搜索中的函数评估次数"
      ]
    },
    "keywords": [
      "张量网络",
      "结构搜索",
      "领域知识",
      "大语言模型",
      "高维数据",
      "函数评估",
      "解释性"
    ],
    "methods": [
      "领域感知提示管道",
      "大语言模型推理",
      "结构初始化优化",
      "迭代优化"
    ],
    "problems": [
      "如何高效地在高维数据中搜索最优张量网络结构",
      "如何利用领域知识和大语言模型提升结构搜索效率与解释性",
      "如何减少结构搜索中的函数评估次数"
    ]
  },
  "2505.23742": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于基于扩散模型的视频生成，提出了MAGREF框架以提升多主体一致性和生成质量。其核心创新在于引入掩码引导机制和像素级通道拼接，属于生成模型范畴，且明确采用扩散模型方法。虽然涉及多模态输入（图像+文本），但主要任务是高质量视频生成，因此归入计算机视觉-生成模型-扩散模型最为贴切。",
      "keywords": [
        "视频生成",
        "扩散模型",
        "多主体一致性",
        "掩码引导",
        "区域感知动态掩码",
        "像素级通道拼接",
        "高保真合成"
      ],
      "methods": [
        "区域感知动态掩码机制",
        "像素级通道拼接机制",
        "基于扩散模型的视频生成框架"
      ],
      "problems": [
        "如何在多参考主体条件下实现一致且高质量的视频生成",
        "如何提升多主体视频生成中的一致性与可控性",
        "如何在不改变模型结构的前提下灵活处理不同类型主体（人、物体、背景）"
      ]
    },
    "keywords": [
      "视频生成",
      "扩散模型",
      "多主体一致性",
      "掩码引导",
      "区域感知动态掩码",
      "像素级通道拼接",
      "高保真合成"
    ],
    "methods": [
      "区域感知动态掩码机制",
      "像素级通道拼接机制",
      "基于扩散模型的视频生成框架"
    ],
    "problems": [
      "如何在多参考主体条件下实现一致且高质量的视频生成",
      "如何提升多主体视频生成中的一致性与可控性",
      "如何在不改变模型结构的前提下灵活处理不同类型主体（人、物体、背景）"
    ]
  },
  "2505.23564": {
    "classification_path": "计算机科学 → 强化学习 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "强化学习",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "本论文聚焦于大语言模型（LLM）的推理能力提升，核心方法为提出一种新的强化学习（RL）框架Segment Policy Optimization（SPO），用于更有效地进行分段级别的奖励归因。虽然论文涉及大语言模型，但其主要创新点和技术贡献在于强化学习中的奖励归因与策略优化方法，属于强化学习领域。论文具体应用于生成模型（即大语言模型的生成任务），但未聚焦于问答系统、对话系统等具体下游任务，因此选择'生成模型'作为三级领域，四级领域无更细分标准任务，设为null。",
      "keywords": [
        "强化学习",
        "大语言模型",
        "奖励归因",
        "分段策略优化",
        "生成模型",
        "蒙特卡洛估计",
        "链式思维"
      ],
      "methods": [
        "Segment Policy Optimization (SPO)",
        "分段优势估计",
        "概率掩码策略",
        "SPO-chain",
        "SPO-tree"
      ],
      "problems": [
        "如何在大语言模型中实现更精确的奖励归因以提升推理能力",
        "如何在强化学习中平衡奖励信号的粒度与估计准确性",
        "如何减少对准确critic模型的依赖，实现高效的优势估计"
      ]
    },
    "keywords": [
      "强化学习",
      "大语言模型",
      "奖励归因",
      "分段策略优化",
      "生成模型",
      "蒙特卡洛估计",
      "链式思维"
    ],
    "methods": [
      "Segment Policy Optimization (SPO)",
      "分段优势估计",
      "概率掩码策略",
      "SPO-chain",
      "SPO-tree"
    ],
    "problems": [
      "如何在大语言模型中实现更精确的奖励归因以提升推理能力",
      "如何在强化学习中平衡奖励信号的粒度与估计准确性",
      "如何减少对准确critic模型的依赖，实现高效的优势估计"
    ]
  },
  "2505.23743": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文主要关注低光照原始图像增强任务，采用了扩散模型（diffusion models）进行生成式图像增强，并将其与相机ISP流程结合。根据标准领域词表，'计算机视觉'是最合适的二级领域，'生成模型'为三级领域，具体任务为'扩散模型'。虽然论文涉及图像增强，但标准词表中没有更细的图像增强分类，因此选择与方法最直接相关的'扩散模型'作为四级领域。",
      "keywords": [
        "低光照图像增强",
        "原始图像处理",
        "扩散模型",
        "生成模型",
        "相机ISP",
        "图像信号处理",
        "深度学习"
      ],
      "methods": [
        "重定向预训练扩散模型",
        "与相机ISP结合的生成式增强框架",
        "深度神经网络",
        "感知质量评估"
      ],
      "problems": [
        "如何在极低光照条件下提升原始图像的质量",
        "现有回归模型导致低光照图像过度平滑和细节丢失的问题",
        "如何利用扩散模型提升低光照图像的细节恢复和色彩准确性"
      ]
    },
    "keywords": [
      "低光照图像增强",
      "原始图像处理",
      "扩散模型",
      "生成模型",
      "相机ISP",
      "图像信号处理",
      "深度学习"
    ],
    "methods": [
      "重定向预训练扩散模型",
      "与相机ISP结合的生成式增强框架",
      "深度神经网络",
      "感知质量评估"
    ],
    "problems": [
      "如何在极低光照条件下提升原始图像的质量",
      "现有回归模型导致低光照图像过度平滑和细节丢失的问题",
      "如何利用扩散模型提升低光照图像的细节恢复和色彩准确性"
    ]
  },
  "2505.23585": {
    "classification_path": "计算机科学 → 强化学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "强化学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了一种新的强化学习算法（OPO），专注于提升大语言模型的对齐与推理能力，核心创新在于强化学习训练过程的优化和稳定性提升。虽然论文应用于大语言模型，但其主要贡献和方法属于强化学习领域，且强调了训练样本效率和稳定性，因此选择'强化学习'为二级领域，'小样本学习'为三级领域（因其关注训练效率和稳定性）。四级领域暂无更具体标准任务可选，设为null。",
      "keywords": [
        "强化学习",
        "奖励基线",
        "大语言模型",
        "训练稳定性",
        "探索性",
        "数学推理"
      ],
      "methods": [
        "On-Policy RL with Optimal reward baseline (OPO)",
        "最优奖励基线",
        "严格on-policy训练"
      ],
      "problems": [
        "提升强化学习在大语言模型对齐中的训练稳定性",
        "减少训练过程中的梯度方差",
        "提高模型输出的多样性与探索性",
        "避免额外辅助模型带来的计算开销"
      ]
    },
    "keywords": [
      "强化学习",
      "奖励基线",
      "大语言模型",
      "训练稳定性",
      "探索性",
      "数学推理"
    ],
    "methods": [
      "On-Policy RL with Optimal reward baseline (OPO)",
      "最优奖励基线",
      "严格on-policy训练"
    ],
    "problems": [
      "提升强化学习在大语言模型对齐中的训练稳定性",
      "减少训练过程中的梯度方差",
      "提高模型输出的多样性与探索性",
      "避免额外辅助模型带来的计算开销"
    ]
  },
  "2505.23744": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注领域增量学习（Domain Incremental Learning, DIL），属于机器学习中的持续学习/增量学习范畴。论文提出了SOYO框架，旨在提升参数隔离式领域增量学习（PIDIL）的参数选择与领域适应能力。虽然论文在多个任务（如图像分类、目标检测、语音增强）上验证，但核心贡献是提升模型在多领域、动态环境下的持续学习能力，属于机器学习领域下的小样本学习/增量学习方向。标准领域词表中没有专门的‘持续学习’或‘增量学习’，‘小样本学习’最为接近，因其同样关注有限数据下的泛化与适应能力。",
      "keywords": [
        "领域增量学习",
        "参数隔离",
        "参数选择",
        "持续学习",
        "SOYO",
        "高斯混合压缩器",
        "领域特征重采样",
        "多层次特征融合",
        "参数高效微调"
      ],
      "methods": [
        "SOYO框架",
        "高斯混合压缩器（GMC）",
        "领域特征重采样器（DFR）",
        "多层次领域特征融合网络（MDFN）",
        "参数高效微调（PEFT）"
      ],
      "problems": [
        "如何提升参数隔离式领域增量学习中参数选择的准确性",
        "如何在多领域、多类别环境下高效存储与平衡先前领域数据",
        "如何增强模型在动态、复杂环境下的适应性和鲁棒性"
      ]
    },
    "keywords": [
      "领域增量学习",
      "参数隔离",
      "参数选择",
      "持续学习",
      "SOYO",
      "高斯混合压缩器",
      "领域特征重采样",
      "多层次特征融合",
      "参数高效微调"
    ],
    "methods": [
      "SOYO框架",
      "高斯混合压缩器（GMC）",
      "领域特征重采样器（DFR）",
      "多层次领域特征融合网络（MDFN）",
      "参数高效微调（PEFT）"
    ],
    "problems": [
      "如何提升参数隔离式领域增量学习中参数选择的准确性",
      "如何在多领域、多类别环境下高效存储与平衡先前领域数据",
      "如何增强模型在动态、复杂环境下的适应性和鲁棒性"
    ]
  },
  "2505.23745": {
    "classification_path": "计算机科学 → 多模态学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于视觉-语言模型（VLMs）的置信度估计与误分类检测，属于视觉与文本的多模态学习范畴。论文强调VLMs在零样本（zero-shot）和迁移学习场景下的表现，并提出无需重新训练即可提升模型可靠性的框架。标准领域词表中‘多模态学习’最贴切，且论文核心任务为提升模型在小样本/零样本场景下的可靠性，因此选择‘小样本学习’作为三级领域。四级领域暂无更细致标准任务可选，设为null。",
      "keywords": [
        "视觉-语言模型",
        "置信度估计",
        "多模态学习",
        "误分类检测",
        "零样本学习",
        "模型可靠性"
      ],
      "methods": [
        "训练无关置信度评分函数",
        "图像嵌入空间分析",
        "多数据集多架构评测"
      ],
      "problems": [
        "如何判断视觉-语言模型的预测何时值得信任",
        "如何在无需重新训练的情况下提升VLMs的误分类检测能力",
        "如何提高VLMs在安全关键领域的部署可靠性"
      ]
    },
    "keywords": [
      "视觉-语言模型",
      "置信度估计",
      "多模态学习",
      "误分类检测",
      "零样本学习",
      "模型可靠性"
    ],
    "methods": [
      "训练无关置信度评分函数",
      "图像嵌入空间分析",
      "多数据集多架构评测"
    ],
    "problems": [
      "如何判断视觉-语言模型的预测何时值得信任",
      "如何在无需重新训练的情况下提升VLMs的误分类检测能力",
      "如何提高VLMs在安全关键领域的部署可靠性"
    ]
  },
  "2505.23631": {
    "classification_path": "计算机科学 → 人机交互 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "人机交互",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于特殊教育环境下的抑郁评估，强调人类教师的同理心与AI系统的协作，属于以人为中心的AI应用。虽然涉及自然语言处理和多模态融合，但核心创新在于将教师的同理心结构化输入AI系统，提升人机协作的透明度和社会责任。因此，'人机交互'最为贴切。具体任务为基于文本和教师输入的抑郁评估，最接近'问答系统'，因其本质是对学生状态的理解与判别，属于人机交互下的智能问答/评估系统。",
      "keywords": [
        "人类同理心",
        "AI辅助抑郁评估",
        "特殊教育",
        "多模态融合",
        "Empathy Vector",
        "PHQ-9",
        "人机协作",
        "社会责任"
      ],
      "methods": [
        "人类同理心编码（HEAE）框架",
        "教师同理心向量（Empathy Vector）结构化输入",
        "学生叙述文本与教师输入的多模态融合",
        "基于PHQ-9的特征设计",
        "多级分类架构优化"
      ],
      "problems": [
        "如何在特殊教育环境下准确评估学生抑郁程度",
        "如何将教师的同理心和个体化理解结构化并有效融入AI系统",
        "如何提升AI抑郁评估的透明度与社会责任"
      ]
    },
    "keywords": [
      "人类同理心",
      "AI辅助抑郁评估",
      "特殊教育",
      "多模态融合",
      "Empathy Vector",
      "PHQ-9",
      "人机协作",
      "社会责任"
    ],
    "methods": [
      "人类同理心编码（HEAE）框架",
      "教师同理心向量（Empathy Vector）结构化输入",
      "学生叙述文本与教师输入的多模态融合",
      "基于PHQ-9的特征设计",
      "多级分类架构优化"
    ],
    "problems": [
      "如何在特殊教育环境下准确评估学生抑郁程度",
      "如何将教师的同理心和个体化理解结构化并有效融入AI系统",
      "如何提升AI抑郁评估的透明度与社会责任"
    ]
  },
  "2505.23747": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解 → 空间关系推理",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": "空间关系推理",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于提升多模态大模型（MLLM）在基于视觉的空间智能与空间推理能力，核心任务是从2D视觉输入（如图片、视频）中进行空间关系理解与推理。虽然涉及多模态和大语言模型，但主要贡献在于视觉空间推理，且方法和实验均以视频/图像为输入，属于计算机视觉下的视频理解范畴，具体任务为空间关系推理。",
      "keywords": [
        "多模态大模型",
        "空间智能",
        "空间推理",
        "2D视觉",
        "视频理解",
        "结构先验",
        "空间感知"
      ],
      "methods": [
        "双编码器架构（语义编码器+空间编码器）",
        "视觉几何基础模型",
        "空间感知帧采样策略",
        "特征融合连接器",
        "监督微调",
        "GRPO训练"
      ],
      "problems": [
        "如何在仅有2D视觉输入的情况下提升MLLM的空间推理能力",
        "如何融合语义与空间结构特征以增强空间理解",
        "如何在有限token长度下选择最具空间信息的视频帧"
      ]
    },
    "keywords": [
      "多模态大模型",
      "空间智能",
      "空间推理",
      "2D视觉",
      "视频理解",
      "结构先验",
      "空间感知"
    ],
    "methods": [
      "双编码器架构（语义编码器+空间编码器）",
      "视觉几何基础模型",
      "空间感知帧采样策略",
      "特征融合连接器",
      "监督微调",
      "GRPO训练"
    ],
    "problems": [
      "如何在仅有2D视觉输入的情况下提升MLLM的空间推理能力",
      "如何融合语义与空间结构特征以增强空间理解",
      "如何在有限token长度下选择最具空间信息的视频帧"
    ]
  },
  "2505.23671": {
    "classification_path": "计算机科学 → 大语言模型 → 代码生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "大语言模型",
      "level2": "代码生成",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注基于大语言模型的SWE-Agent在高性能软件优化任务中的能力评测，核心任务是让智能体基于代码库和性能测试进行代码优化，属于大语言模型在代码生成领域的应用。虽然涉及性能优化和自动化评测，但最贴切的标准分类是'大语言模型 → 代码生成'，没有更细的标准四级任务，因此level3为null。",
      "keywords": [
        "软件优化",
        "基准测试",
        "大语言模型",
        "SWE-Agent",
        "代码生成",
        "性能测试",
        "自动化评测"
      ],
      "methods": [
        "自动化性能测试流水线",
        "代码库提交历史分析",
        "基于大语言模型的智能体优化",
        "定量与定性评估"
      ],
      "problems": [
        "如何评估大语言模型在高性能软件优化任务中的能力？",
        "当前SWE-Agent在实际软件优化任务中存在哪些主要瓶颈和失败模式？",
        "如何构建覆盖多领域、多语言的高难度软件优化基准？"
      ]
    },
    "keywords": [
      "软件优化",
      "基准测试",
      "大语言模型",
      "SWE-Agent",
      "代码生成",
      "性能测试",
      "自动化评测"
    ],
    "methods": [
      "自动化性能测试流水线",
      "代码库提交历史分析",
      "基于大语言模型的智能体优化",
      "定量与定性评估"
    ],
    "problems": [
      "如何评估大语言模型在高性能软件优化任务中的能力？",
      "当前SWE-Agent在实际软件优化任务中存在哪些主要瓶颈和失败模式？",
      "如何构建覆盖多领域、多语言的高难度软件优化基准？"
    ]
  },
  "2505.23752": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注遥感任务中的空间推理与工具增强型大语言模型代理的评估。虽然涉及多模态和大语言模型，但核心任务是基于遥感影像（卫星或航空图像）进行复杂场景分析，如城市规划、灾害评估、环境监测等，这些均属于计算机视觉领域下的遥感图像分析。标准领域词表中没有专门的‘遥感’或‘遥感图像分析’，但这些任务通常归入‘目标检测’等视觉任务范畴。论文并未聚焦于分割、三维重建等具体视觉任务，因此选择‘目标检测’作为最贴近的三级领域，四级领域留空。",
      "keywords": [
        "遥感",
        "工具增强型代理",
        "大语言模型",
        "空间推理",
        "多步规划",
        "基准评测",
        "卫星影像",
        "任务规划"
      ],
      "methods": [
        "ReAct-style交互循环",
        "多步推理",
        "工具集成",
        "结构化任务评测",
        "人类策划查询"
      ],
      "problems": [
        "如何评估大语言模型驱动的工具增强型代理在遥感任务中的表现",
        "现有评测缺乏针对复杂遥感任务的工具使用能力基准",
        "不同模型在工具准确性和规划一致性上的差异"
      ]
    },
    "keywords": [
      "遥感",
      "工具增强型代理",
      "大语言模型",
      "空间推理",
      "多步规划",
      "基准评测",
      "卫星影像",
      "任务规划"
    ],
    "methods": [
      "ReAct-style交互循环",
      "多步推理",
      "工具集成",
      "结构化任务评测",
      "人类策划查询"
    ],
    "problems": [
      "如何评估大语言模型驱动的工具增强型代理在遥感任务中的表现",
      "现有评测缺乏针对复杂遥感任务的工具使用能力基准",
      "不同模型在工具准确性和规划一致性上的差异"
    ]
  },
  "2505.23756": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 三维目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "三维重建",
      "level3": "三维目标检测",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究在无已知相机位姿的情况下，通过对象为中心的三维包围盒匹配，实现室内场景的三维目标检测、定位与建图。其核心任务是基于图像集合进行三维目标检测与三维场景重建，属于计算机视觉领域下的三维重建方向，具体聚焦于三维目标检测任务。",
      "keywords": [
        "三维目标检测",
        "室内场景",
        "结构光束法（Structure-from-Motion）",
        "三维包围盒",
        "相机位姿估计",
        "对象为中心",
        "三维建图"
      ],
      "methods": [
        "对象为中心的三维包围盒匹配",
        "基于图像的三维目标检测",
        "无已知相机位姿的结构光束法替代",
        "全局三维包围盒优化"
      ],
      "problems": [
        "如何在无已知相机位姿的情况下实现室内三维目标检测与建图",
        "如何通过对象为中心的三维包围盒匹配替代传统的2D关键点匹配",
        "如何提升三维目标检测与建图的精度和稀疏性"
      ]
    },
    "keywords": [
      "三维目标检测",
      "室内场景",
      "结构光束法（Structure-from-Motion）",
      "三维包围盒",
      "相机位姿估计",
      "对象为中心",
      "三维建图"
    ],
    "methods": [
      "对象为中心的三维包围盒匹配",
      "基于图像的三维目标检测",
      "无已知相机位姿的结构光束法替代",
      "全局三维包围盒优化"
    ],
    "problems": [
      "如何在无已知相机位姿的情况下实现室内三维目标检测与建图",
      "如何通过对象为中心的三维包围盒匹配替代传统的2D关键点匹配",
      "如何提升三维目标检测与建图的精度和稀疏性"
    ]
  },
  "2505.23761": {
    "classification_path": "计算机科学 → 机器学习 → 生成模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "生成模型",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注语言模型的偏好优化（preference optimization）理论基础，提出了差分信息分布（DID）来解释Direct Preference Optimization (DPO)的最优性，并分析了偏好数据结构与策略行为的关系。虽然涉及大语言模型和自然语言处理，但核心贡献在于对生成模型（如语言模型）偏好优化目标的理论解释和方法创新，属于生成模型理论与优化方法的研究，因此归入‘机器学习 → 生成模型’。",
      "keywords": [
        "Direct Preference Optimization",
        "Differential Information Distribution",
        "偏好优化",
        "信息论",
        "语言模型对齐",
        "log-ratio reward",
        "熵分析"
      ],
      "methods": [
        "差分信息分布建模",
        "理论分析与推导",
        "log-ratio reward参数化",
        "熵分析",
        "合成与真实数据实验验证"
      ],
      "problems": [
        "DPO中log-ratio reward参数化的理论基础是什么？",
        "偏好标签如何编码差分信息以优化生成策略？",
        "偏好数据结构与策略分布行为之间的关系如何？",
        "高/低熵差分信息对生成模型行为有何影响？"
      ]
    },
    "keywords": [
      "Direct Preference Optimization",
      "Differential Information Distribution",
      "偏好优化",
      "信息论",
      "语言模型对齐",
      "log-ratio reward",
      "熵分析"
    ],
    "methods": [
      "差分信息分布建模",
      "理论分析与推导",
      "log-ratio reward参数化",
      "熵分析",
      "合成与真实数据实验验证"
    ],
    "problems": [
      "DPO中log-ratio reward参数化的理论基础是什么？",
      "偏好标签如何编码差分信息以优化生成策略？",
      "偏好数据结构与策略分布行为之间的关系如何？",
      "高/低熵差分信息对生成模型行为有何影响？"
    ]
  },
  "2505.23757": {
    "classification_path": "计算机科学 → 多模态学习 → 视频理解 → null",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "视频理解",
      "level3": "null",
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于视觉-语言-动作（VLA）模型在自动驾驶场景下的应用，核心贡献为构建了一个大规模多模态视频数据集，并通过问答和动作轨迹标注提升模型在感知、预测和规划等多模态任务上的表现。论文强调视频、语言、动作三模态的结合，属于多模态学习范畴；具体任务为自动驾驶场景下的视频理解与推理，因此选择'多模态学习→视频理解'作为最合适的分类路径。",
      "keywords": [
        "视觉-语言-动作模型",
        "自动驾驶",
        "多模态学习",
        "视频理解",
        "数据集",
        "问答标注",
        "动作轨迹"
      ],
      "methods": [
        "大规模多模态数据集构建",
        "视频剪辑筛选与标注",
        "规划导向问答标注",
        "动作轨迹标注",
        "基于数据集的VLA模型训练与评测"
      ],
      "problems": [
        "现有自动驾驶VLA模型在非结构化场景下表现不佳，缺乏针对性基准数据",
        "如何构建覆盖多样非结构化场景的多模态视频数据集",
        "如何通过问答和动作轨迹标注提升VLA模型在感知、预测和规划等任务上的能力"
      ]
    },
    "keywords": [
      "视觉-语言-动作模型",
      "自动驾驶",
      "多模态学习",
      "视频理解",
      "数据集",
      "问答标注",
      "动作轨迹"
    ],
    "methods": [
      "大规模多模态数据集构建",
      "视频剪辑筛选与标注",
      "规划导向问答标注",
      "动作轨迹标注",
      "基于数据集的VLA模型训练与评测"
    ],
    "problems": [
      "现有自动驾驶VLA模型在非结构化场景下表现不佳，缺乏针对性基准数据",
      "如何构建覆盖多样非结构化场景的多模态视频数据集",
      "如何通过问答和动作轨迹标注提升VLA模型在感知、预测和规划等任务上的能力"
    ]
  },
  "2505.23762": {
    "classification_path": "计算机科学 → 强化学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "强化学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文提出了ZeroGUI框架，通过在线强化学习和大规模视觉-语言模型实现了无需人工标注的GUI Agent自动训练。其核心创新在于利用VLM进行自动任务生成和奖励估计，并采用两阶段在线强化学习方法，显著减少了人工成本并提升了适应性。论文强调了在极少或零人工标注下的学习能力，属于强化学习领域下的小样本学习方向。虽然涉及多模态和人机交互，但主要研究范式和创新点集中在强化学习与小样本学习的结合。",
      "keywords": [
        "GUI Agent",
        "零样本学习",
        "在线强化学习",
        "视觉-语言模型",
        "自动任务生成",
        "自动奖励估计"
      ],
      "methods": [
        "VLM自动任务生成",
        "VLM自动奖励估计",
        "两阶段在线强化学习"
      ],
      "problems": [
        "如何在无需人工标注的情况下自动训练GUI Agent",
        "如何提升GUI Agent对动态和交互式环境的适应能力",
        "如何利用视觉-语言模型实现任务生成与奖励估计"
      ]
    },
    "keywords": [
      "GUI Agent",
      "零样本学习",
      "在线强化学习",
      "视觉-语言模型",
      "自动任务生成",
      "自动奖励估计"
    ],
    "methods": [
      "VLM自动任务生成",
      "VLM自动奖励估计",
      "两阶段在线强化学习"
    ],
    "problems": [
      "如何在无需人工标注的情况下自动训练GUI Agent",
      "如何提升GUI Agent对动态和交互式环境的适应能力",
      "如何利用视觉-语言模型实现任务生成与奖励估计"
    ]
  },
  "2505.23758": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于基于LoRA的多概念图像生成与编辑，核心方法为无训练的扩散模型（Flux-style diffusion transformers）与特征分离掩码，属于计算机视觉领域下的生成模型，具体任务为扩散模型的图像生成与编辑。",
      "keywords": [
        "LoRA",
        "多概念图像编辑",
        "扩散模型",
        "Transformer",
        "特征分离",
        "无训练",
        "图像生成"
      ],
      "methods": [
        "基于特征分离的掩码生成",
        "局部LoRA权重融合",
        "Flux-style扩散Transformer",
        "训练自由的多概念编辑"
      ],
      "problems": [
        "如何在无需重新训练的情况下实现多概念图像生成与编辑",
        "如何在扩散模型中实现概念分离与局部编辑",
        "如何提升多主体/多风格图像编辑的身份保持与细节保留"
      ]
    },
    "keywords": [
      "LoRA",
      "多概念图像编辑",
      "扩散模型",
      "Transformer",
      "特征分离",
      "无训练",
      "图像生成"
    ],
    "methods": [
      "基于特征分离的掩码生成",
      "局部LoRA权重融合",
      "Flux-style扩散Transformer",
      "训练自由的多概念编辑"
    ],
    "problems": [
      "如何在无需重新训练的情况下实现多概念图像生成与编辑",
      "如何在扩散模型中实现概念分离与局部编辑",
      "如何提升多主体/多风格图像编辑的身份保持与细节保留"
    ]
  },
  "2505.23764": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统 → 视觉问答",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": "视觉问答",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文提出了一个针对多图像空间推理的视觉问答基准（MMSI-Bench），主要评测多模态大语言模型在多图像空间智能任务上的表现。论文核心任务为多模态（图像+文本）下的问答系统，且聚焦于视觉问答（VQA）这一具体应用，因此选择'多模态学习 → 问答系统 → 视觉问答'作为最合适的分层分类路径。",
      "keywords": [
        "多模态大语言模型",
        "空间智能",
        "视觉问答",
        "多图像推理",
        "基准测试",
        "空间推理",
        "错误分析"
      ],
      "methods": [
        "多图像视觉问答基准设计",
        "多项选择题构建",
        "逐步推理过程标注",
        "自动化错误分析管道"
      ],
      "problems": [
        "现有基准无法评估多图像空间推理能力",
        "多模态大语言模型在多图像空间智能任务上的表现有限",
        "分析并诊断多模态模型在空间推理中的主要失败模式"
      ]
    },
    "keywords": [
      "多模态大语言模型",
      "空间智能",
      "视觉问答",
      "多图像推理",
      "基准测试",
      "空间推理",
      "错误分析"
    ],
    "methods": [
      "多图像视觉问答基准设计",
      "多项选择题构建",
      "逐步推理过程标注",
      "自动化错误分析管道"
    ],
    "problems": [
      "现有基准无法评估多图像空间推理能力",
      "多模态大语言模型在多图像空间智能任务上的表现有限",
      "分析并诊断多模态模型在空间推理中的主要失败模式"
    ]
  },
  "2505.23763": {
    "classification_path": "计算机科学 → 计算机视觉 → 小样本学习 → 细粒度图像检索",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "小样本学习",
      "level3": "细粒度图像检索",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于高效网络在手绘草图（sketch）数据上的适配与推理，具体以细粒度草图图像检索（FG-SBIR）为主要应用场景。论文提出了针对草图的高效模型设计，包括跨模态知识蒸馏和基于强化学习的动态抽象选择器，旨在大幅降低FLOPs和参数量。由于FG-SBIR属于细粒度图像检索任务，且论文强调模型在小样本、稀疏数据（草图）上的高效适配，因此选择'计算机视觉 → 小样本学习 → 细粒度图像检索'作为最合适的分层分类路径。",
      "keywords": [
        "高效网络",
        "草图识别",
        "细粒度图像检索",
        "知识蒸馏",
        "跨模态",
        "强化学习",
        "FLOPs",
        "模型压缩"
      ],
      "methods": [
        "跨模态知识蒸馏网络",
        "基于强化学习的画布选择器",
        "高效网络适配"
      ],
      "problems": [
        "现有高效视觉模型无法直接适用于草图数据",
        "如何大幅降低草图检索模型的FLOPs和参数量",
        "如何在保持准确率的同时实现草图数据的高效推理"
      ]
    },
    "keywords": [
      "高效网络",
      "草图识别",
      "细粒度图像检索",
      "知识蒸馏",
      "跨模态",
      "强化学习",
      "FLOPs",
      "模型压缩"
    ],
    "methods": [
      "跨模态知识蒸馏网络",
      "基于强化学习的画布选择器",
      "高效网络适配"
    ],
    "problems": [
      "现有高效视觉模型无法直接适用于草图数据",
      "如何大幅降低草图检索模型的FLOPs和参数量",
      "如何在保持准确率的同时实现草图数据的高效推理"
    ]
  },
  "2505.23766": {
    "classification_path": "计算机科学 → 多模态学习 → 问答系统",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "问答系统",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文聚焦于多模态大模型（MLLMs）在视觉-语言推理任务中的能力提升，提出了基于视觉注意力的链式推理机制，主要解决视觉中心场景下的多模态推理与目标指代问题。虽然涉及视觉对象定位，但核心贡献在于多模态推理与问答能力的提升，因此选择'多模态学习'为二级领域，'问答系统'为三级领域，四级领域暂无更细分标准任务。",
      "keywords": [
        "多模态大模型",
        "视觉-语言推理",
        "视觉注意力",
        "对象指代",
        "链式推理",
        "视觉区域关注"
      ],
      "methods": [
        "视觉注意力定位机制",
        "对象中心化链式推理",
        "显式语言引导视觉区域关注"
      ],
      "problems": [
        "提升多模态大模型在视觉中心推理场景下的准确性",
        "实现更有效的目标指代与视觉区域定位",
        "增强多模态推理中的视觉关注与语言协同能力"
      ]
    },
    "keywords": [
      "多模态大模型",
      "视觉-语言推理",
      "视觉注意力",
      "对象指代",
      "链式推理",
      "视觉区域关注"
    ],
    "methods": [
      "视觉注意力定位机制",
      "对象中心化链式推理",
      "显式语言引导视觉区域关注"
    ],
    "problems": [
      "提升多模态大模型在视觉中心推理场景下的准确性",
      "实现更有效的目标指代与视觉区域定位",
      "增强多模态推理中的视觉关注与语言协同能力"
    ]
  },
  "2505.23769": {
    "classification_path": "计算机科学 → 计算机视觉 → 图像分割 → 语义分割",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "图像分割",
      "level3": "语义分割",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文提出了一种结合图像-文本模型与分割模型（如SAM2）的方法，旨在提升细粒度视觉理解能力，并应用于开放世界语义分割、指代表达理解和视觉定位等任务。核心贡献在于生成与文本对齐的区域token，直接服务于语义分割等下游任务。根据标准领域词表，'图像分割'最为贴切，具体任务为'语义分割'，因此选择该分类路径。",
      "keywords": [
        "图像-文本模型",
        "区域token",
        "语义分割",
        "开放词汇",
        "SAM2",
        "视觉理解",
        "文本对齐"
      ],
      "methods": [
        "无训练框架",
        "结合冻结图像-文本模型与分割模型",
        "生成文本对齐的区域token"
      ],
      "problems": [
        "如何提升图像-文本模型在细粒度视觉理解任务中的表现",
        "如何在无需训练的情况下实现开放词汇的语义分割与视觉定位",
        "如何将文本语义与空间区域精确对齐以支持下游视觉任务"
      ]
    },
    "keywords": [
      "图像-文本模型",
      "区域token",
      "语义分割",
      "开放词汇",
      "SAM2",
      "视觉理解",
      "文本对齐"
    ],
    "methods": [
      "无训练框架",
      "结合冻结图像-文本模型与分割模型",
      "生成文本对齐的区域token"
    ],
    "problems": [
      "如何提升图像-文本模型在细粒度视觉理解任务中的表现",
      "如何在无需训练的情况下实现开放词汇的语义分割与视觉定位",
      "如何将文本语义与空间区域精确对齐以支持下游视觉任务"
    ]
  },
  "2505.22673": {
    "classification_path": "计算机科学 → 医学图像 → 生成模型 → 医学影像生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "生成模型",
      "level3": "医学影像生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要聚焦于通过生成式深度学习方法（MAGIC框架）将非增强CT影像映射为无对比剂的CT灌注图像，属于医学图像领域。其核心任务是医学影像的生成（contrast-free CT perfusion maps），并结合生理信息提升生成质量，因此选择'医学图像→生成模型→医学影像生成'作为最合适的分层分类路径。",
      "keywords": [
        "CT灌注成像",
        "生成模型",
        "多任务学习",
        "生理信息融合",
        "无对比剂成像",
        "深度学习",
        "脑卒中",
        "医学影像"
      ],
      "methods": [
        "生成式深度学习框架（MAGIC）",
        "多任务学习",
        "生理信息嵌入损失函数",
        "对比实验与双盲评估"
      ],
      "problems": [
        "如何在无需对比剂的情况下生成高质量的CT灌注参数图像",
        "如何融合生理信息提升生成医学影像的真实性与诊断价值",
        "如何降低对比剂带来的副作用和医疗成本"
      ]
    },
    "keywords": [
      "CT灌注成像",
      "生成模型",
      "多任务学习",
      "生理信息融合",
      "无对比剂成像",
      "深度学习",
      "脑卒中",
      "医学影像"
    ],
    "methods": [
      "生成式深度学习框架（MAGIC）",
      "多任务学习",
      "生理信息嵌入损失函数",
      "对比实验与双盲评估"
    ],
    "problems": [
      "如何在无需对比剂的情况下生成高质量的CT灌注参数图像",
      "如何融合生理信息提升生成医学影像的真实性与诊断价值",
      "如何降低对比剂带来的副作用和医疗成本"
    ]
  },
  "2505.22682": {
    "classification_path": "计算机科学 → 医学图像 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究基于文本提示的MRI医学图像生成，核心方法为Stable Diffusion（扩散模型），并应用于医学影像领域。虽然涉及多模态（文本到图像），但主要贡献在于医学图像的生成与增强，因此选择'医学图像'作为二级领域，'生成模型'为三级领域，具体任务为'扩散模型'。论文未聚焦于分割、检测等下游任务，故不选医学图像分割等方向。",
      "keywords": [
        "MRI图像生成",
        "文本提示",
        "Stable Diffusion",
        "医学影像合成",
        "数据增强",
        "多磁场强度",
        "FID",
        "MS-SSIM"
      ],
      "methods": [
        "Stable Diffusion模型微调",
        "基于文本的图像生成",
        "定量指标评估（FID, MS-SSIM）",
        "小样本分类实验"
      ],
      "problems": [
        "如何利用文本提示生成高质量的MRI医学图像以缓解真实数据获取难题",
        "如何提升生成医学图像的语义一致性和图像质量",
        "生成的合成MRI图像能否有效增强下游医学AI任务的数据集"
      ]
    },
    "keywords": [
      "MRI图像生成",
      "文本提示",
      "Stable Diffusion",
      "医学影像合成",
      "数据增强",
      "多磁场强度",
      "FID",
      "MS-SSIM"
    ],
    "methods": [
      "Stable Diffusion模型微调",
      "基于文本的图像生成",
      "定量指标评估（FID, MS-SSIM）",
      "小样本分类实验"
    ],
    "problems": [
      "如何利用文本提示生成高质量的MRI医学图像以缓解真实数据获取难题",
      "如何提升生成医学图像的语义一致性和图像质量",
      "生成的合成MRI图像能否有效增强下游医学AI任务的数据集"
    ]
  },
  "2505.22683": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 脑网络构建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "三维重建",
      "level3": "脑网络构建",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于从DTI（弥散张量成像）自动构建脑结构网络，属于医学影像领域。其核心任务是基于三维医学影像数据实现脑网络的自动化重建，涉及生成模型和图神经网络，但主要应用场景和创新点在于医学图像的三维重建与脑网络分析，因此选择'医学图像→三维重建→脑网络构建'作为最合适的分层分类路径。",
      "keywords": [
        "脑网络构建",
        "弥散张量成像",
        "生成模型",
        "图卷积网络",
        "神经退行性疾病",
        "阿尔茨海默病",
        "结构连接组",
        "自动化"
      ],
      "methods": [
        "Riemannian几何特征提取",
        "扩散生成模型",
        "图卷积网络分类器",
        "端到端自动化流程"
      ],
      "problems": [
        "现有DTI脑网络构建方法主观性强、流程繁琐、难以捕捉复杂拓扑和疾病特异性生物标志物",
        "如何实现自动化、高保真度的脑结构网络重建",
        "如何提升神经退行性疾病（如阿尔茨海默病）诊断的敏感性和准确性"
      ]
    },
    "keywords": [
      "脑网络构建",
      "弥散张量成像",
      "生成模型",
      "图卷积网络",
      "神经退行性疾病",
      "阿尔茨海默病",
      "结构连接组",
      "自动化"
    ],
    "methods": [
      "Riemannian几何特征提取",
      "扩散生成模型",
      "图卷积网络分类器",
      "端到端自动化流程"
    ],
    "problems": [
      "现有DTI脑网络构建方法主观性强、流程繁琐、难以捕捉复杂拓扑和疾病特异性生物标志物",
      "如何实现自动化、高保真度的脑结构网络重建",
      "如何提升神经退行性疾病（如阿尔茨海默病）诊断的敏感性和准确性"
    ]
  },
  "2505.22685": {
    "classification_path": "计算机科学 → 计算机视觉 → 三维重建 → 脑结构连接组预测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "三维重建",
      "level3": "脑结构连接组预测",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于从扩散MRI数据直接预测脑结构连接组（connectome），属于医学影像领域。其核心任务是利用深度学习方法对三维脑部结构进行重建和连接预测，绕过传统的灰质分区流程，提升大规模研究的效率。虽然涉及点云神经网络和多任务学习，但主要贡献在于医学图像领域下的三维重建与脑连接组预测，因此选择‘医学图像 → 三维重建 → 脑结构连接组预测’作为最合适的分层分类。",
      "keywords": [
        "结构连接组",
        "扩散MRI",
        "深度学习",
        "多任务学习",
        "点云神经网络",
        "脑网络",
        "灰质分区",
        "脑成像"
      ],
      "methods": [
        "点云神经网络",
        "多任务学习",
        "深度学习模型",
        "结构连接组预测",
        "大规模数据训练"
      ],
      "problems": [
        "如何高效、准确地从扩散MRI纤维追踪数据直接预测结构连接组，避免传统灰质分区流程的低效与复杂性",
        "如何支持多种脑区分区方案下的连接组预测",
        "如何提升结构连接组生成的速度与可扩展性以适应大规模脑影像研究"
      ]
    },
    "keywords": [
      "结构连接组",
      "扩散MRI",
      "深度学习",
      "多任务学习",
      "点云神经网络",
      "脑网络",
      "灰质分区",
      "脑成像"
    ],
    "methods": [
      "点云神经网络",
      "多任务学习",
      "深度学习模型",
      "结构连接组预测",
      "大规模数据训练"
    ],
    "problems": [
      "如何高效、准确地从扩散MRI纤维追踪数据直接预测结构连接组，避免传统灰质分区流程的低效与复杂性",
      "如何支持多种脑区分区方案下的连接组预测",
      "如何提升结构连接组生成的速度与可扩展性以适应大规模脑影像研究"
    ]
  },
  "2505.22764": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要研究如何通过测试时增强（test-time augmentation, TTA）提升保形预测（conformal prediction）的效率，减少预测集的大小。保形预测是一种为分类任务提供置信集的方法，属于机器学习领域。TTA作为一种提升泛化能力和鲁棒性的技术，常用于小样本或分布外数据场景。虽然论文在多个数据集和模型上实验，但核心贡献是提升保形预测在有限样本或分布变化下的表现，因此归入‘机器学习→小样本学习’最为贴切。",
      "keywords": [
        "保形预测",
        "测试时增强",
        "置信集",
        "分类器",
        "分布外泛化"
      ],
      "methods": [
        "测试时增强（Test-time augmentation, TTA）",
        "保形评分方法",
        "无须重训练的推理增强"
      ],
      "problems": [
        "如何减少保形预测产生的置信集大小，提高其信息性和实用性",
        "如何在无需模型重训练的情况下提升保形预测的效率和泛化能力",
        "如何在不同分布和模型下保证保形预测的有效性"
      ]
    },
    "keywords": [
      "保形预测",
      "测试时增强",
      "置信集",
      "分类器",
      "分布外泛化"
    ],
    "methods": [
      "测试时增强（Test-time augmentation, TTA）",
      "保形评分方法",
      "无须重训练的推理增强"
    ],
    "problems": [
      "如何减少保形预测产生的置信集大小，提高其信息性和实用性",
      "如何在无需模型重训练的情况下提升保形预测的效率和泛化能力",
      "如何在不同分布和模型下保证保形预测的有效性"
    ]
  },
  "2505.22769": {
    "classification_path": "计算机科学 → 人机交互 → 三维重建 → 视线追踪",
    "raw_result": {
      "root": "计算机科学",
      "level1": "人机交互",
      "level2": "三维重建",
      "level3": "视线追踪",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "本论文聚焦于移动设备上的视线追踪（gaze tracking），其核心挑战是用户姿态和设备朝向变化导致的追踪精度下降。论文提出了一种结合IMU传感器与视觉模型的持续校准方法，属于典型的人机交互（HCI）领域中的视线追踪应用。虽然涉及多模态学习和计算机视觉，但主要贡献和应用场景是提升移动端人机交互体验，因此归入‘人机交互’。‘三维重建’下的‘视线追踪’是最贴切的具体任务。",
      "keywords": [
        "移动视线追踪",
        "持续校准",
        "IMU传感器",
        "人机交互",
        "多模态学习",
        "灾难性遗忘",
        "活动识别"
      ],
      "methods": [
        "基于IMU的活动识别",
        "预训练视觉视线估计器",
        "聚类混合决策机制",
        "重放式持续学习"
      ],
      "problems": [
        "如何在用户姿态和设备朝向动态变化下保持移动端视线追踪的高精度？",
        "如何自动检测用户运动状态变化并触发模型再校准？",
        "如何在持续学习新运动条件时避免灾难性遗忘，保证模型在历史状态下的性能？"
      ]
    },
    "keywords": [
      "移动视线追踪",
      "持续校准",
      "IMU传感器",
      "人机交互",
      "多模态学习",
      "灾难性遗忘",
      "活动识别"
    ],
    "methods": [
      "基于IMU的活动识别",
      "预训练视觉视线估计器",
      "聚类混合决策机制",
      "重放式持续学习"
    ],
    "problems": [
      "如何在用户姿态和设备朝向动态变化下保持移动端视线追踪的高精度？",
      "如何自动检测用户运动状态变化并触发模型再校准？",
      "如何在持续学习新运动条件时避免灾难性遗忘，保证模型在历史状态下的性能？"
    ]
  },
  "2505.22805": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于利用生成扩散模型进行像素级异常检测，主要应用于机器人越野导航场景。其核心方法是通过扩散模型对输入图像进行编辑以去除异常，并分析被修改的区域实现异常检测。该方法属于计算机视觉领域，具体为生成模型中的扩散模型应用，因此选择'计算机视觉 → 生成模型 → 扩散模型'作为分类路径。",
      "keywords": [
        "异常检测",
        "扩散模型",
        "生成模型",
        "越野导航",
        "像素级分析",
        "机器人",
        "分析-合成方法",
        "视觉-语言基础模型"
      ],
      "methods": [
        "基于生成扩散模型的图像编辑",
        "像素级异常检测",
        "分析-合成（analysis-by-synthesis）方法",
        "引导扩散推理与梯度近似",
        "利用视觉-语言基础模型进行特征空间对比"
      ],
      "problems": [
        "如何在越野和非结构化环境中实现机器人对分布外异常的检测",
        "如何在无需对异常类型做假设的情况下进行像素级异常检测",
        "如何在不重新训练或微调的前提下集成异常检测方法到现有工作流"
      ]
    },
    "keywords": [
      "异常检测",
      "扩散模型",
      "生成模型",
      "越野导航",
      "像素级分析",
      "机器人",
      "分析-合成方法",
      "视觉-语言基础模型"
    ],
    "methods": [
      "基于生成扩散模型的图像编辑",
      "像素级异常检测",
      "分析-合成（analysis-by-synthesis）方法",
      "引导扩散推理与梯度近似",
      "利用视觉-语言基础模型进行特征空间对比"
    ],
    "problems": [
      "如何在越野和非结构化环境中实现机器人对分布外异常的检测",
      "如何在无需对异常类型做假设的情况下进行像素级异常检测",
      "如何在不重新训练或微调的前提下集成异常检测方法到现有工作流"
    ]
  },
  "2505.22923": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于盲逆问题（如盲图像去模糊），属于计算机视觉领域。其核心创新是将扩散模型作为先验，通过Plug-and-Play框架进行后验采样，解决目标图像和测量算子均未知的盲逆问题。扩散模型是当前生成模型中的主流方法，且论文明确提出了Plug-and-Play扩散模型用于盲逆问题，因此最合适的分类路径为‘计算机科学 → 计算机视觉 → 生成模型 → 扩散模型’。",
      "keywords": [
        "盲逆问题",
        "Plug-and-Play",
        "扩散模型",
        "后验采样",
        "图像去模糊"
      ],
      "methods": [
        "Plug-and-Play扩散模型",
        "交替高斯去噪",
        "双扩散模型先验",
        "后验采样"
      ],
      "problems": [
        "如何在目标图像和测量算子均未知的情况下解决盲逆问题",
        "如何利用扩散模型作为先验提升盲图像去模糊的性能"
      ]
    },
    "keywords": [
      "盲逆问题",
      "Plug-and-Play",
      "扩散模型",
      "后验采样",
      "图像去模糊"
    ],
    "methods": [
      "Plug-and-Play扩散模型",
      "交替高斯去噪",
      "双扩散模型先验",
      "后验采样"
    ],
    "problems": [
      "如何在目标图像和测量算子均未知的情况下解决盲逆问题",
      "如何利用扩散模型作为先验提升盲图像去模糊的性能"
    ]
  },
  "2505.22991": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注无监督聚类中簇数的自动确定问题，提出了正则化k-means方法及其参数选择理论分析。该问题属于机器学习领域，具体涉及聚类算法的改进和模型选择。标准词表中没有专门的'聚类'或'无监督学习'，但'小样本学习'在实际应用中常包含模型选择、聚类等小样本/无标签数据场景，因此选择'机器学习 → 小样本学习'作为最贴切的分类路径。",
      "keywords": [
        "聚类",
        "k-means",
        "正则化",
        "簇数选择",
        "超参数",
        "无监督学习"
      ],
      "methods": [
        "正则化k-means算法",
        "加性正则项",
        "乘性正则项",
        "理论界限推导",
        "实验验证"
      ],
      "problems": [
        "如何自动确定数据集中的有效簇数",
        "正则化k-means中正则化参数λ的合理设置",
        "正则化k-means多解的消歧"
      ]
    },
    "keywords": [
      "聚类",
      "k-means",
      "正则化",
      "簇数选择",
      "超参数",
      "无监督学习"
    ],
    "methods": [
      "正则化k-means算法",
      "加性正则项",
      "乘性正则项",
      "理论界限推导",
      "实验验证"
    ],
    "problems": [
      "如何自动确定数据集中的有效簇数",
      "正则化k-means中正则化参数λ的合理设置",
      "正则化k-means多解的消歧"
    ]
  },
  "2505.23027": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注于提升机器学习模型在子群体分布变化（subpopulation shift）下的鲁棒性，提出了一种基于多样化原型集成（Diverse Prototypical Ensembles, DPEs）的方法。该方法通过集成多样化的原型分类器来适应不同子群体的风险，属于机器学习领域。虽然论文涉及到分类任务和泛化能力提升，但其核心在于处理数据分布变化和小样本泛化问题，因此归入‘小样本学习’最为贴切。论文未聚焦于具体的视觉、语言或音频任务，而是提出通用的机器学习方法，因此不选更细的应用领域。",
      "keywords": [
        "subpopulation shift",
        "robustness",
        "ensemble learning",
        "prototypical classifiers",
        "generalization",
        "worst-group accuracy"
      ],
      "methods": [
        "Diverse Prototypical Ensembles (DPEs)",
        "mixture of prototypical classifiers",
        "feature extractor network",
        "adaptive risk modeling"
      ],
      "problems": [
        "如何提升机器学习模型在子群体分布变化下的鲁棒性",
        "如何在缺乏子群体标签的情况下实现有效的泛化",
        "如何避免对子群体数量和属性的先验假设"
      ]
    },
    "keywords": [
      "subpopulation shift",
      "robustness",
      "ensemble learning",
      "prototypical classifiers",
      "generalization",
      "worst-group accuracy"
    ],
    "methods": [
      "Diverse Prototypical Ensembles (DPEs)",
      "mixture of prototypical classifiers",
      "feature extractor network",
      "adaptive risk modeling"
    ],
    "problems": [
      "如何提升机器学习模型在子群体分布变化下的鲁棒性",
      "如何在缺乏子群体标签的情况下实现有效的泛化",
      "如何避免对子群体数量和属性的先验假设"
    ]
  },
  "2505.23173": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习 → 域泛化",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": "域泛化",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于提升模型在分布外数据上的泛化能力，属于典型的域泛化（Domain Generalization）问题。虽然论文涉及计算机视觉中的数据集和风格迁移等技术，但其核心贡献在于提出了一种新的域泛化框架（PMDG），并通过生成伪多源域数据来提升单源域泛化能力。这一研究方向属于机器学习领域下的小样本学习（因其强调泛化和数据分布外表现），具体任务为域泛化。因此选择“计算机科学 → 机器学习 → 小样本学习 → 域泛化”作为分类路径。",
      "keywords": [
        "域泛化",
        "多源域泛化",
        "单源域泛化",
        "风格迁移",
        "数据增强",
        "伪多源域",
        "DomainBed"
      ],
      "methods": [
        "伪多源域生成（Pseudo Multi-source Domain Generation）",
        "风格迁移",
        "数据增强",
        "MDG算法适配",
        "实验基准（PseudoDomainBed）"
      ],
      "problems": [
        "如何在仅有单一源域数据的情况下提升模型在未知目标域的泛化能力？",
        "如何利用伪多源域生成技术，使多源域泛化算法能够应用于单源域场景？",
        "伪多源域方法与真实多源域方法在泛化性能上有何异同？"
      ]
    },
    "keywords": [
      "域泛化",
      "多源域泛化",
      "单源域泛化",
      "风格迁移",
      "数据增强",
      "伪多源域",
      "DomainBed"
    ],
    "methods": [
      "伪多源域生成（Pseudo Multi-source Domain Generation）",
      "风格迁移",
      "数据增强",
      "MDG算法适配",
      "实验基准（PseudoDomainBed）"
    ],
    "problems": [
      "如何在仅有单一源域数据的情况下提升模型在未知目标域的泛化能力？",
      "如何利用伪多源域生成技术，使多源域泛化算法能够应用于单源域场景？",
      "伪多源域方法与真实多源域方法在泛化性能上有何异同？"
    ]
  },
  "2505.23189": {
    "classification_path": "计算机科学 → 计算机视觉 → 视频理解 → 视觉目标跟踪",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "视频理解",
      "level3": "视觉目标跟踪",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于具身视觉目标跟踪（embodied visual tracking），核心任务是让智能体在动态环境中通过视觉跟踪特定目标。该任务属于计算机视觉领域下的视频理解分支，具体为视觉目标跟踪。虽然论文涉及多模态（视觉-语言-动作）和强化学习元素，但主要贡献和实验均围绕视觉目标跟踪展开，因此选择'计算机视觉 → 视频理解 → 视觉目标跟踪'作为最合适的分层分类路径。",
      "keywords": [
        "具身视觉跟踪",
        "视觉-语言-动作模型",
        "目标识别",
        "轨迹规划",
        "扩散模型",
        "大语言模型",
        "动态环境",
        "遮挡鲁棒性"
      ],
      "methods": [
        "视觉-语言-动作（VLA）模型",
        "共享大语言模型骨干",
        "语言建模头用于目标识别",
        "基于锚点的扩散模型用于轨迹规划",
        "构建具身视觉跟踪基准（EVT-Bench）",
        "多难度样本采集与训练"
      ],
      "problems": [
        "如何在动态和高遮挡环境下实现鲁棒的具身视觉目标跟踪",
        "如何联合优化目标识别与轨迹规划以提升跟踪性能",
        "如何实现零样本泛化能力和高效推理速度"
      ]
    },
    "keywords": [
      "具身视觉跟踪",
      "视觉-语言-动作模型",
      "目标识别",
      "轨迹规划",
      "扩散模型",
      "大语言模型",
      "动态环境",
      "遮挡鲁棒性"
    ],
    "methods": [
      "视觉-语言-动作（VLA）模型",
      "共享大语言模型骨干",
      "语言建模头用于目标识别",
      "基于锚点的扩散模型用于轨迹规划",
      "构建具身视觉跟踪基准（EVT-Bench）",
      "多难度样本采集与训练"
    ],
    "problems": [
      "如何在动态和高遮挡环境下实现鲁棒的具身视觉目标跟踪",
      "如何联合优化目标识别与轨迹规划以提升跟踪性能",
      "如何实现零样本泛化能力和高效推理速度"
    ]
  },
  "2505.23266": {
    "classification_path": "计算机科学 → 多模态学习 → 三维重建 → 视觉 → 语言导航",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "三维重建",
      "level3": "视觉-语言导航",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文聚焦于视觉-语言模型（VLM）驱动的导航系统中的对抗性攻击，涉及3D对象生成与融合，属于多模态学习领域。其核心方法是通过对3D对象的对抗性融合影响视觉-语言导航（VLN）代理的感知与决策，属于三维重建下的具体应用任务——视觉-语言导航。虽然涉及安全性，但主要创新点和技术路线集中在多模态感知与三维空间中的对抗性对象生成，因此选择‘多模态学习 → 三维重建 → 视觉-语言导航’作为最合适的分层分类。",
      "keywords": [
        "对抗性攻击",
        "视觉-语言导航",
        "多模态学习",
        "三维重建",
        "服务型机器人",
        "对象融合",
        "安全性"
      ],
      "methods": [
        "对抗性对象融合（AdvOF）",
        "三维与二维空间对齐",
        "多视角优化",
        "正则化物理属性与感知特征",
        "重要性加权视角融合"
      ],
      "problems": [
        "如何通过对抗性3D对象攻击视觉-语言导航系统以影响其感知与决策？",
        "如何在保证导航任务正常运行的前提下，有效降低VLM驱动导航代理的性能？",
        "如何提升服务型导航系统在物理世界部署中的安全性与鲁棒性？"
      ]
    },
    "keywords": [
      "对抗性攻击",
      "视觉-语言导航",
      "多模态学习",
      "三维重建",
      "服务型机器人",
      "对象融合",
      "安全性"
    ],
    "methods": [
      "对抗性对象融合（AdvOF）",
      "三维与二维空间对齐",
      "多视角优化",
      "正则化物理属性与感知特征",
      "重要性加权视角融合"
    ],
    "problems": [
      "如何通过对抗性3D对象攻击视觉-语言导航系统以影响其感知与决策？",
      "如何在保证导航任务正常运行的前提下，有效降低VLM驱动导航代理的性能？",
      "如何提升服务型导航系统在物理世界部署中的安全性与鲁棒性？"
    ]
  },
  "2505.23290": {
    "classification_path": "计算机科学 → 计算机视觉 → 生成模型 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "生成模型",
      "level3": "三维重建",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于3D语音驱动的面部动画生成任务，核心贡献在于提出了一种用于提升语音到面部动画映射质量的语义解耦模块。虽然涉及音频特征处理，但主要目标是提升三维面部动画的生成质量，属于计算机视觉领域下的生成模型与三维重建的交叉任务。标准领域词表中，'三维重建'最贴合该论文的具体应用场景。",
      "keywords": [
        "3D面部动画",
        "语音驱动",
        "语义解耦",
        "生成模型",
        "三维重建"
      ],
      "methods": [
        "语义解耦模块（Wav2Sem）",
        "自监督音频特征编码",
        "特征空间去相关",
        "端到端生成模型"
      ],
      "problems": [
        "现有自监督音频编码器对近音同音节的唇形生成存在平均化效应",
        "如何提升语音驱动三维面部动画的精确性与自然度",
        "如何在音频特征空间中有效解耦语义信息以改善动画生成"
      ]
    },
    "keywords": [
      "3D面部动画",
      "语音驱动",
      "语义解耦",
      "生成模型",
      "三维重建"
    ],
    "methods": [
      "语义解耦模块（Wav2Sem）",
      "自监督音频特征编码",
      "特征空间去相关",
      "端到端生成模型"
    ],
    "problems": [
      "现有自监督音频编码器对近音同音节的唇形生成存在平均化效应",
      "如何提升语音驱动三维面部动画的精确性与自然度",
      "如何在音频特征空间中有效解耦语义信息以改善动画生成"
    ]
  },
  "2505.23317": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测 → 实时目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": "实时目标检测",
      "depth": 4,
      "confidence": 0.98,
      "reasoning": "该论文聚焦于基于Transformer的目标检测方法（DETR），并提出了面向自动驾驶等实时场景的高效检测系统CF-DETR。论文核心贡献在于提升目标检测的实时性与准确性，属于计算机视觉领域下的目标检测任务，且强调实时性，因此归为'实时目标检测'。",
      "keywords": [
        "DETR",
        "Transformer",
        "实时目标检测",
        "自动驾驶",
        "调度框架",
        "资源分配",
        "安全关键对象"
      ],
      "methods": [
        "粗到细Transformer架构",
        "NPFP**实时调度框架",
        "粗到细推理",
        "选择性细粒度推理",
        "多级批量推理",
        "任务分区（安全关键与可选子任务）"
      ],
      "problems": [
        "如何在资源受限条件下实现高准确率的实时目标检测",
        "如何满足自动驾驶等安全关键场景下的严格时限和检测准确性要求",
        "如何利用Transformer模型特性进行高效的资源调度与分配"
      ]
    },
    "keywords": [
      "DETR",
      "Transformer",
      "实时目标检测",
      "自动驾驶",
      "调度框架",
      "资源分配",
      "安全关键对象"
    ],
    "methods": [
      "粗到细Transformer架构",
      "NPFP**实时调度框架",
      "粗到细推理",
      "选择性细粒度推理",
      "多级批量推理",
      "任务分区（安全关键与可选子任务）"
    ],
    "problems": [
      "如何在资源受限条件下实现高准确率的实时目标检测",
      "如何满足自动驾驶等安全关键场景下的严格时限和检测准确性要求",
      "如何利用Transformer模型特性进行高效的资源调度与分配"
    ]
  },
  "2505.23353": {
    "classification_path": "计算机科学 → 医学图像 → 医学图像分割 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "医学图像",
      "level2": "医学图像分割",
      "level3": "小样本学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于多发性硬化症中磁共振影像的定量易感图（QSM）中边缘病灶（rim lesions）的合成生成与去噪，旨在提升稀有病灶（小样本）检测与分割的性能。论文主要贡献为生成合成医学影像数据、提升少数类（边缘病灶）检测能力，并提出基于生成网络的去噪方法。根据标准领域词表，最合适的分类路径为‘医学图像 → 医学图像分割 → 小样本学习’，因为论文核心任务是医学影像中稀有病灶的分割与检测，且主要技术难点在于小样本学习。",
      "keywords": [
        "多发性硬化症",
        "磁共振成像",
        "定量易感图",
        "边缘病灶",
        "生成对抗网络",
        "小样本学习",
        "医学图像分割",
        "数据增强",
        "去噪"
      ],
      "methods": [
        "合成定量易感图生成",
        "多通道生成对抗网络（GAN）",
        "投影去噪方法",
        "概率分割图生成",
        "数据增强"
      ],
      "problems": [
        "如何在多发性硬化症磁共振影像中提升稀有边缘病灶（PRLs）的检测与分割性能",
        "如何通过合成数据缓解医学影像中边缘病灶类别不平衡问题",
        "如何利用生成模型进行标签去噪以提升小样本类别的检测能力"
      ]
    },
    "keywords": [
      "多发性硬化症",
      "磁共振成像",
      "定量易感图",
      "边缘病灶",
      "生成对抗网络",
      "小样本学习",
      "医学图像分割",
      "数据增强",
      "去噪"
    ],
    "methods": [
      "合成定量易感图生成",
      "多通道生成对抗网络（GAN）",
      "投影去噪方法",
      "概率分割图生成",
      "数据增强"
    ],
    "problems": [
      "如何在多发性硬化症磁共振影像中提升稀有边缘病灶（PRLs）的检测与分割性能",
      "如何通过合成数据缓解医学影像中边缘病灶类别不平衡问题",
      "如何利用生成模型进行标签去噪以提升小样本类别的检测能力"
    ]
  },
  "2505.23412": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习 → 类增量学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": "类增量学习",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要研究如何在无需存储历史数据的情况下实现类增量学习（Class-Incremental Learning, CIL），并结合了开放世界下的分布外检测（OOD Detection）。CIL属于小样本学习范畴，尤其关注模型在不断接收新类别时的适应能力和对未知类别的识别能力。虽然涉及计算机视觉数据集，但核心贡献在于增量学习方法本身，因此归入机器学习-小样本学习-类增量学习。",
      "keywords": [
        "类增量学习",
        "分布外检测",
        "无缓冲区",
        "开放世界学习",
        "遗忘问题",
        "隐私保护"
      ],
      "methods": [
        "后验分布外检测方法",
        "无缓冲区推理策略",
        "多头模型训练",
        "任务增量学习框架"
      ],
      "problems": [
        "如何在不使用历史数据缓冲区的情况下实现高效的类增量学习",
        "如何在开放世界场景下准确检测并拒绝未知类别输入",
        "如何在保证隐私和可扩展性的前提下提升CIL系统性能"
      ]
    },
    "keywords": [
      "类增量学习",
      "分布外检测",
      "无缓冲区",
      "开放世界学习",
      "遗忘问题",
      "隐私保护"
    ],
    "methods": [
      "后验分布外检测方法",
      "无缓冲区推理策略",
      "多头模型训练",
      "任务增量学习框架"
    ],
    "problems": [
      "如何在不使用历史数据缓冲区的情况下实现高效的类增量学习",
      "如何在开放世界场景下准确检测并拒绝未知类别输入",
      "如何在保证隐私和可扩展性的前提下提升CIL系统性能"
    ]
  },
  "2505.23448": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "该论文主要关注于提升模型对分布外样本（OOD）的检测能力和不确定性估计，这属于机器学习领域中的泛化与鲁棒性问题。论文提出的方法无需外部OOD数据集，强调模型对未知分布的识别能力，这与小样本学习领域中对有限或未知样本分布的泛化能力密切相关。虽然论文也涉及图像数据，但核心创新点和主要贡献在于机器学习方法本身而非具体的计算机视觉任务，因此选择'机器学习 → 小样本学习'作为最合适的分类路径。",
      "keywords": [
        "分布外检测",
        "不确定性估计",
        "网络反演",
        "垃圾类别",
        "分类器训练"
      ],
      "methods": [
        "网络反演与分类器联合训练",
        "引入垃圾类别扩展分类空间",
        "迭代训练-反演-排除循环",
        "无需外部OOD数据集的自监督方法"
      ],
      "problems": [
        "如何在无需外部分布外数据集的情况下实现有效的分布外检测",
        "如何同时实现对分布内与分布外样本的不确定性估计",
        "如何提升分类器对未知输入的鲁棒性和安全性"
      ]
    },
    "keywords": [
      "分布外检测",
      "不确定性估计",
      "网络反演",
      "垃圾类别",
      "分类器训练"
    ],
    "methods": [
      "网络反演与分类器联合训练",
      "引入垃圾类别扩展分类空间",
      "迭代训练-反演-排除循环",
      "无需外部OOD数据集的自监督方法"
    ],
    "problems": [
      "如何在无需外部分布外数据集的情况下实现有效的分布外检测",
      "如何同时实现对分布内与分布外样本的不确定性估计",
      "如何提升分类器对未知输入的鲁棒性和安全性"
    ]
  },
  "2505.23465": {
    "classification_path": "计算机科学 → 多模态学习 → 生成模型 → 人体动作生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "生成模型",
      "level3": "人体动作生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究如何根据音频指令生成与语义相关的人体动作，属于多模态（音频与动作）信息的联合建模与生成。论文核心方法为生成模型（masked generative transformer），具体任务为人体动作生成。虽然涉及音频处理，但主要创新点和任务聚焦在多模态生成，因此选择‘多模态学习→生成模型→人体动作生成’作为分类路径。",
      "keywords": [
        "多模态生成",
        "人体动作生成",
        "音频指令",
        "语义对齐",
        "生成式Transformer",
        "记忆检索注意力"
      ],
      "methods": [
        "端到端生成框架",
        "masked generative transformer",
        "记忆检索注意力模块",
        "数据集扩充（对话式描述与多说话人音频生成）"
      ],
      "problems": [
        "如何根据音频指令生成与语义高度相关的人体动作",
        "如何提升音频与动作之间的语义对齐程度",
        "如何处理稀疏和长时音频输入以生成自然的人体动作"
      ]
    },
    "keywords": [
      "多模态生成",
      "人体动作生成",
      "音频指令",
      "语义对齐",
      "生成式Transformer",
      "记忆检索注意力"
    ],
    "methods": [
      "端到端生成框架",
      "masked generative transformer",
      "记忆检索注意力模块",
      "数据集扩充（对话式描述与多说话人音频生成）"
    ],
    "problems": [
      "如何根据音频指令生成与语义高度相关的人体动作",
      "如何提升音频与动作之间的语义对齐程度",
      "如何处理稀疏和长时音频输入以生成自然的人体动作"
    ]
  },
  "2505.23606": {
    "classification_path": "计算机科学 → 多模态学习 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "多模态学习",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文提出了一个统一的离散扩散模型（Muddit），能够在文本和图像两种模态下进行生成任务。论文强调模型的多模态能力、生成模型架构以及扩散模型方法，因此最合适的分类路径为‘多模态学习 → 生成模型 → 扩散模型’。虽然涉及视觉和文本，但核心贡献在于多模态统一生成和扩散模型方法。",
      "keywords": [
        "多模态生成",
        "离散扩散模型",
        "统一模型",
        "文本生成",
        "图像生成",
        "视觉先验"
      ],
      "methods": [
        "离散扩散变换器",
        "预训练文本到图像骨干集成",
        "轻量级文本解码器",
        "并行生成"
      ],
      "problems": [
        "如何实现高效且统一的多模态生成（文本与图像）",
        "如何克服自回归模型推理慢和非自回归模型泛化弱的问题",
        "如何利用强视觉先验提升多模态生成质量和效率"
      ]
    },
    "keywords": [
      "多模态生成",
      "离散扩散模型",
      "统一模型",
      "文本生成",
      "图像生成",
      "视觉先验"
    ],
    "methods": [
      "离散扩散变换器",
      "预训练文本到图像骨干集成",
      "轻量级文本解码器",
      "并行生成"
    ],
    "problems": [
      "如何实现高效且统一的多模态生成（文本与图像）",
      "如何克服自回归模型推理慢和非自回归模型泛化弱的问题",
      "如何利用强视觉先验提升多模态生成质量和效率"
    ]
  },
  "2505.23612": {
    "classification_path": "计算机科学 → 机器人学 → 生成模型 → 轨迹生成",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器人学",
      "level2": "生成模型",
      "level3": "轨迹生成",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文聚焦于自动驾驶中的可控轨迹生成，核心是提出一种自回归的meta-action机制以提升轨迹与高层语义决策的对齐与控制能力。虽然涉及生成模型和序列建模，但其主要应用场景和任务是机器人（自动驾驶）中的轨迹生成，因此选择'机器人学'为二级领域，'生成模型'为三级领域，'轨迹生成'为四级领域。",
      "keywords": [
        "可控轨迹生成",
        "自回归meta-action",
        "自动驾驶",
        "高层语义决策",
        "时序对齐"
      ],
      "methods": [
        "自回归meta-action分解",
        "帧级meta-action预测",
        "分阶段预训练",
        "meta-action条件轨迹生成"
      ],
      "problems": [
        "现有方法中meta-action与轨迹的时序错位导致的任务不一致和性能下降",
        "如何实现高层决策与轨迹生成的精确对齐与统一建模",
        "提升轨迹生成对动态决策场景的适应性和响应性"
      ]
    },
    "keywords": [
      "可控轨迹生成",
      "自回归meta-action",
      "自动驾驶",
      "高层语义决策",
      "时序对齐"
    ],
    "methods": [
      "自回归meta-action分解",
      "帧级meta-action预测",
      "分阶段预训练",
      "meta-action条件轨迹生成"
    ],
    "problems": [
      "现有方法中meta-action与轨迹的时序错位导致的任务不一致和性能下降",
      "如何实现高层决策与轨迹生成的精确对齐与统一建模",
      "提升轨迹生成对动态决策场景的适应性和响应性"
    ]
  },
  "2505.23625": {
    "classification_path": "计算机科学 → 语音与音频处理 → 生成模型 → 扩散模型",
    "raw_result": {
      "root": "计算机科学",
      "level1": "语音与音频处理",
      "level2": "生成模型",
      "level3": "扩散模型",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "该论文主要研究音频源分离问题，属于语音与音频处理领域。其核心方法是利用预训练的文本引导音频扩散生成模型进行零样本分离，属于生成模型范畴，具体采用扩散模型实现。因此，最合适的分层路径为‘计算机科学 → 语音与音频处理 → 生成模型 → 扩散模型’。",
      "keywords": [
        "音频源分离",
        "零样本学习",
        "扩散模型",
        "文本引导",
        "生成模型",
        "预训练",
        "开放集"
      ],
      "methods": [
        "预训练文本引导音频扩散模型",
        "反向扩散过程中的文本条件引导",
        "无监督/零样本分离"
      ],
      "problems": [
        "如何在无需任务特定训练的情况下实现音频源分离",
        "如何利用生成式扩散模型进行开放集音频分离",
        "如何克服现有监督方法对标注数据的依赖和泛化能力不足"
      ]
    },
    "keywords": [
      "音频源分离",
      "零样本学习",
      "扩散模型",
      "文本引导",
      "生成模型",
      "预训练",
      "开放集"
    ],
    "methods": [
      "预训练文本引导音频扩散模型",
      "反向扩散过程中的文本条件引导",
      "无监督/零样本分离"
    ],
    "problems": [
      "如何在无需任务特定训练的情况下实现音频源分离",
      "如何利用生成式扩散模型进行开放集音频分离",
      "如何克服现有监督方法对标注数据的依赖和泛化能力不足"
    ]
  },
  "2505.23651": {
    "classification_path": "计算机科学 → 机器学习 → 小样本学习 → 多目标域自适应",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器学习",
      "level2": "小样本学习",
      "level3": "多目标域自适应",
      "depth": 4,
      "confidence": 0.95,
      "reasoning": "论文主要关注模型量化与模型合并在多目标域自适应（multi-target domain adaptation）中的挑战与方法。虽然涉及模型量化和合并，但核心问题是如何在多目标域自适应场景下实现高效的后训练量化与模型合并。标准领域词表中，'小样本学习'最贴近领域自适应相关任务，'多目标域自适应'为具体任务，符合四级分类要求。",
      "keywords": [
        "模型合并",
        "后训练量化",
        "多目标域自适应",
        "HDRQ",
        "Hessian正则化",
        "离散化效应"
      ],
      "methods": [
        "HDRQ（Hessian和远距离正则化量化）",
        "误差屏障分析",
        "后训练量化方法设计"
      ],
      "problems": [
        "量化对多目标域自适应中模型合并的影响",
        "如何设计兼容模型合并的后训练量化方法",
        "在保证模型性能的同时减少量化带来的损失"
      ]
    },
    "keywords": [
      "模型合并",
      "后训练量化",
      "多目标域自适应",
      "HDRQ",
      "Hessian正则化",
      "离散化效应"
    ],
    "methods": [
      "HDRQ（Hessian和远距离正则化量化）",
      "误差屏障分析",
      "后训练量化方法设计"
    ],
    "problems": [
      "量化对多目标域自适应中模型合并的影响",
      "如何设计兼容模型合并的后训练量化方法",
      "在保证模型性能的同时减少量化带来的损失"
    ]
  },
  "2505.23692": {
    "classification_path": "计算机科学 → 机器人学 → 三维重建",
    "raw_result": {
      "root": "计算机科学",
      "level1": "机器人学",
      "level2": "三维重建",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "本论文主要关注于移动机器人在新环境中通过优化基座位置以提升操控策略泛化能力，属于机器人学领域。论文核心方法包括利用3D Gaussian Splatting进行新视角合成和基于采样的优化，涉及三维空间中的感知与动作决策，因此选择'三维重建'作为三级领域。虽然涉及视觉和强化学习，但主要贡献在于机器人移动与操控策略的结合，且未聚焦于目标检测、图像分割等视觉任务，因此未选择计算机视觉相关三级领域。",
      "keywords": [
        "移动机器人",
        "操控策略泛化",
        "三维重建",
        "新视角合成",
        "基座位置优化",
        "策略迁移"
      ],
      "methods": [
        "3D Gaussian Splatting",
        "新视角合成",
        "基座位置采样优化",
        "策略分布对齐",
        "基于得分函数的姿态评估"
      ],
      "problems": [
        "如何在新环境中为移动机器人选择合适的基座位置以提升已学习操控策略的泛化能力",
        "如何在不增加额外演示的情况下实现策略迁移",
        "如何量化和分析策略动员的难度"
      ]
    },
    "keywords": [
      "移动机器人",
      "操控策略泛化",
      "三维重建",
      "新视角合成",
      "基座位置优化",
      "策略迁移"
    ],
    "methods": [
      "3D Gaussian Splatting",
      "新视角合成",
      "基座位置采样优化",
      "策略分布对齐",
      "基于得分函数的姿态评估"
    ],
    "problems": [
      "如何在新环境中为移动机器人选择合适的基座位置以提升已学习操控策略的泛化能力",
      "如何在不增加额外演示的情况下实现策略迁移",
      "如何量化和分析策略动员的难度"
    ]
  },
  "2505.23751": {
    "classification_path": "计算机科学 → 计算机视觉 → 目标检测",
    "raw_result": {
      "root": "计算机科学",
      "level1": "计算机视觉",
      "level2": "目标检测",
      "level3": null,
      "depth": 3,
      "confidence": 0.95,
      "reasoning": "论文主要关注视觉模型（如transformer）在处理图像patch顺序时的性能影响，提出了优化patch顺序以提升视觉任务表现的方法。虽然论文涉及transformer结构和序列建模，但核心问题是如何通过patch重排序提升视觉模型在图像分类等任务上的表现。标准领域词表下，最贴近的三级领域为'目标检测'，因其涵盖了视觉模型对图像内容的理解与识别任务。由于没有更细的分类（如'图像分类'），选择'目标检测'作为最接近的领域。",
      "keywords": [
        "patch ordering",
        "transformer",
        "vision models",
        "self-attention",
        "permutation sensitivity",
        "REOrder",
        "ImageNet-1K"
      ],
      "methods": [
        "信息论先验（compressibility评估）",
        "Plackett-Luce policy优化",
        "REINFORCE算法",
        "两阶段patch重排序框架"
      ],
      "problems": [
        "视觉transformer模型对patch顺序敏感性导致性能波动",
        "如何自动发现最优patch顺序以提升视觉模型表现"
      ]
    },
    "keywords": [
      "patch ordering",
      "transformer",
      "vision models",
      "self-attention",
      "permutation sensitivity",
      "REOrder",
      "ImageNet-1K"
    ],
    "methods": [
      "信息论先验（compressibility评估）",
      "Plackett-Luce policy优化",
      "REINFORCE算法",
      "两阶段patch重排序框架"
    ],
    "problems": [
      "视觉transformer模型对patch顺序敏感性导致性能波动",
      "如何自动发现最优patch顺序以提升视觉模型表现"
    ]
  }
}